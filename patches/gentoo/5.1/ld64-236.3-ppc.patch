diff --git a/src/abstraction/MachOFileAbstraction.hpp b/src/abstraction/MachOFileAbstraction.hpp
index 9279734..f09d5ed 100644
--- a/src/abstraction/MachOFileAbstraction.hpp
+++ b/src/abstraction/MachOFileAbstraction.hpp
@@ -30,6 +30,7 @@
 #include <mach-o/fat.h>
 #include <mach-o/stab.h>
 #include <mach-o/reloc.h>
+#include <mach-o/ppc/reloc.h>
 #include <mach-o/x86_64/reloc.h>
 #include <mach-o/compact_unwind_encoding.h>
 #include <mach/machine.h>
@@ -501,6 +502,28 @@ static const ArchInfo archInfoArray[] = {
 #if SUPPORT_ARCH_arm64v8
 	{ "arm64v8", CPU_TYPE_ARM64, CPU_SUBTYPE_ARM64_V8,   "arm64v8-",  "",   true,  false },
 #endif
+#if SUPPORT_ARCH_ppc
+	{ "ppc", CPU_TYPE_POWERPC,	CPU_SUBTYPE_POWERPC_ALL,	"ppc-", "", false,  false },
+#endif
+#if SUPPORT_ARCH_ppc750
+	{ "ppc750", CPU_TYPE_POWERPC,	CPU_SUBTYPE_POWERPC_750,	"ppc750-", "", true,  false },
+	#define SUPPORT_ARCH_ppc 1
+#endif
+#if SUPPORT_ARCH_ppc7400
+	{ "ppc7400", CPU_TYPE_POWERPC,	CPU_SUBTYPE_POWERPC_7400,	"ppc7400-", "", true,  false },
+	#define SUPPORT_ARCH_ppc 1
+#endif
+#if SUPPORT_ARCH_ppc7450
+	{ "ppc7450", CPU_TYPE_POWERPC,	CPU_SUBTYPE_POWERPC_7450,	"ppc7450-", "", true,  false },
+	#define SUPPORT_ARCH_ppc 1
+#endif
+#if SUPPORT_ARCH_ppc970
+	{ "ppc970", CPU_TYPE_POWERPC,	CPU_SUBTYPE_POWERPC_970,	"ppc970-", "", true,  false },
+	#define SUPPORT_ARCH_ppc 1
+#endif
+#if SUPPORT_ARCH_ppc64
+	{ "ppc64", CPU_TYPE_POWERPC64,	CPU_SUBTYPE_POWERPC_ALL,	"ppc64-", "", false,  false },
+#endif
 	{ NULL, 0, 0, NULL, NULL, false, false }
 };
 
diff --git a/src/create_configure b/src/create_configure
old mode 100644
new mode 100755
index 8ca92be..a8db80d
--- a/src/create_configure
+++ b/src/create_configure
@@ -16,7 +16,7 @@ fi
 
 for ANARCH in ${RC_SUPPORTED_ARCHS}
 do
-	KNOWN_ARCHS=",armv4t,armv5,armv6,armv7,armv7f,armv7k,armv7s,armv6m,armv7m,armv7em,armv8,arm64,arm64v8,i386,x86_64,x86_64h,"
+	KNOWN_ARCHS=",armv4t,armv5,armv6,armv7,armv7f,armv7k,armv7s,armv6m,armv7m,armv7em,armv8,arm64,arm64v8,i386,x86_64,x86_64h,ppc,ppc750,ppc7400,ppc7450,ppc970,ppc64,"
 	FOUND=`echo "$KNOWN_ARCHS" | grep ",$ANARCH,"`
 	if [ $FOUND ]; then
 		echo "#define SUPPORT_ARCH_$ANARCH  1" >> ${DERIVED_FILE_DIR}/configure.h
diff --git a/src/ld/HeaderAndLoadCommands.hpp b/src/ld/HeaderAndLoadCommands.hpp
index acbdf4f..e522f82 100644
--- a/src/ld/HeaderAndLoadCommands.hpp
+++ b/src/ld/HeaderAndLoadCommands.hpp
@@ -598,17 +598,55 @@ uint32_t HeaderAndLoadCommandsAtom<A>::flags() const
 	return bits;
 }
 
+#if SUPPORT_ARCH_ppc
+template <> uint32_t HeaderAndLoadCommandsAtom<ppc>::magic() const		{ return MH_MAGIC; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <> uint32_t HeaderAndLoadCommandsAtom<ppc64>::magic() const		{ return MH_MAGIC_64; }
+#endif
 template <> uint32_t HeaderAndLoadCommandsAtom<x86>::magic() const		{ return MH_MAGIC; }
 template <> uint32_t HeaderAndLoadCommandsAtom<x86_64>::magic() const	{ return MH_MAGIC_64; }
+#if SUPPORT_ARCH_arm_any
 template <> uint32_t HeaderAndLoadCommandsAtom<arm>::magic() const		{ return MH_MAGIC; }
+#endif
+#if SUPPORT_ARCH_arm64
 template <> uint32_t HeaderAndLoadCommandsAtom<arm64>::magic() const		{ return MH_MAGIC_64; }
-
+#endif
+
+#if SUPPORT_ARCH_ppc
+template <> uint32_t HeaderAndLoadCommandsAtom<ppc>::cpuType() const	{ return CPU_TYPE_POWERPC; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <> uint32_t HeaderAndLoadCommandsAtom<ppc64>::cpuType() const	{ return CPU_TYPE_POWERPC64; }
+#endif
 template <> uint32_t HeaderAndLoadCommandsAtom<x86>::cpuType() const	{ return CPU_TYPE_I386; }
 template <> uint32_t HeaderAndLoadCommandsAtom<x86_64>::cpuType() const	{ return CPU_TYPE_X86_64; }
+#if SUPPORT_ARCH_arm_any
 template <> uint32_t HeaderAndLoadCommandsAtom<arm>::cpuType() const	{ return CPU_TYPE_ARM; }
+#endif
+#if SUPPORT_ARCH_arm64
 template <> uint32_t HeaderAndLoadCommandsAtom<arm64>::cpuType() const	{ return CPU_TYPE_ARM64; }
+#endif
 
 
+#if SUPPORT_ARCH_ppc
+template <>
+uint32_t HeaderAndLoadCommandsAtom<ppc>::cpuSubType() const
+{
+	return _state.cpuSubType;
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+uint32_t HeaderAndLoadCommandsAtom<ppc64>::cpuSubType() const
+{
+	if ( (_options.outputKind() == Options::kDynamicExecutable) && (_options.macosxVersionMin() >= ld::mac10_5) )
+		return (CPU_SUBTYPE_POWERPC_ALL | 0x80000000);
+	else
+		return CPU_SUBTYPE_POWERPC_ALL;
+}
+#endif
 
 template <>
 uint32_t HeaderAndLoadCommandsAtom<x86>::cpuSubType() const
@@ -625,17 +663,21 @@ uint32_t HeaderAndLoadCommandsAtom<x86_64>::cpuSubType() const
 		return _state.cpuSubType;
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 uint32_t HeaderAndLoadCommandsAtom<arm>::cpuSubType() const
 {
 	return _state.cpuSubType;
 }
+#endif
 
+#if SUPPORT_ARCH_arm64
 template <>
 uint32_t HeaderAndLoadCommandsAtom<arm64>::cpuSubType() const
 {
 	return CPU_SUBTYPE_ARM64_ALL;
 }
+#endif
 
 
 
@@ -1065,8 +1107,10 @@ template <typename A>
 uint8_t* HeaderAndLoadCommandsAtom<A>::copyRoutinesLoadCommand(uint8_t* p) const
 {
 	pint_t initAddr = _state.entryPoint->finalAddress(); 
+#if SUPPORT_ARCH_arm_any
 	if ( _state.entryPoint->isThumb() )
 		initAddr |= 1ULL;
+#endif
 	macho_routines_command<P>* cmd = (macho_routines_command<P>*)p;
 	cmd->set_cmd(macho_routines_command<P>::CMD);
 	cmd->set_cmdsize(sizeof(macho_routines_command<P>));
@@ -1127,6 +1171,54 @@ uint8_t* HeaderAndLoadCommandsAtom<A>::copySourceVersionLoadCommand(uint8_t* p)
 	return p + sizeof(macho_source_version_command<P>);
 }
 
+#if SUPPORT_ARCH_ppc
+template <>
+uint32_t HeaderAndLoadCommandsAtom<ppc>::threadLoadCommandSize() const
+{
+	return this->alignedSize(16 + 40*4);	// base size + PPC_THREAD_STATE_COUNT * 4
+}
+
+
+template <>
+uint8_t* HeaderAndLoadCommandsAtom<ppc>::copyThreadsLoadCommand(uint8_t* p) const
+{
+	assert(_state.entryPoint != NULL);
+	pint_t start = _state.entryPoint->finalAddress();
+	macho_thread_command<ppc::P>* cmd = (macho_thread_command<ppc::P>*)p;
+	cmd->set_cmd(LC_UNIXTHREAD);
+	cmd->set_cmdsize(threadLoadCommandSize());
+	cmd->set_flavor(1);				// PPC_THREAD_STATE
+	cmd->set_count(40);				// PPC_THREAD_STATE_COUNT;
+	cmd->set_thread_register(0, start);
+	if ( _options.hasCustomStack() )
+		cmd->set_thread_register(3, _options.customStackAddr());	// r1
+	return p + threadLoadCommandSize();
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+uint32_t HeaderAndLoadCommandsAtom<ppc64>::threadLoadCommandSize() const
+{
+	return this->alignedSize(16 + 76*4);	// base size + PPC_THREAD_STATE64_COUNT * 4
+}
+
+template <>
+uint8_t* HeaderAndLoadCommandsAtom<ppc64>::copyThreadsLoadCommand(uint8_t* p) const
+{
+	assert(_state.entryPoint != NULL);
+	pint_t start = _state.entryPoint->finalAddress();
+	macho_thread_command<ppc::P>* cmd = (macho_thread_command<ppc::P>*)p;
+	cmd->set_cmd(LC_UNIXTHREAD);
+	cmd->set_cmdsize(threadLoadCommandSize());
+	cmd->set_flavor(5);				// PPC_THREAD_STATE64
+	cmd->set_count(76);				// PPC_THREAD_STATE64_COUNT;
+	cmd->set_thread_register(0, start);
+	if ( _options.hasCustomStack() )
+		cmd->set_thread_register(3, _options.customStackAddr());	// r1
+	return p + threadLoadCommandSize();
+}
+#endif
 
 template <>
 uint32_t HeaderAndLoadCommandsAtom<x86>::threadLoadCommandSize() const
@@ -1172,6 +1264,7 @@ uint8_t* HeaderAndLoadCommandsAtom<x86_64>::copyThreadsLoadCommand(uint8_t* p) c
 	return p + threadLoadCommandSize();
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 uint32_t HeaderAndLoadCommandsAtom<arm>::threadLoadCommandSize() const
 {
@@ -1195,8 +1288,10 @@ uint8_t* HeaderAndLoadCommandsAtom<arm>::copyThreadsLoadCommand(uint8_t* p) cons
 		cmd->set_thread_register(13, _options.customStackAddr());	// sp
 	return p + threadLoadCommandSize();
 }
+#endif
 
 
+#if SUPPORT_ARCH_arm64
 template <>
 uint32_t HeaderAndLoadCommandsAtom<arm64>::threadLoadCommandSize() const
 {
@@ -1218,6 +1313,7 @@ uint8_t* HeaderAndLoadCommandsAtom<arm64>::copyThreadsLoadCommand(uint8_t* p) co
 		cmd->set_thread_register(31, _options.customStackAddr());	// sp 
 	return p + threadLoadCommandSize();
 }
+#endif
 
 
 template <typename A>
@@ -1228,8 +1324,10 @@ uint8_t* HeaderAndLoadCommandsAtom<A>::copyEntryPointLoadCommand(uint8_t* p) con
 	cmd->set_cmdsize(sizeof(macho_entry_point_command<P>));
 	assert(_state.entryPoint != NULL);
 	pint_t start = _state.entryPoint->finalAddress(); 
+#if SUPPORT_ARCH_arm_any
 	if ( _state.entryPoint->isThumb() )
 		start |= 1ULL;
+#endif
 	cmd->set_entryoff(start - this->finalAddress());
 	cmd->set_stacksize(_options.hasCustomStack() ? _options.customStackSize() : 0 );
 	return p + sizeof(macho_entry_point_command<P>);
diff --git a/src/ld/InputFiles.cpp b/src/ld/InputFiles.cpp
index f49f2e3..a4a4d5d 100644
--- a/src/ld/InputFiles.cpp
+++ b/src/ld/InputFiles.cpp
@@ -759,6 +759,10 @@ void InputFiles::inferArchitecture(Options& opts, const char** archName)
 	warning("-arch not specified");
 #if __i386__
 	opts.setArchitecture(CPU_TYPE_I386, CPU_SUBTYPE_X86_ALL);
+#elif __ppc__
+	opts.setArchitecture(CPU_TYPE_POWERPC, CPU_SUBTYPE_POWERPC_ALL);
+#elif __ppc64__
+	opts.setArchitecture(CPU_TYPE_POWERPC64, CPU_SUBTYPE_POWERPC_ALL);
 #elif __x86_64__
 	opts.setArchitecture(CPU_TYPE_X86_64, CPU_SUBTYPE_X86_64_ALL);
 #elif __arm__
diff --git a/src/ld/LinkEdit.hpp b/src/ld/LinkEdit.hpp
index 3420626..ddec0ef 100644
--- a/src/ld/LinkEdit.hpp
+++ b/src/ld/LinkEdit.hpp
@@ -1016,8 +1016,11 @@ void ExportInfoAtom<A>::encode() const
 		else {
 			if ( (atom->definition() == ld::Atom::definitionRegular) && (atom->combine() == ld::Atom::combineByName) )
 				flags |= EXPORT_SYMBOL_FLAGS_WEAK_DEFINITION;
+
+#if SUPPORT_ARCH_arm_any
 			if ( atom->isThumb() )
 				address |= 1;
+#endif
 			if ( atom->contentType() == ld::Atom::typeResolver ) {
 				flags |= EXPORT_SYMBOL_FLAGS_STUB_AND_RESOLVER;
 				// set normal lookup to return stub address
@@ -1025,8 +1028,10 @@ void ExportInfoAtom<A>::encode() const
 				other = address;
 				const ld::Atom* stub = stubForResolverFunction(atom);
 				address = stub->finalAddress() - imageBaseAddress;
+#if SUPPORT_ARCH_arm_any
 				if ( stub->isThumb() )
 					address |= 1;
+#endif
 			}
 			entry.name = atom->name();
 			entry.flags = flags;
@@ -1072,11 +1077,18 @@ private:
 
 	mutable std::vector<uint64_t>				_32bitPointerLocations;
 	mutable std::vector<uint64_t>				_64bitPointerLocations;
+#if SUPPORT_ARCH_ppc
+	mutable std::vector<uint64_t>				_ppcHi16Locations;
+#endif
+#if SUPPORT_ARCH_arm_any
 	mutable std::vector<uint64_t>				_thumbLo16Locations;
 	mutable std::vector<uint64_t>				_thumbHi16Locations[16];
 	mutable std::vector<uint64_t>				_armLo16Locations;
 	mutable std::vector<uint64_t>				_armHi16Locations[16];
+#endif
+#if SUPPORT_ARCH_arm64
 	mutable std::vector<uint64_t>				_adrpLocations;
+#endif
 
 
 	static ld::Section			_s_section;
@@ -1131,6 +1143,7 @@ void SplitSegInfoAtom<x86>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind ki
 	}
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 void SplitSegInfoAtom<arm>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind kind, uint32_t extra) const
 {
@@ -1157,6 +1170,7 @@ void SplitSegInfoAtom<arm>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind ki
 			break;
 	}
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -1187,6 +1201,39 @@ void SplitSegInfoAtom<arm64>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
+template <>
+void SplitSegInfoAtom<ppc>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind kind, uint32_t extra) const
+{
+	switch (kind) {
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+			_ppcHi16Locations.push_back(address);
+			break;
+		case ld::Fixup::kindStoreBigEndian32:
+			_32bitPointerLocations.push_back(address);
+			break;
+		default:
+			warning("codegen at address 0x%08llX prevents image from working in dyld shared cache", address);
+			break;
+	}
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+void SplitSegInfoAtom<ppc64>::addSplitSegInfo(uint64_t address, ld::Fixup::Kind kind, uint32_t extra) const
+{
+	switch (kind) {
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+			_ppcHi16Locations.push_back(address);
+			break;
+		default:
+			warning("codegen at address 0x%08llX prevents image from working in dyld shared cache", address);
+			break;
+	}
+}
+#endif
+
 template <typename A>
 void SplitSegInfoAtom<A>::uleb128EncodeAddresses(const std::vector<uint64_t>& locations) const
 {
@@ -1241,6 +1288,7 @@ void SplitSegInfoAtom<A>::encode() const
 		this->_encodedData.append_byte(0); // terminator
 	}
 
+#if SUPPORT_ARCH_arm64
 	if ( _adrpLocations.size() != 0 ) {
 		this->_encodedData.append_byte(3);
 		//fprintf(stderr, "type 3:\n");
@@ -1248,7 +1296,19 @@ void SplitSegInfoAtom<A>::encode() const
 		this->uleb128EncodeAddresses(_adrpLocations);
 		this->_encodedData.append_byte(0); // terminator
 	}
+#endif
+
+#if SUPPORT_ARCH_ppc
+	if ( _ppcHi16Locations.size() != 0 ) {
+		this->_encodedData.append_byte(3);
+		//fprintf(stderr, "type 3:\n");
+		std::sort(_ppcHi16Locations.begin(), _ppcHi16Locations.end());
+		this->uleb128EncodeAddresses(_ppcHi16Locations);
+		this->_encodedData.append_byte(0); // terminator
+	}
+#endif
 
+#if SUPPORT_ARCH_arm_any
 	if ( _thumbLo16Locations.size() != 0 ) {
 		this->_encodedData.append_byte(5);
 		//fprintf(stderr, "type 5:\n");
@@ -1284,6 +1344,7 @@ void SplitSegInfoAtom<A>::encode() const
 			this->_encodedData.append_byte(0); // terminator
 		}
 	}
+#endif
 
 	// always add zero byte to mark end
 	this->_encodedData.append_byte(0);
@@ -1296,6 +1357,9 @@ void SplitSegInfoAtom<A>::encode() const
 	// clean up temporaries
 	_32bitPointerLocations.clear();
 	_64bitPointerLocations.clear();
+#if SUPPORT_ARCH_ppc
+	_ppcHi16Locations.clear();
+#endif
 }
 
 template <typename A>
@@ -1344,8 +1408,10 @@ void FunctionStartsAtom<A>::encode() const
 				if ( atom->size() == 0 )
 					continue;
 				uint64_t nextAddr = atom->finalAddress();
+#if SUPPORT_ARCH_arm_any
 				if ( atom->isThumb() )
 					nextAddr |= 1; 
+#endif
 				uint64_t delta = nextAddr - addr;
 				if ( delta != 0 )
 					this->_encodedData.append_uleb128(delta);
@@ -1595,6 +1661,7 @@ void OptimizationHintsAtom<A>::encode() const
 				for (ld::Fixup::iterator fit = atom->fixupsBegin(); fit != atom->fixupsEnd(); ++fit) {
 					if ( fit->kind != ld::Fixup::kindLinkerOptimizationHint) 
 						continue;
+#if SUPPORT_ARCH_arm64
 					ld::Fixup::LOH_arm64 extra;
 					extra.addend = fit->u.addend;
 					_encodedData.append_uleb128(extra.info.kind);
@@ -1606,6 +1673,7 @@ void OptimizationHintsAtom<A>::encode() const
 						_encodedData.append_uleb128((extra.info.delta3 << 2) + fit->offsetInAtom + address);
 					if ( extra.info.count > 2 )
 						_encodedData.append_uleb128((extra.info.delta4 << 2) + fit->offsetInAtom + address);
+#endif
 				}
 			}
 		}
diff --git a/src/ld/LinkEditClassic.hpp b/src/ld/LinkEditClassic.hpp
index b9b1215..c6dccdd 100644
--- a/src/ld/LinkEditClassic.hpp
+++ b/src/ld/LinkEditClassic.hpp
@@ -310,8 +310,10 @@ bool SymbolTableAtom<A>::addLocal(const ld::Atom* atom, StringPoolAtom* pool)
         desc |= N_NO_DEAD_STRIP;
 	if ( (atom->definition() == ld::Atom::definitionRegular) && (atom->combine() == ld::Atom::combineByName) )
 		desc |= N_WEAK_DEF;
+#if SUPPORT_ARCH_arm_any
 	if ( atom->isThumb() )
 		desc |= N_ARM_THUMB_DEF;
+#endif
 	entry.set_n_desc(desc);
 
 	// set n_value ( address this symbol will be at if this executable is loaded at it preferred address )
@@ -379,8 +381,10 @@ void SymbolTableAtom<A>::addGlobal(const ld::Atom* atom, StringPoolAtom* pool)
 
 	// set n_desc
 	uint16_t desc = 0;
+#if SUPPORT_ARCH_arm_any
     if ( atom->isThumb() )
         desc |= N_ARM_THUMB_DEF;
+#endif
     if ( atom->symbolTableInclusion() == ld::Atom::symbolTableInAndNeverStrip )
         desc |= REFERENCED_DYNAMICALLY;
     if ( (atom->contentType() == ld::Atom::typeResolver) && (this->_options.outputKind() == Options::kObjectFile) )
@@ -806,6 +810,54 @@ void LocalRelocationsAtom<A>::addPointerReloc(uint64_t addr, uint32_t symNum)
 template <typename A>
 void LocalRelocationsAtom<A>::addTextReloc(uint64_t addr, ld::Fixup::Kind kind, uint64_t targetAddr, uint32_t symNum)
 {
+	macho_relocation_info<P> reloc1;
+	macho_relocation_info<P> reloc2;
+	switch ( kind ) {
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCAbsLow14:
+		case ld::Fixup::kindStorePPCAbsLow16:
+			// a reference to the absolute address of something in this same linkage unit can be
+			// encoded as a local text reloc in a dylib or bundle
+			if ( _options.outputSlidable() ) {
+				reloc1.set_r_address(addr);
+				reloc1.set_r_symbolnum(symNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(false);
+				reloc1.set_r_type(kind==ld::Fixup::kindStorePPCAbsLow16 ? PPC_RELOC_LO16 : PPC_RELOC_LO14);
+				reloc2.set_r_address(targetAddr >> 16);
+				reloc2.set_r_symbolnum(0);
+				reloc2.set_r_pcrel(false);
+				reloc2.set_r_length(2);
+				reloc2.set_r_extern(false);
+				reloc2.set_r_type(PPC_RELOC_PAIR);
+				_relocs.push_back(reloc1);
+				_relocs.push_back(reloc2);
+			}
+			break;
+		case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+		case ld::Fixup::kindStorePPCAbsHigh16:
+			if ( _options.outputSlidable() ) {
+				reloc1.set_r_address(addr);
+				reloc1.set_r_symbolnum(symNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(false);
+				reloc1.set_r_type(kind==ld::Fixup::kindStorePPCAbsHigh16AddLow ? PPC_RELOC_HA16 : PPC_RELOC_HI16);
+				reloc2.set_r_address(targetAddr & 0xFFFF);
+				reloc2.set_r_symbolnum(0);
+				reloc2.set_r_pcrel(false);
+				reloc2.set_r_length(2);
+				reloc2.set_r_extern(false);
+				reloc2.set_r_type(PPC_RELOC_PAIR);
+				_relocs.push_back(reloc1);
+				_relocs.push_back(reloc2);
+			}
+			break;
+#endif
+		default:
+			break;
+	}
 }
 
 
@@ -934,7 +986,13 @@ template <> uint32_t ExternalRelocationsAtom<arm64>::pointerReloc() { return ARM
 template <> uint32_t ExternalRelocationsAtom<arm>::pointerReloc() { return ARM_RELOC_VANILLA; }
 #endif
 template <> uint32_t ExternalRelocationsAtom<x86>::pointerReloc() { return GENERIC_RELOC_VANILLA; }
+#if SUPPORT_ARCH_ppc
+template <> uint32_t ExternalRelocationsAtom<ppc>::pointerReloc() { return PPC_RELOC_VANILLA; }
+#endif
 template <> uint32_t ExternalRelocationsAtom<x86_64>::pointerReloc() { return X86_64_RELOC_UNSIGNED; }
+#if SUPPORT_ARCH_ppc64
+template <> uint32_t ExternalRelocationsAtom<ppc64>::pointerReloc() { return PPC_RELOC_VANILLA; }
+#endif
 
 
 template <> uint32_t ExternalRelocationsAtom<x86_64>::callReloc() { return X86_64_RELOC_BRANCH; }
@@ -1854,6 +1912,586 @@ void SectionRelocationsAtom<arm64>::encodeSectionReloc(ld::Internal::FinalSectio
 }
 #endif // SUPPORT_ARCH_arm64
 
+#if SUPPORT_ARCH_ppc
+template <>
+void SectionRelocationsAtom<ppc>::encodeSectionReloc(ld::Internal::FinalSection* sect,
+													const Entry& entry, std::vector<macho_relocation_info<P> >& relocs)
+{
+	macho_relocation_info<P> reloc1;
+	macho_relocation_info<P> reloc2;
+	macho_scattered_relocation_info<P>* sreloc1 = (macho_scattered_relocation_info<P>*)&reloc1;
+	macho_scattered_relocation_info<P>* sreloc2 = (macho_scattered_relocation_info<P>*)&reloc2;
+	uint64_t address = entry.inAtom->finalAddress()+entry.offsetInAtom - sect->address;
+	bool external = entry.toTargetUsesExternalReloc;
+	uint32_t symbolNum = sectSymNum(external, entry.toTarget);
+	bool fromExternal = false;
+	uint32_t fromSymbolNum = 0;
+	if ( entry.fromTarget != NULL ) {
+		fromExternal = entry.fromTargetUsesExternalReloc;
+		fromSymbolNum= sectSymNum(fromExternal, entry.fromTarget);
+	}
+	uint32_t toAddr;
+	uint32_t fromAddr;
+
+	switch ( entry.kind ) {
+
+		case ld::Fixup::kindStorePPCBranch24:
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+		case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+		case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(true);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_BR24);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(true);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_BR24);
+			}
+			relocs.push_back(reloc1);
+			break;
+
+		case ld::Fixup::kindStorePPCBranch14:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(true);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_BR14);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(true);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_BR14);
+			}
+			relocs.push_back(reloc1);
+			break;
+
+		case ld::Fixup::kindStoreBigEndian32:
+		case ld::Fixup::kindStoreTargetAddressBigEndian32:
+			if ( entry.fromTarget != NULL ) {
+				// this is a pointer-diff
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				if ( entry.toTarget->scope() == ld::Atom::scopeTranslationUnit )
+					sreloc1->set_r_type(PPC_RELOC_LOCAL_SECTDIFF);
+				else
+					sreloc1->set_r_type(PPC_RELOC_SECTDIFF);
+				sreloc1->set_r_address(address);
+				if ( entry.toTarget == entry.inAtom )
+					sreloc1->set_r_value(entry.toTarget->finalAddress()+entry.toAddend);
+				else
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				sreloc2->set_r_scattered(true);
+				sreloc2->set_r_pcrel(false);
+				sreloc2->set_r_length(2);
+				sreloc2->set_r_type(PPC_RELOC_PAIR);
+				sreloc2->set_r_address(0);
+				if ( entry.fromTarget == entry.inAtom ) {
+					if ( entry.fromAddend > entry.fromTarget->size() )
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.offsetInAtom);
+					else
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.fromAddend);
+				}
+				else
+					sreloc2->set_r_value(entry.fromTarget->finalAddress());
+				relocs.push_back(reloc1);
+				relocs.push_back(reloc2);
+			}
+			else {
+				// regular pointer
+				if ( !external && (entry.toAddend != 0) ) {
+					// use scattered reloc is target offset is non-zero
+					sreloc1->set_r_scattered(true);
+					sreloc1->set_r_pcrel(false);
+					sreloc1->set_r_length(2);
+					sreloc1->set_r_type(GENERIC_RELOC_VANILLA);
+					sreloc1->set_r_address(address);
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				}
+				else {
+					reloc1.set_r_address(address);
+					reloc1.set_r_symbolnum(symbolNum);
+					reloc1.set_r_pcrel(false);
+					reloc1.set_r_length(2);
+					reloc1.set_r_extern(external);
+					reloc1.set_r_type(GENERIC_RELOC_VANILLA);
+				}
+				relocs.push_back(reloc1);
+			}
+			break;
+
+		case ld::Fixup::kindStorePPCAbsLow14:
+		case ld::Fixup::kindStorePPCAbsLow16:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(entry.kind==ld::Fixup::kindStorePPCAbsLow16 ? PPC_RELOC_LO16 : PPC_RELOC_LO14);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(entry.kind==ld::Fixup::kindStorePPCAbsLow16 ? PPC_RELOC_LO16 : PPC_RELOC_LO14);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend >> 16);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) >> 16);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCAbsHigh16:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_HI16);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_HI16);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend & 0x0000FFFF);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) & 0x0000FFFF);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_HA16);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_HA16);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend & 0x0000FFFF);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) & 0x0000FFFF);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCPicLow14:
+		case ld::Fixup::kindStorePPCPicLow16:
+			fromAddr = entry.fromTarget->finalAddress() + entry.fromAddend;
+			toAddr = entry.toTarget->finalAddress() + entry.toAddend;
+			sreloc1->set_r_scattered(true);
+			sreloc1->set_r_pcrel(false);
+			sreloc1->set_r_length(2);
+			sreloc1->set_r_type(entry.kind == ld::Fixup::kindStorePPCPicLow16 ? PPC_RELOC_LO16_SECTDIFF : PPC_RELOC_LO14_SECTDIFF);
+			sreloc1->set_r_address(address);
+			sreloc1->set_r_value(entry.toTarget->finalAddress());
+			sreloc2->set_r_scattered(true);
+			sreloc2->set_r_pcrel(false);
+			sreloc2->set_r_length(2);
+			sreloc2->set_r_type(PPC_RELOC_PAIR);
+			sreloc2->set_r_address(((toAddr-fromAddr) >> 16) & 0xFFFF);
+			sreloc2->set_r_value(fromAddr);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+			fromAddr = entry.fromTarget->finalAddress() + entry.fromAddend;
+			toAddr = entry.toTarget->finalAddress() + entry.toAddend;
+			sreloc1->set_r_scattered(true);
+			sreloc1->set_r_pcrel(false);
+			sreloc1->set_r_length(2);
+			sreloc1->set_r_type(PPC_RELOC_HA16_SECTDIFF);
+			sreloc1->set_r_address(address);
+			sreloc1->set_r_value(entry.toTarget->finalAddress());
+			sreloc2->set_r_scattered(true);
+			sreloc2->set_r_pcrel(false);
+			sreloc2->set_r_length(2);
+			sreloc2->set_r_type(PPC_RELOC_PAIR);
+			sreloc2->set_r_address((toAddr-fromAddr) & 0xFFFF);
+			sreloc2->set_r_value(fromAddr);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		default:
+			assert(0 && "need to handle -r reloc");
+
+	}
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+void SectionRelocationsAtom<ppc64>::encodeSectionReloc(ld::Internal::FinalSection* sect,
+													const Entry& entry, std::vector<macho_relocation_info<P> >& relocs)
+{
+	macho_relocation_info<P> reloc1;
+	macho_relocation_info<P> reloc2;
+	macho_scattered_relocation_info<P>* sreloc1 = (macho_scattered_relocation_info<P>*)&reloc1;
+	macho_scattered_relocation_info<P>* sreloc2 = (macho_scattered_relocation_info<P>*)&reloc2;
+	uint64_t address = entry.inAtom->finalAddress()+entry.offsetInAtom - sect->address;
+	bool external = entry.toTargetUsesExternalReloc;
+	uint32_t symbolNum = sectSymNum(external, entry.toTarget);
+	bool fromExternal = false;
+	uint32_t fromSymbolNum = 0;
+	if ( entry.fromTarget != NULL ) {
+		fromExternal = entry.fromTargetUsesExternalReloc;
+		fromSymbolNum= sectSymNum(fromExternal, entry.fromTarget);
+	}
+	uint32_t toAddr;
+	uint32_t fromAddr;
+
+	switch ( entry.kind ) {
+
+		case ld::Fixup::kindStorePPCBranch24:
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+		case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+		case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(true);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_BR24);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(true);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_BR24);
+			}
+			relocs.push_back(reloc1);
+			break;
+
+		case ld::Fixup::kindStorePPCBranch14:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(true);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_BR14);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(true);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_BR14);
+			}
+			relocs.push_back(reloc1);
+			break;
+
+		case ld::Fixup::kindStoreBigEndian32:
+		case ld::Fixup::kindStoreTargetAddressBigEndian32:
+			if ( entry.fromTarget != NULL ) {
+				// this is a pointer-diff
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				if ( entry.toTarget->scope() == ld::Atom::scopeTranslationUnit )
+					sreloc1->set_r_type(PPC_RELOC_LOCAL_SECTDIFF);
+				else
+					sreloc1->set_r_type(PPC_RELOC_SECTDIFF);
+				sreloc1->set_r_address(address);
+				if ( entry.toTarget == entry.inAtom )
+					sreloc1->set_r_value(entry.toTarget->finalAddress()+entry.toAddend);
+				else
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				sreloc2->set_r_scattered(true);
+				sreloc2->set_r_pcrel(false);
+				sreloc2->set_r_length(2);
+				sreloc2->set_r_type(PPC_RELOC_PAIR);
+				sreloc2->set_r_address(0);
+				if ( entry.fromTarget == entry.inAtom ) {
+					if ( entry.fromAddend > entry.fromTarget->size() )
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.offsetInAtom);
+					else
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.fromAddend);
+				}
+				else
+					sreloc2->set_r_value(entry.fromTarget->finalAddress());
+				relocs.push_back(reloc1);
+				relocs.push_back(reloc2);
+			}
+			else {
+				// regular pointer
+				if ( !external && (entry.toAddend != 0) ) {
+					// use scattered reloc is target offset is non-zero
+					sreloc1->set_r_scattered(true);
+					sreloc1->set_r_pcrel(false);
+					sreloc1->set_r_length(2);
+					sreloc1->set_r_type(GENERIC_RELOC_VANILLA);
+					sreloc1->set_r_address(address);
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				}
+				else {
+					reloc1.set_r_address(address);
+					reloc1.set_r_symbolnum(symbolNum);
+					reloc1.set_r_pcrel(false);
+					reloc1.set_r_length(2);
+					reloc1.set_r_extern(external);
+					reloc1.set_r_type(GENERIC_RELOC_VANILLA);
+				}
+				relocs.push_back(reloc1);
+			}
+			break;
+
+		case ld::Fixup::kindStoreBigEndian64:
+		case ld::Fixup::kindStoreTargetAddressBigEndian64:
+			if ( entry.fromTarget != NULL ) {
+				// this is a pointer-diff
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(3);
+				if ( entry.toTarget->scope() == ld::Atom::scopeTranslationUnit )
+					sreloc1->set_r_type(PPC_RELOC_LOCAL_SECTDIFF);
+				else
+					sreloc1->set_r_type(PPC_RELOC_SECTDIFF);
+				sreloc1->set_r_address(address);
+				if ( entry.toTarget == entry.inAtom )
+					sreloc1->set_r_value(entry.toTarget->finalAddress()+entry.toAddend);
+				else
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				sreloc2->set_r_scattered(true);
+				sreloc2->set_r_pcrel(false);
+				sreloc2->set_r_length(3);
+				sreloc2->set_r_type(PPC_RELOC_PAIR);
+				sreloc2->set_r_address(0);
+				if ( entry.fromTarget == entry.inAtom ) {
+					if ( entry.fromAddend > entry.fromTarget->size() )
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.offsetInAtom);
+					else
+						sreloc2->set_r_value(entry.fromTarget->finalAddress()+entry.fromAddend);
+				}
+				else
+					sreloc2->set_r_value(entry.fromTarget->finalAddress());
+				relocs.push_back(reloc1);
+				relocs.push_back(reloc2);
+			}
+			else {
+				// regular pointer
+				if ( !external && (entry.toAddend != 0) ) {
+					// use scattered reloc is target offset is non-zero
+					sreloc1->set_r_scattered(true);
+					sreloc1->set_r_pcrel(false);
+					sreloc1->set_r_length(3);
+					sreloc1->set_r_type(GENERIC_RELOC_VANILLA);
+					sreloc1->set_r_address(address);
+					sreloc1->set_r_value(entry.toTarget->finalAddress());
+				}
+				else {
+					reloc1.set_r_address(address);
+					reloc1.set_r_symbolnum(symbolNum);
+					reloc1.set_r_pcrel(false);
+					reloc1.set_r_length(3);
+					reloc1.set_r_extern(external);
+					reloc1.set_r_type(GENERIC_RELOC_VANILLA);
+				}
+				relocs.push_back(reloc1);
+			}
+			break;
+
+		case ld::Fixup::kindStorePPCAbsLow14:
+		case ld::Fixup::kindStorePPCAbsLow16:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(entry.kind==ld::Fixup::kindStorePPCAbsLow16 ? PPC_RELOC_LO16 : PPC_RELOC_LO14);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(entry.kind==ld::Fixup::kindStorePPCAbsLow16 ? PPC_RELOC_LO16 : PPC_RELOC_LO14);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend >> 16);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) >> 16);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCAbsHigh16:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_HI16);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_HI16);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend & 0x0000FFFF);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) & 0x0000FFFF);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+			if ( !external && (entry.toAddend != 0) ) {
+				// use scattered reloc if target offset is non-zero
+				sreloc1->set_r_scattered(true);
+				sreloc1->set_r_pcrel(false);
+				sreloc1->set_r_length(2);
+				sreloc1->set_r_type(PPC_RELOC_HA16);
+				sreloc1->set_r_address(address);
+				sreloc1->set_r_value(entry.toTarget->finalAddress());
+			}
+			else {
+				reloc1.set_r_address(address);
+				reloc1.set_r_symbolnum(symbolNum);
+				reloc1.set_r_pcrel(false);
+				reloc1.set_r_length(2);
+				reloc1.set_r_extern(external);
+				reloc1.set_r_type(PPC_RELOC_HA16);
+			}
+			if ( external )
+				reloc2.set_r_address(entry.toAddend & 0x0000FFFF);
+			else
+				reloc2.set_r_address((entry.toTarget->finalAddress()+entry.toAddend) & 0x0000FFFF);
+			reloc2.set_r_symbolnum(0);
+			reloc2.set_r_pcrel(false);
+			reloc2.set_r_length(2);
+			reloc2.set_r_extern(false);
+			reloc2.set_r_type(PPC_RELOC_PAIR);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCPicLow14:
+		case ld::Fixup::kindStorePPCPicLow16:
+			fromAddr = entry.fromTarget->finalAddress() + entry.fromAddend;
+			toAddr = entry.toTarget->finalAddress() + entry.toAddend;
+			sreloc1->set_r_scattered(true);
+			sreloc1->set_r_pcrel(false);
+			sreloc1->set_r_length(2);
+			sreloc1->set_r_type(entry.kind == ld::Fixup::kindStorePPCPicLow16 ? PPC_RELOC_LO16_SECTDIFF : PPC_RELOC_LO14_SECTDIFF);
+			sreloc1->set_r_address(address);
+			sreloc1->set_r_value(entry.toTarget->finalAddress());
+			sreloc2->set_r_scattered(true);
+			sreloc2->set_r_pcrel(false);
+			sreloc2->set_r_length(2);
+			sreloc2->set_r_type(PPC_RELOC_PAIR);
+			sreloc2->set_r_address(((toAddr-fromAddr) >> 16) & 0xFFFF);
+			sreloc2->set_r_value(fromAddr);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+			fromAddr = entry.fromTarget->finalAddress() + entry.fromAddend;
+			toAddr = entry.toTarget->finalAddress() + entry.toAddend;
+			sreloc1->set_r_scattered(true);
+			sreloc1->set_r_pcrel(false);
+			sreloc1->set_r_length(2);
+			sreloc1->set_r_type(PPC_RELOC_HA16_SECTDIFF);
+			sreloc1->set_r_address(address);
+			sreloc1->set_r_value(entry.toTarget->finalAddress());
+			sreloc2->set_r_scattered(true);
+			sreloc2->set_r_pcrel(false);
+			sreloc2->set_r_length(2);
+			sreloc2->set_r_type(PPC_RELOC_PAIR);
+			sreloc2->set_r_address((toAddr-fromAddr) & 0xFFFF);
+			sreloc2->set_r_value(fromAddr);
+			relocs.push_back(reloc1);
+			relocs.push_back(reloc2);
+			break;
+
+		default:
+			assert(0 && "need to handle -r reloc");
+
+	}
+}
+#endif
 
 template <typename A>
 void SectionRelocationsAtom<A>::addSectionReloc(ld::Internal::FinalSection*	sect, ld::Fixup::Kind kind, 
diff --git a/src/ld/Options.cpp b/src/ld/Options.cpp
index 057fad9..948a067 100644
--- a/src/ld/Options.cpp
+++ b/src/ld/Options.cpp
@@ -561,8 +561,31 @@ void Options::setArchitecture(cpu_type_t type, cpu_subtype_t subtype)
 				#endif		
 					}
 					break;
+#if SUPPORT_ARCH_ppc
+				case CPU_TYPE_POWERPC:
+#endif
+#if SUPPORT_ARCH_ppc64
+				case CPU_TYPE_POWERPC64:
+#endif
+#if SUPPORT_ARCH_ppc || SUPPORT_ARCH_ppc64
+					if ( (fMacVersionMin == ld::macVersionUnset) && (fIOSVersionMin == ld::iOSVersionUnset) && (fOutputKind != Options::kObjectFile) ) {
+				#ifdef DEFAULT_MACOSX_MIN_VERSION
+						warning("-macosx_version_min not specified, assuming " DEFAULT_MACOSX_MIN_VERSION);
+						setMacOSXVersionMin(DEFAULT_MACOSX_MIN_VERSION);
+				#else
+						warning("-macosx_version_min not specified, assuming 10.5");
+						fMacVersionMin = ld::mac10_5;
+				#endif
+					}
+					break;
+#endif
+#if SUPPORT_ARCH_arm_any
 				case CPU_TYPE_ARM:
+#endif
+#if SUPPORT_ARCH_arm64
 				case CPU_TYPE_ARM64:
+#endif
+#if SUPPORT_ARCH_arm_any || SUPPORT_ARCH_arm64
 					if ( (fMacVersionMin == ld::macVersionUnset) && (fIOSVersionMin == ld::iOSVersionUnset) && (fOutputKind != Options::kObjectFile) ) {
 				#if defined(DEFAULT_IPHONEOS_MIN_VERSION)
 						warning("-ios_version_min not specified, assuming " DEFAULT_IPHONEOS_MIN_VERSION);
@@ -573,6 +596,7 @@ void Options::setArchitecture(cpu_type_t type, cpu_subtype_t subtype)
 				#endif
 					}
 					break;
+#endif
 			}
 			fLinkSnapshot.recordArch(fArchitectureName);
 			// only use compressed LINKEDIT for:
@@ -1623,9 +1647,19 @@ void Options::parseOrderFile(const char* path, bool cstring)
 				}
 				// if there is an architecture prefix, only use this symbol it if matches current arch
 				if ( strncmp(symbolStart, "ppc:", 4) == 0 ) {
+#if SUPPORT_ARCH_ppc
+					if ( fArchitecture == CPU_TYPE_POWERPC )
+						symbolStart = &symbolStart[4];
+					else
+#endif
 					symbolStart = NULL;
 				}
 				else if ( strncmp(symbolStart, "ppc64:", 6) == 0 ) {
+#if SUPPORT_ARCH_ppc64
+					if ( fArchitecture == CPU_TYPE_POWERPC64 )
+						symbolStart = &symbolStart[6];
+					else
+#endif
 					symbolStart = NULL;
 				}
 				else if ( strncmp(symbolStart, "i386:", 5) == 0 ) {
@@ -1641,9 +1675,11 @@ void Options::parseOrderFile(const char* path, bool cstring)
 						symbolStart = NULL;
 				}
 				else if ( strncmp(symbolStart, "arm:", 4) == 0 ) {
+#if SUPPORT_ARCH_arm_any
 					if ( fArchitecture == CPU_TYPE_ARM )
 						symbolStart = &symbolStart[4];
 					else
+#endif
 						symbolStart = NULL;
 				}
 				if ( symbolStart != NULL ) {
@@ -3387,6 +3423,25 @@ void Options::reconfigureDefaults()
 			#endif		
 					}
 					break;
+#if SUPPORT_ARCH_ppc
+				case CPU_TYPE_POWERPC:
+#endif
+#if SUPPORT_ARCH_ppc64
+				case CPU_TYPE_POWERPC64:
+#endif
+#if SUPPORT_ARCH_ppc || SUPPORT_ARCH_ppc64
+					if ( (fOutputKind != Options::kObjectFile) && (fOutputKind != Options::kPreload) ) {
+			#ifdef DEFAULT_MACOSX_MIN_VERSION
+						warning("-macosx_version_min not specificed, assuming " DEFAULT_MACOSX_MIN_VERSION);
+						setMacOSXVersionMin(DEFAULT_MACOSX_MIN_VERSION);
+			#else
+						warning("-macosx_version_min not specificed, assuming 10.5");
+						fMacVersionMin = ld::mac10_5;
+			#endif
+					}
+					break;
+#endif
+#if SUPPORT_ARCH_arm_any
 				case CPU_TYPE_ARM:
 					if ( (fOutputKind != Options::kObjectFile) && (fOutputKind != Options::kPreload) ) {
 			#if defined(DEFAULT_IPHONEOS_MIN_VERSION)
@@ -3398,6 +3453,7 @@ void Options::reconfigureDefaults()
 			#endif
 					}
 					break;
+#endif
 				default:
 					// architecture will be infered later by examining .o files
 					break;
@@ -3414,18 +3470,41 @@ void Options::reconfigureDefaults()
 				fMacVersionMin = ld::mac10_4;
 			}
 			break;
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			/* no OS X for PPC later than 10.5 */
+			if ( fMacVersionMin > ld::mac10_5 ) {
+				//warning("-macosx_version_min should be 10.5 or earlier for ppc");
+				fMacVersionMin = ld::mac10_5;
+			}
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			if ( fMacVersionMin < ld::mac10_4 ) {
+				//warning("-macosx_version_min should be 10.4 or later for ppc64");
+				fMacVersionMin = ld::mac10_4;
+			}
+			if ( fMacVersionMin > ld::mac10_5 ) {
+				//warning("-macosx_version_min should be 10.5 or earlier for ppc64");
+				fMacVersionMin = ld::mac10_5;
+			}
+			break;
+#endif
 		case CPU_TYPE_X86_64:
 			if ( (fMacVersionMin < ld::mac10_4) && (fIOSVersionMin == ld::iOSVersionUnset) ) {
 				//warning("-macosx_version_min should be 10.4 or later for x86_64");
 				fMacVersionMin = ld::mac10_4;
 			}
 			break;
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:
 			if ( fIOSVersionMin < ld::iOS_7_0 ) {
 				//warning("-mios_version_min should be 7.0 or later for arm64");
 				fIOSVersionMin = ld::iOS_7_0;
 			}
 			break;
+#endif
 	}
 	
 	// default to adding functions start for dynamic code, static code must opt-in
@@ -3465,6 +3544,7 @@ void Options::reconfigureDefaults()
 				fAllowTextRelocs = true;
 				fUndefinedTreatment = kUndefinedDynamicLookup;
 				break;
+#if SUPPORT_ARCH_arm64
 			case CPU_TYPE_ARM64:
 				// arm64 uses new MH_KEXT_BUNDLE type
 				fMakeCompressedDyldInfo = false;
@@ -3473,6 +3553,8 @@ void Options::reconfigureDefaults()
 				fKextsUseStubs = true;
 				fUndefinedTreatment = kUndefinedDynamicLookup;
 				break;
+#endif
+#if SUPPORT_ARCH_arm_any
 			case CPU_TYPE_ARM:
 				if ( fIOSVersionMin >= ld::iOS_5_0 ) {
                     // iOS 5.0 and later use new MH_KEXT_BUNDLE type
@@ -3485,6 +3567,10 @@ void Options::reconfigureDefaults()
 					break;
 				}
 				// else use object file
+#endif
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+#endif
 			case CPU_TYPE_I386:
 				// use .o files
 				fOutputKind = kObjectFile;
@@ -3527,8 +3613,11 @@ void Options::reconfigureDefaults()
 	
 	// split segs only allowed for dylibs
 	if ( fSplitSegs ) {
-        // split seg only supported for i386, and arm.
+        // split seg only supported for ppc, i386, and arm.
         switch ( fArchitecture ) {
+#if SUPPORT_ARCH_ppc
+            case CPU_TYPE_POWERPC:
+#endif
             case CPU_TYPE_I386:
                 if ( fOutputKind != Options::kDynamicLibrary )
                     fSplitSegs = false;
@@ -3536,6 +3625,7 @@ void Options::reconfigureDefaults()
                 if ( fSplitSegs && (fBaseWritableAddress-fBaseAddress != 0x10000000) )
                     fBaseWritableAddress = fBaseAddress + 0x10000000;
                 break;
+#if SUPPORT_ARCH_arm_any
             case CPU_TYPE_ARM:
                 if ( fOutputKind != Options::kDynamicLibrary ) {
                     fSplitSegs = false;
@@ -3546,6 +3636,7 @@ void Options::reconfigureDefaults()
 						fBaseWritableAddress = fBaseAddress + 0x08000000;
 				}
                 break;
+#endif
             default:
                 fSplitSegs = false;
                 fBaseAddress = 0;
@@ -3555,11 +3646,18 @@ void Options::reconfigureDefaults()
 
 	// set too-large size
 	switch ( fArchitecture ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+#endif
 		case CPU_TYPE_I386:
 			fMaxAddress = 0xFFFFFFFF;
 			break;
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+#endif
 		case CPU_TYPE_X86_64:
 			break;
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			switch ( fOutputKind ) {
 				case Options::kDynamicExecutable:
@@ -3582,6 +3680,7 @@ void Options::reconfigureDefaults()
 				fBaseAddress = 0;
 			}
 			break;
+#endif
 	}
 
 	// <rdar://problem/6138961> -r implies no prebinding for all architectures
@@ -3591,6 +3690,9 @@ void Options::reconfigureDefaults()
 	// disable prebinding depending on arch and min OS version
 	if ( fPrebind ) {
 		switch ( fArchitecture ) {
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+#endif
 			case CPU_TYPE_I386:
 				if ( fMacVersionMin == ld::mac10_4 ) {
 					// in 10.4 only split seg dylibs are prebound
@@ -3624,9 +3726,13 @@ void Options::reconfigureDefaults()
 					}
 				}
 				break;
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+#endif
 			case CPU_TYPE_X86_64:
 				fPrebind = false;
 				break;
+#if SUPPORT_ARCH_arm_any
             case CPU_TYPE_ARM:
 				switch ( fOutputKind ) {
 					case Options::kDynamicExecutable:
@@ -3644,6 +3750,7 @@ void Options::reconfigureDefaults()
 						break;
 				}
 				break;
+#endif
 		}
 	}
 
@@ -3670,10 +3777,18 @@ void Options::reconfigureDefaults()
 			case CPU_TYPE_I386:
 				if ( fIOSVersionMin != ld::iOSVersionUnset ) // simulator never needs modules
 					break;
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:	// 10.3 and earlier dyld requires a module table
+				if ( fMacVersionMin <= ld::mac10_5 )
+					fNeedsModuleTable = true;
+				break;
+#endif
+#if SUPPORT_ARCH_arm_any
 			case CPU_TYPE_ARM:
 				if ( fPrebind )
 					fNeedsModuleTable = true; // redo_prebinding requires a module table
 				break;
+#endif
 		}
 	}
 	
@@ -3689,7 +3804,9 @@ void Options::reconfigureDefaults()
 	switch ( fArchitecture ) {
 		case CPU_TYPE_I386:		
 		case CPU_TYPE_X86_64:		
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:		
+#endif
 			switch ( fOutputKind ) {
 				case Options::kObjectFile:
 				case Options::kStaticExecutable:
@@ -3706,10 +3823,20 @@ void Options::reconfigureDefaults()
 					break;
 			}
 			break;
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+#endif
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
+#endif
+#if SUPPORT_ARCH_ppc || SUPPORT_ARCH_ppc64 || SUPPORT_ARCH_arm_any
 			fAddCompactUnwindEncoding = false;
 			fRemoveDwarfUnwindIfCompactExists = false;
 			break;
+#endif
 		case 0:
 			// if -arch is missing, assume we don't want compact unwind info
 			fAddCompactUnwindEncoding = false;
@@ -3719,7 +3846,16 @@ void Options::reconfigureDefaults()
 	// only iOS main executables should be encrypted
 	if ( fOutputKind != Options::kDynamicExecutable )
 		fEncryptable = false;
-	if ( (fArchitecture != CPU_TYPE_ARM) && (fArchitecture != CPU_TYPE_ARM64) )
+#if SUPPORT_ARCH_arm_any || SUPPORT_ARCH_arm64
+	if ( 1
+#if SUPPORT_ARCH_arm_any
+		&& (fArchitecture != CPU_TYPE_ARM)
+#endif
+#if SUPPORT_ARCH_arm64
+		&& (fArchitecture != CPU_TYPE_ARM64)
+#endif
+		)
+#endif
 		fEncryptable = false;
 
 	// don't move inits in dyld because dyld wants certain
@@ -3771,15 +3907,24 @@ void Options::reconfigureDefaults()
 
 	// only ARM and x86_64 enforces that cpu-sub-types must match
 	switch ( fArchitecture ) {
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
+#endif
 		case CPU_TYPE_X86_64:
 			break;
 		case CPU_TYPE_I386:
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:
+#endif
 			fAllowCpuSubtypeMismatches = true;
 			break;
 	}
 		
+#if SUPPORT_ARCH_arm_any
+	// only ARM enforces that cpu-sub-types must match
+	if ( fArchitecture != CPU_TYPE_ARM )
+#endif
+		fAllowCpuSubtypeMismatches = true;
 		
 	// only final linked images can not optimize zero fill sections
 	if ( fOutputKind == Options::kObjectFile )
@@ -3821,6 +3966,7 @@ void Options::reconfigureDefaults()
 			fPositionIndependentExecutable = true;
 	}
 
+#if SUPPORT_ARCH_arm_any
 	// armv7 for iOS4.3 defaults to PIE
 	if ( (fArchitecture == CPU_TYPE_ARM) 
 		&& fArchSupportsThumb2
@@ -3828,15 +3974,18 @@ void Options::reconfigureDefaults()
 		&& (fIOSVersionMin >= ld::iOS_4_3) ) {
 			fPositionIndependentExecutable = true;
 	}
+#endif
 
 	// -no_pie anywhere on command line disable PIE
 	if ( fDisablePositionIndependentExecutable )
 		fPositionIndependentExecutable = false;
 
+#if SUPPORT_ARCH_arm64
 	// arm64 is always PIE
 	if ( (fArchitecture == CPU_TYPE_ARM64) && (fOutputKind == kDynamicExecutable) ) {
 		fPositionIndependentExecutable = true;
 	}
+#endif
 
 	// set fOutputSlidable
 	switch ( fOutputKind ) {
@@ -4052,6 +4201,7 @@ void Options::reconfigureDefaults()
 		}
 	}
   
+#if SUPPORT_ARCH_arm64
 	// <rdar://problem/12258065> ARM64 needs 16KB page size for user land code
 	if ( fArchitecture == CPU_TYPE_ARM64 ) {
 		if ( fSegmentAlignment == 4096 ) {
@@ -4070,6 +4220,7 @@ void Options::reconfigureDefaults()
 			}
 		}
 	}
+#endif
 	
 	// <rdar://problem/13624134> linker should not convert dwarf unwind if .o file has compact unwind section
 	switch ( fOutputKind ) {
@@ -4167,12 +4318,22 @@ void Options::checkIllegalOptionCombinations()
 	if ( fStackAddr != 0 ) {
 		switch (fArchitecture) {
 			case CPU_TYPE_I386:
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+#endif
+#if SUPPORT_ARCH_arm_any
             case CPU_TYPE_ARM:
+#endif
 				if ( fStackAddr > 0xFFFFFFFF )
 					throw "-stack_addr must be < 4G for 32-bit processes";
 				break;
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+#endif
 			case CPU_TYPE_X86_64:
+#if SUPPORT_ARCH_arm64
 			case CPU_TYPE_ARM64:
+#endif
 				break;
 		}
 		if ( (fStackAddr & -4096) != fStackAddr )
@@ -4185,6 +4346,9 @@ void Options::checkIllegalOptionCombinations()
 	if ( fStackSize != 0 ) {
 		switch (fArchitecture) {
 			case CPU_TYPE_I386:
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+#endif
 				if ( fStackSize > 0xFFFFFFFF )
 					throw "-stack_size must be < 4G for 32-bit processes";
 				if ( fStackAddr == 0 ) {
@@ -4193,6 +4357,7 @@ void Options::checkIllegalOptionCombinations()
 				if ( (fStackAddr > 0xB0000000) && ((fStackAddr-fStackSize) < 0xB0000000)  )
 					warning("custom stack placement overlaps and will disable shared region");
 				break;
+#if SUPPORT_ARCH_arm_any
             case CPU_TYPE_ARM:
 				if ( fStackSize > 0x2F000000 )
 					throw "-stack_size must be < 752MB";
@@ -4201,11 +4366,16 @@ void Options::checkIllegalOptionCombinations()
                 if ( fStackAddr > 0x30000000)
                     throw "-stack_addr must be < 0x30000000 for arm";
 				break;
+#endif
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+#endif
 			case CPU_TYPE_X86_64:
 				if ( fStackAddr == 0 ) {
 					fStackAddr = 0x00007FFF5C000000LL;
 				}
 				break;
+#if SUPPORT_ARCH_arm64
 			case CPU_TYPE_ARM64:
 				if ( fStackSize > 0x20000000 )
 					throw "-stack_size must be < 512MB";
@@ -4213,6 +4383,7 @@ void Options::checkIllegalOptionCombinations()
 					fStackAddr = 0x120000000;
 				}
 				break;
+#endif
 		}
 		if ( (fStackSize & -4096) != fStackSize )
 			throw "-stack_size must be multiples of 4K";
@@ -4321,9 +4492,16 @@ void Options::checkIllegalOptionCombinations()
 			if ( fObjCABIVersion2Override )
 				alterObjC1ClassNamesToObjC2 = true;
 			break;
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+#endif
 		case CPU_TYPE_X86_64:
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
+#endif
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:
+#endif
 			alterObjC1ClassNamesToObjC2 = true;
 			break;
 	}
@@ -4415,11 +4593,27 @@ void Options::checkIllegalOptionCombinations()
 		// zero page size not specified on command line, set default
 		switch (fArchitecture) {
 			case CPU_TYPE_I386:
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+#endif
+#if SUPPORT_ARCH_arm_any
             case CPU_TYPE_ARM:
+#endif
 				// first 4KB for 32-bit architectures
 				fZeroPageSize = 0x1000;
 				break;
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+				// first 4GB for ppc64 on 10.5
+				if ( fMacVersionMin >= ld::mac10_5 )
+					fZeroPageSize = 0x100000000ULL;
+				else
+					fZeroPageSize = 0x1000;	// 10.4 dyld may not be able to handle >4GB zero page
+				break;
+#endif
+#if SUPPORT_ARCH_arm64
 			case CPU_TYPE_ARM64:
+#endif
 			case CPU_TYPE_X86_64:
 				// first 4GB for x86_64 on all OS's
 				fZeroPageSize = 0x100000000ULL;
@@ -4521,9 +4715,11 @@ void Options::checkIllegalOptionCombinations()
 	
 	// -force_cpusubtype_ALL is not supported for ARM
 	if ( fForceSubtypeAll ) {
+#if SUPPORT_ARCH_arm_any
 		if ( fArchitecture == CPU_TYPE_ARM ) {
 			warning("-force_cpusubtype_ALL will become unsupported for ARM architectures");
 		}
+#endif
 	}
 	
 	// -reexported_symbols_list can only be used with -dynamiclib
diff --git a/src/ld/OutputFile.cpp b/src/ld/OutputFile.cpp
index c7a0918..09e2933 100644
--- a/src/ld/OutputFile.cpp
+++ b/src/ld/OutputFile.cpp
@@ -454,6 +454,7 @@ static const char* referenceTargetAtomName(ld::Internal& state, const ld::Fixup*
 	return "BAD BINDING";
 }
 
+#if SUPPORT_ARCH_arm_any
 bool OutputFile::targetIsThumb(ld::Internal& state, const ld::Fixup* fixup)
 {
 	switch ( fixup->binding ) {
@@ -467,6 +468,7 @@ bool OutputFile::targetIsThumb(ld::Internal& state, const ld::Fixup* fixup)
 	}
 	throw "unexpected binding";
 }
+#endif
 
 uint64_t OutputFile::addressOf(const ld::Internal& state, const ld::Fixup* fixup, const ld::Atom** target)
 {
@@ -623,7 +625,11 @@ void OutputFile::rangeCheckAbsolute32(int64_t displacement, ld::Internal& state,
 		// is encoded in mach-o the same as:
 		//  .long _foo + 0x40000000
 		// so if _foo lays out to 0xC0000100, the first is ok, but the second is not.  
-		if ( (_options.architecture() == CPU_TYPE_ARM) || (_options.architecture() == CPU_TYPE_I386) ) {
+		if (0
+#if SUPPORT_ARCH_arm_any
+			|| (_options.architecture() == CPU_TYPE_ARM)
+#endif
+			|| (_options.architecture() == CPU_TYPE_I386) ) {
 			// Unlikely userland code does funky stuff like this, so warn for them, but not warn for -preload or -static
 			if ( (_options.outputKind() != Options::kPreload) && (_options.outputKind() != Options::kStaticExecutable) ) {
 				warning("32-bit absolute address out of range (0x%08llX max is 4GB): from %s + 0x%08X (0x%08llX) to 0x%08llX", 
@@ -660,6 +666,7 @@ void OutputFile::rangeCheckRIP32(int64_t displacement, ld::Internal& state, cons
 	}
 }
 
+#if SUPPORT_ARCH_arm_any
 void OutputFile::rangeCheckARM12(int64_t displacement, ld::Internal& state, const ld::Atom* atom, const ld::Fixup* fixup)
 {
 	if ( (displacement > 4092LL) || (displacement < (-4092LL)) ) {
@@ -729,8 +736,39 @@ void OutputFile::rangeCheckThumbBranch22(int64_t displacement, ld::Internal& sta
 				addressOf(state, fixup, &target));
 	}
 }
+#endif
+
+#if SUPPORT_ARCH_ppc
+void OutputFile::rangeCheckPPCBranch24(int64_t displacement, ld::Internal& state, const ld::Atom* atom, const ld::Fixup* fixup)
+{
+	const int64_t bl_eightMegLimit = 0x00FFFFFF;
+	if ( (displacement > bl_eightMegLimit) || (displacement < (-bl_eightMegLimit)) ) {
+		// show layout of final image
+		printSectionLayout(state);
 
+		const ld::Atom* target;
+		throwf("bl PPC branch out of range (%lld max is +/-16MB): from %s (0x%08llX) to %s (0x%08llX)",
+				displacement, atom->name(), atom->finalAddress(), referenceTargetAtomName(state, fixup),
+				addressOf(state, fixup, &target));
+	}
+}
 
+void OutputFile::rangeCheckPPCBranch14(int64_t displacement, ld::Internal& state, const ld::Atom* atom, const ld::Fixup* fixup)
+{
+	const int64_t b_sixtyFourKiloLimit = 0x0000FFFF;
+	if ( (displacement > b_sixtyFourKiloLimit) || (displacement < (-b_sixtyFourKiloLimit)) ) {
+		// show layout of final image
+		printSectionLayout(state);
+
+		const ld::Atom* target;
+		throwf("bcc PPC branch out of range (%lld max is +/-64KB): from %s (0x%08llX) to %s (0x%08llX)",
+				displacement, atom->name(), atom->finalAddress(), referenceTargetAtomName(state, fixup),
+				addressOf(state, fixup, &target));
+	}
+}
+#endif
+
+#if SUPPORT_ARCH_arm64
 void OutputFile::rangeCheckARM64Branch26(int64_t displacement, ld::Internal& state, const ld::Atom* atom, const ld::Fixup* fixup)
 {
 	const int64_t bl_128MegLimit = 0x07FFFFFF;
@@ -758,6 +796,7 @@ void OutputFile::rangeCheckARM64Page21(int64_t displacement, ld::Internal& state
 				addressOf(state, fixup, &target));
 	}
 }
+#endif
 
 
 uint16_t OutputFile::get16LE(uint8_t* loc) { return LittleEndian::get16(*(uint16_t*)loc); }
@@ -778,6 +817,7 @@ void     OutputFile::set32BE(uint8_t* loc, uint32_t value) { BigEndian::set32(*(
 uint64_t OutputFile::get64BE(uint8_t* loc) { return BigEndian::get64(*(uint64_t*)loc); }
 void     OutputFile::set64BE(uint8_t* loc, uint64_t value) { BigEndian::set64(*(uint64_t*)loc, value); }
 
+#if SUPPORT_ARCH_arm64
 static uint32_t makeNOP() {
 	return 0xD503201F;
 }
@@ -1187,6 +1227,7 @@ static bool withinOneMeg(uint64_t addr1, uint64_t addr2) {
 	int64_t delta = (addr2 - addr1);
 	return ( (delta < 1024*1024) && (delta > -1024*1024) );
 }
+#endif
 
 void OutputFile::setInfo(ld::Internal& state, const ld::Atom* atom, uint8_t* buffer, const std::map<uint32_t, const Fixup*>& usedByHints, 
 						uint32_t offsetInAtom, uint32_t delta, InstructionInfo* info) 
@@ -1217,6 +1258,7 @@ void OutputFile::setInfo(ld::Internal& state, const ld::Atom* atom, uint8_t* buf
 	info->instruction = get32LE(info->instructionContent);
 }	
 
+#if SUPPORT_ARCH_arm64
 static bool isPageKind(const ld::Fixup* fixup, bool mustBeGOT=false)
 {
 	if ( fixup == NULL )
@@ -1280,6 +1322,7 @@ static bool isPageOffsetKind(const ld::Fixup* fixup, bool mustBeGOT=false)
 	}
 	return false;
 }
+#endif
 
 
 #define LOH_ASSERT(cond) \
@@ -1298,14 +1341,19 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 	int64_t delta;
 	uint32_t instruction;
 	uint32_t newInstruction;
+	uint16_t instructionLowHalf;
 	bool is_bl;
 	bool is_blx;
 	bool is_b;
+#if SUPPORT_ARCH_arm_any
 	bool thumbTarget = false;
+#endif
 	std::map<uint32_t, const Fixup*> usedByHints;
 	for (ld::Fixup::iterator fit = atom->fixupsBegin(), end=atom->fixupsEnd(); fit != end; ++fit) {
 		uint8_t* fixUpLocation = &buffer[fit->offsetInAtom];
+#if SUPPORT_ARCH_arm64
 		ld::Fixup::LOH_arm64 lohExtra;
+#endif
 		switch ( (ld::Fixup::Kind)(fit->kind) ) { 
 			case ld::Fixup::kindNone:
 			case ld::Fixup::kindNoneFollowOn:
@@ -1316,9 +1364,11 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				break;
 			case ld::Fixup::kindSetTargetAddress:
 				accumulator = addressOf(state, fit, &toTarget);			
+#if SUPPORT_ARCH_arm_any
 				thumbTarget = targetIsThumb(state, fit);
 				if ( thumbTarget ) 
 					accumulator |= 1;
+#endif
 				if ( fit->contentAddendOnly || fit->contentDetlaToAddendOnly )
 					accumulator = 0;
 				break;
@@ -1329,6 +1379,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				break;
 			case ld::Fixup::kindAddAddend:
 				if ( ! fit->contentIgnoresAddend ) {
+#if SUPPORT_ARCH_arm_any
 					// <rdar://problem/8342028> ARM main executables main contain .long constants pointing
 					// into themselves such as jump tables.  These .long should not have thumb bit set
 					// even though the target is a thumb instruction. We can tell it is an interior pointer
@@ -1338,6 +1389,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 						//warning("removing thumb bit from intra-atom pointer in %s %s+0x%0X", 
 						//		atom->section().sectionName(), atom->name(), fit->offsetInAtom);
 					}
+#endif
 					accumulator += fit->u.addend;
 				}
 				break;
@@ -1473,6 +1525,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				rangeCheckRIP32(delta, state, atom, fit);
 				set32LE(fixUpLocation, delta);
 				break;
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreTargetAddressARMLoad12:
 				accumulator = addressOf(state, fit, &toTarget);
 				// fall into kindStoreARMLoad12 case
@@ -1490,6 +1543,44 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				}
 				set32LE(fixUpLocation, newInstruction);
 				break;
+#endif
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStorePPCBranch14:
+				delta = accumulator - (atom->finalAddress() + fit->offsetInAtom);
+				rangeCheckPPCBranch14(delta, state, atom, fit);
+				instruction = get32BE(fixUpLocation);
+				newInstruction = (instruction & 0xFFFF0003) | ((uint32_t)delta & 0x0000FFFC);
+				set32BE(fixUpLocation, newInstruction);
+				break;
+			case ld::Fixup::kindStorePPCPicLow14:
+			case ld::Fixup::kindStorePPCAbsLow14:
+				instruction = get32BE(fixUpLocation);
+				if ( (accumulator & 0x3) != 0 )
+					throwf("bad offset (0x%08X) for lo14 instruction pic-base fix-up", (uint32_t)accumulator);
+				newInstruction = (instruction & 0xFFFF0003) | (accumulator & 0xFFFC);
+				set32BE(fixUpLocation, newInstruction);
+				break;
+			case ld::Fixup::kindStorePPCAbsLow16:
+			case ld::Fixup::kindStorePPCPicLow16:
+				instruction = get32BE(fixUpLocation);
+				newInstruction = (instruction & 0xFFFF0000) | (accumulator & 0xFFFF);
+				set32BE(fixUpLocation, newInstruction);
+				break;
+			case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+			case ld::Fixup::kindStorePPCPicHigh16AddLow:
+				instructionLowHalf = (accumulator >> 16) & 0xFFFF;
+				if ( accumulator & 0x00008000 )
+					++instructionLowHalf;
+				instruction = get32BE(fixUpLocation);
+				newInstruction = (instruction & 0xFFFF0000) | instructionLowHalf;
+				set32BE(fixUpLocation, newInstruction);
+				break;
+			case ld::Fixup::kindStorePPCAbsHigh16:
+				instruction = get32BE(fixUpLocation);
+				newInstruction = (instruction & 0xFFFF0000) | ((accumulator >> 16) & 0xFFFF);
+				set32BE(fixUpLocation, newInstruction);
+				break;
+#endif
 			case ld::Fixup::kindDtraceExtra:
 				break;
 			case ld::Fixup::kindStoreX86DtraceCallSiteNop:
@@ -1512,6 +1603,21 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 					fixUpLocation[3] = 0x90;		// 1-byte nop
 				}
 				break;
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+				if ( _options.outputKind() != Options::kObjectFile ) {
+					// change call site to a NOP
+					set32BE(fixUpLocation, 0x60000000);
+				}
+				break;
+			case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+				if ( _options.outputKind() != Options::kObjectFile ) {
+					// change call site to a li r3,0
+					set32BE(fixUpLocation, 0x38600000);
+				}
+				break;
+#endif
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreARMDtraceCallSiteNop:
 				if ( _options.outputKind() != Options::kObjectFile ) {
 					// change call site to a NOP
@@ -1536,6 +1642,8 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 					set32LE(fixUpLocation, 0x46C04040);
 				}
 				break;
+#endif
+#if SUPPORT_ARCH_arm64
 			case ld::Fixup::kindStoreARM64DtraceCallSiteNop:
 				if ( _options.outputKind() != Options::kObjectFile ) {
 					// change call site to a NOP
@@ -1548,6 +1656,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 					set32LE(fixUpLocation, 0xD2800000);
 				}
 				break;
+#endif
 			case ld::Fixup::kindLazyTarget:
 			case ld::Fixup::kindIslandTarget:
 				break;
@@ -1563,6 +1672,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 			case ld::Fixup::kindDataInCodeEnd:
 				break;
 			case ld::Fixup::kindLinkerOptimizationHint:
+#if SUPPORT_ARCH_arm64
 				// expand table of address/offsets used by hints
 				lohExtra.addend = fit->u.addend;
 				usedByHints[fit->offsetInAtom + (lohExtra.info.delta1 << 2)] = NULL;
@@ -1572,12 +1682,15 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 					usedByHints[fit->offsetInAtom + (lohExtra.info.delta3 << 2)] = NULL;
 				if ( lohExtra.info.count > 2 )
 					usedByHints[fit->offsetInAtom + (lohExtra.info.delta4 << 2)] = NULL;
+#endif
 				break;
 			case ld::Fixup::kindStoreTargetAddressLittleEndian32:
 				accumulator = addressOf(state, fit, &toTarget);
+#if SUPPORT_ARCH_arm_any
 				thumbTarget = targetIsThumb(state, fit);
 				if ( thumbTarget ) 
 					accumulator |= 1;
+#endif
 				if ( fit->contentAddendOnly )
 					accumulator = 0;
 				rangeCheckAbsolute32(accumulator, state, atom, fit);
@@ -1654,6 +1767,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				rangeCheckRIP32(delta, state, atom, fit);
 				set32LE(fixUpLocation, delta);
 				break;
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreTargetAddressARMBranch24:
 				accumulator = addressOf(state, fit, &toTarget);
 				thumbTarget = targetIsThumb(state, fit);
@@ -1868,6 +1982,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 					set32LE(fixUpLocation, newInstruction);		
 				}
 				break;
+#endif
 #if SUPPORT_ARCH_arm64
 			case ld::Fixup::kindStoreTargetAddressARM64Branch26:
 				accumulator = addressOf(state, fit, &toTarget);
@@ -2007,9 +2122,24 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 				set32LE(fixUpLocation, delta);
 				break;
 #endif
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+				accumulator = addressOf(state, fit, &toTarget);
+				if ( fit->contentDetlaToAddendOnly )
+					accumulator = 0;
+				// fall into kindStorePPCBranch24 case
+			case ld::Fixup::kindStorePPCBranch24:
+				delta = accumulator - (atom->finalAddress() + fit->offsetInAtom);
+				rangeCheckPPCBranch24(delta, state, atom, fit);
+				instruction = get32BE(fixUpLocation);
+				newInstruction = (instruction & 0xFC000003) | ((uint32_t)delta & 0x03FFFFFC);
+				set32BE(fixUpLocation, newInstruction);
+				break;
+#endif
 		}
 	}
 	
+#if SUPPORT_ARCH_arm64
 	// after all fixups are done on atom, if there are potential optimizations, do those
 	if ( (usedByHints.size() != 0) && (_options.outputKind() != Options::kObjectFile) && !_options.ignoreOptimizationHints() ) {
 		// fill in second part of usedByHints map, so we can see the target of fixups that might be optimized
@@ -2449,6 +2579,7 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 			}				
 		}
 	}
+#endif
 
 
 	
@@ -2458,11 +2589,18 @@ void OutputFile::applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::
 void OutputFile::copyNoOps(uint8_t* from, uint8_t* to, bool thumb)
 {
 	switch ( _options.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			for (uint8_t* p=from; p < to; p += 4)
+				OSWriteBigInt32((uint32_t*)p, 0, 0x60000000);
+			break;
+#endif
 		case CPU_TYPE_I386:
 		case CPU_TYPE_X86_64:
 			for (uint8_t* p=from; p < to; ++p)
 				*p = 0x90;
 			break;
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			if ( thumb ) {
 				for (uint8_t* p=from; p < to; p += 2)
@@ -2473,6 +2611,7 @@ void OutputFile::copyNoOps(uint8_t* from, uint8_t* to, bool thumb)
 					OSWriteLittleInt32((uint32_t*)p, 0, 0xe1a00000);
 			}
 			break;
+#endif
 		default:
 			for (uint8_t* p=from; p < to; ++p)
 				*p = 0x00;
@@ -2545,7 +2684,9 @@ void OutputFile::writeAtoms(ld::Internal& state, uint8_t* wholeBuffer)
 				this->applyFixUps(state, mhAddress, atom, &wholeBuffer[fileOffset]);
 				fileOffsetOfEndOfLastAtom = fileOffset+atom->size();
 				lastAtomUsesNoOps = sectionUsesNops;
+#if SUPPORT_ARCH_arm_any
 				lastAtomWasThumb = atom->isThumb();
+#endif
 			}
 			catch (const char* msg) {
 				if ( atom->file() != NULL )
@@ -2801,7 +2942,12 @@ void OutputFile::buildSymbolTable(ld::Internal& state)
 				
 			// in -r mode, clarify symbolTableNotInFinalLinkedImages
 			if ( _options.outputKind() == Options::kObjectFile ) {
-				if ( (_options.architecture() == CPU_TYPE_X86_64) || (_options.architecture() == CPU_TYPE_ARM64) ) {
+				if ( 0
+					|| (_options.architecture() == CPU_TYPE_X86_64)
+#if SUPPORT_ARCH_arm64
+					|| (_options.architecture() == CPU_TYPE_ARM64)
+#endif
+					) {
 					// x86_64 .o files need labels on anonymous literal strings
 					if ( (sect->type() == ld::Section::typeCString) && (atom->combine() == ld::Atom::combineByNameAndContent) ) {
 						(const_cast<ld::Atom*>(atom))->setSymbolTableInclusion(ld::Atom::symbolTableIn);
@@ -3046,6 +3192,68 @@ void OutputFile::addLinkEdit(ld::Internal& state)
 		return addPreloadLinkEdit(state);
 	
 	switch ( _options.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			if ( _hasSectionRelocations ) {
+				_sectionsRelocationsAtom = new SectionRelocationsAtom<ppc>(_options, state, *this);
+				sectionRelocationsSection = state.addAtom(*_sectionsRelocationsAtom);
+			}
+			if ( _hasDyldInfo ) {
+				_rebasingInfoAtom = new RebaseInfoAtom<ppc>(_options, state, *this);
+				rebaseSection = state.addAtom(*_rebasingInfoAtom);
+
+				_bindingInfoAtom = new BindingInfoAtom<ppc>(_options, state, *this);
+				bindingSection = state.addAtom(*_bindingInfoAtom);
+
+				_weakBindingInfoAtom = new WeakBindingInfoAtom<ppc>(_options, state, *this);
+				weakBindingSection = state.addAtom(*_weakBindingInfoAtom);
+
+				_lazyBindingInfoAtom = new LazyBindingInfoAtom<ppc>(_options, state, *this);
+				lazyBindingSection = state.addAtom(*_lazyBindingInfoAtom);
+
+				_exportInfoAtom = new ExportInfoAtom<ppc>(_options, state, *this);
+				exportSection = state.addAtom(*_exportInfoAtom);
+			}
+			if ( _hasLocalRelocations ) {
+				_localRelocsAtom = new LocalRelocationsAtom<ppc>(_options, state, *this);
+				localRelocationsSection = state.addAtom(*_localRelocsAtom);
+			}
+			if ( _hasSplitSegInfo ) {
+				_splitSegInfoAtom = new SplitSegInfoAtom<ppc>(_options, state, *this);
+				splitSegInfoSection = state.addAtom(*_splitSegInfoAtom);
+			}
+			if ( _hasFunctionStartsInfo ) {
+				_functionStartsAtom = new FunctionStartsAtom<ppc>(_options, state, *this);
+				functionStartsSection = state.addAtom(*_functionStartsAtom);
+			}
+			if ( _hasDataInCodeInfo ) {
+				_dataInCodeAtom = new DataInCodeAtom<ppc>(_options, state, *this);
+				dataInCodeSection = state.addAtom(*_dataInCodeAtom);
+			}
+			if ( _hasOptimizationHints ) {
+				_optimizationHintsAtom = new OptimizationHintsAtom<ppc>(_options, state, *this);
+				optimizationHintsSection = state.addAtom(*_optimizationHintsAtom);
+			}
+			if ( _hasDependentDRInfo ) {
+				_dependentDRInfoAtom = new DependentDRAtom<ppc>(_options, state, *this);
+				dependentDRsSection = state.addAtom(*_dependentDRInfoAtom);
+			}
+			if ( _hasSymbolTable ) {
+				_symbolTableAtom = new SymbolTableAtom<ppc>(_options, state, *this);
+				symbolTableSection = state.addAtom(*_symbolTableAtom);
+			}
+			if ( _hasExternalRelocations ) {
+				_externalRelocsAtom = new ExternalRelocationsAtom<ppc>(_options, state, *this);
+				externalRelocationsSection = state.addAtom(*_externalRelocsAtom);
+			}
+			if ( _hasSymbolTable ) {
+				_indirectSymbolTableAtom = new IndirectSymbolTableAtom<ppc>(_options, state, *this);
+				indirectSymbolTableSection = state.addAtom(*_indirectSymbolTableAtom);
+				_stringPoolAtom = new StringPoolAtom(_options, state, *this, 4);
+				stringPoolSection = state.addAtom(*_stringPoolAtom);
+			}
+			break;
+#endif
 #if SUPPORT_ARCH_i386
 		case CPU_TYPE_I386:
 			if ( _hasSectionRelocations ) {
@@ -3294,6 +3502,68 @@ void OutputFile::addLinkEdit(ld::Internal& state)
 			}
 			break;
 #endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			if ( _hasSectionRelocations ) {
+				_sectionsRelocationsAtom = new SectionRelocationsAtom<ppc64>(_options, state, *this);
+				sectionRelocationsSection = state.addAtom(*_sectionsRelocationsAtom);
+			}
+			if ( _hasDyldInfo ) {
+				_rebasingInfoAtom = new RebaseInfoAtom<ppc64>(_options, state, *this);
+				rebaseSection = state.addAtom(*_rebasingInfoAtom);
+
+				_bindingInfoAtom = new BindingInfoAtom<ppc64>(_options, state, *this);
+				bindingSection = state.addAtom(*_bindingInfoAtom);
+
+				_weakBindingInfoAtom = new WeakBindingInfoAtom<ppc64>(_options, state, *this);
+				weakBindingSection = state.addAtom(*_weakBindingInfoAtom);
+
+				_lazyBindingInfoAtom = new LazyBindingInfoAtom<ppc64>(_options, state, *this);
+				lazyBindingSection = state.addAtom(*_lazyBindingInfoAtom);
+
+				_exportInfoAtom = new ExportInfoAtom<ppc64>(_options, state, *this);
+				exportSection = state.addAtom(*_exportInfoAtom);
+			}
+			if ( _hasLocalRelocations ) {
+				_localRelocsAtom = new LocalRelocationsAtom<ppc64>(_options, state, *this);
+				localRelocationsSection = state.addAtom(*_localRelocsAtom);
+			}
+			if  ( _hasSplitSegInfo ) {
+				_splitSegInfoAtom = new SplitSegInfoAtom<ppc64>(_options, state, *this);
+				splitSegInfoSection = state.addAtom(*_splitSegInfoAtom);
+			}
+			if ( _hasFunctionStartsInfo ) {
+				_functionStartsAtom = new FunctionStartsAtom<ppc64>(_options, state, *this);
+				functionStartsSection = state.addAtom(*_functionStartsAtom);
+			}
+			if ( _hasDataInCodeInfo ) {
+				_dataInCodeAtom = new DataInCodeAtom<ppc64>(_options, state, *this);
+				dataInCodeSection = state.addAtom(*_dataInCodeAtom);
+			}
+			if ( _hasOptimizationHints ) {
+				_optimizationHintsAtom = new OptimizationHintsAtom<ppc64>(_options, state, *this);
+				optimizationHintsSection = state.addAtom(*_optimizationHintsAtom);
+			}
+			if ( _hasDependentDRInfo ) {
+				_dependentDRInfoAtom = new DependentDRAtom<ppc64>(_options, state, *this);
+				dependentDRsSection = state.addAtom(*_dependentDRInfoAtom);
+			}
+			if ( _hasSymbolTable ) {
+				_symbolTableAtom = new SymbolTableAtom<ppc64>(_options, state, *this);
+				symbolTableSection = state.addAtom(*_symbolTableAtom);
+			}
+			if ( _hasExternalRelocations ) {
+				_externalRelocsAtom = new ExternalRelocationsAtom<ppc64>(_options, state, *this);
+				externalRelocationsSection = state.addAtom(*_externalRelocsAtom);
+			}
+			if ( _hasSymbolTable ) {
+				_indirectSymbolTableAtom = new IndirectSymbolTableAtom<ppc64>(_options, state, *this);
+				indirectSymbolTableSection = state.addAtom(*_indirectSymbolTableAtom);
+				_stringPoolAtom = new StringPoolAtom(_options, state, *this, 4);
+				stringPoolSection = state.addAtom(*_stringPoolAtom);
+			}
+			break;
+#endif
 		default:
 			throw "unknown architecture";
 	}
@@ -3326,6 +3596,18 @@ void OutputFile::addLoadCommands(ld::Internal& state)
 			headerAndLoadCommandsSection = state.addAtom(*_headersAndLoadCommandAtom);
 			break;
 #endif
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			_headersAndLoadCommandAtom = new HeaderAndLoadCommandsAtom<ppc>(_options, state, *this);
+			headerAndLoadCommandsSection = state.addAtom(*_headersAndLoadCommandAtom);
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			_headersAndLoadCommandAtom = new HeaderAndLoadCommandsAtom<ppc64>(_options, state, *this);
+			headerAndLoadCommandsSection = state.addAtom(*_headersAndLoadCommandAtom);
+			break;
+#endif
 		default:
 			throw "unknown architecture";
 	}
@@ -3482,17 +3764,28 @@ bool OutputFile::isPcRelStore(ld::Fixup::Kind kind)
 		case ld::Fixup::kindStoreX86PCRel32GOT:
 		case ld::Fixup::kindStoreX86PCRel32TLVLoad:
 		case ld::Fixup::kindStoreX86PCRel32TLVLoadNowLEA:
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMBranch24:
 		case ld::Fixup::kindStoreThumbBranch22:
 		case ld::Fixup::kindStoreARMLoad12:
+#endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCBranch24:
+		case ld::Fixup::kindStorePPCBranch14:
+		case ld::Fixup::kindStorePPCPicLow14:
+		case ld::Fixup::kindStorePPCPicLow16:
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+#endif
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32:
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32GOTLoad:
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32GOTLoadNowLEA:
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoad:
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoadNowLEA:
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreTargetAddressARMBranch24:
 		case ld::Fixup::kindStoreTargetAddressThumbBranch22:
 		case ld::Fixup::kindStoreTargetAddressARMLoad12:
+#endif
 #if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreARM64Page21:
 		case ld::Fixup::kindStoreARM64PageOff12:
@@ -3508,6 +3801,9 @@ bool OutputFile::isPcRelStore(ld::Fixup::Kind kind)
 		case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPage21:
 		case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPageOff12:
 #endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+#endif
 			return true;
 		case ld::Fixup::kindStoreTargetAddressX86BranchPCRel32:
 #if SUPPORT_ARCH_arm64
@@ -3559,9 +3855,11 @@ bool OutputFile::setsTarget(ld::Fixup::Kind kind)
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoad:
 		case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoadNowLEA:
 		case ld::Fixup::kindStoreTargetAddressX86Abs32TLVLoad:
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreTargetAddressARMBranch24:
 		case ld::Fixup::kindStoreTargetAddressThumbBranch22:
 		case ld::Fixup::kindStoreTargetAddressARMLoad12:
+#endif
 #if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreTargetAddressARM64Branch26:
 		case ld::Fixup::kindStoreTargetAddressARM64Page21:
@@ -3571,15 +3869,28 @@ bool OutputFile::setsTarget(ld::Fixup::Kind kind)
 		case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPage21:
 		case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPageOff12:
 #endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+#endif
 			return true;
 		case ld::Fixup::kindStoreX86DtraceCallSiteNop:
 		case ld::Fixup::kindStoreX86DtraceIsEnableSiteClear:
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMDtraceCallSiteNop:
 		case ld::Fixup::kindStoreARMDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreARM64DtraceCallSiteNop:
 		case ld::Fixup::kindStoreARM64DtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreThumbDtraceCallSiteNop:
 		case ld::Fixup::kindStoreThumbDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+		case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+#endif
 			return (_options.outputKind() == Options::kObjectFile);
 		default:
 			break;
@@ -4024,8 +4335,10 @@ void OutputFile::addDyldInfo(ld::Internal& state,  ld::Internal::FinalSection* s
 		if ( _options.sharedRegionEligible() ) {
 			// <rdar://problem/13287063> when range checking, ignore high byte of arm64 addends
 			uint64_t checkAddend = addend;
+#if SUPPORT_ARCH_arm64
 			if ( _options.architecture() == CPU_TYPE_ARM64 )
 				checkAddend &= 0x0FFFFFFFFFFFFFFFULL;
+#endif
 			if ( checkAddend != 0 ) {
 				// make sure the addend does not cause the pointer to point outside the target's segment
 				// if it does, update_dyld_shared_cache will not be able to put this dylib into the shared cache
@@ -4197,6 +4510,27 @@ void OutputFile::addClassicRelocs(ld::Internal& state, ld::Internal::FinalSectio
 				sect->hasLocalRelocs = true;
 			}
 			break;
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCAbsLow14:
+		case ld::Fixup::kindStorePPCAbsLow16:
+		case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+		case ld::Fixup::kindStorePPCAbsHigh16:
+			{
+				assert(target != NULL);
+				if ( target->definition() == ld::Atom::definitionProxy )
+					throwf("half word text relocs not supported in %s", atom->name());
+				if ( _options.outputSlidable() ) {
+					if ( inReadOnlySeg )
+						noteTextReloc(atom, target);
+					uint32_t machoSectionIndex = (target->definition() == ld::Atom::definitionAbsolute)
+						? R_ABS : target->machoSection();
+					_localRelocsAtom->addTextReloc(relocAddress, fixupWithTarget->kind,
+						target->finalAddress(), machoSectionIndex);
+					sect->hasLocalRelocs = true;
+				}
+			}
+			break;
+#endif
 		case ld::Fixup::kindStoreTargetAddressX86BranchPCRel32:
 #if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreTargetAddressARM64Branch26:
@@ -4210,6 +4544,7 @@ void OutputFile::addClassicRelocs(ld::Internal& state, ld::Internal::FinalSectio
 			}
 			break;
 		
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMLow16:
 		case ld::Fixup::kindStoreThumbLow16:
 			// no way to encode rebasing of binding for these instructions
@@ -4223,6 +4558,7 @@ void OutputFile::addClassicRelocs(ld::Internal& state, ld::Internal::FinalSectio
 			if ( _options.outputSlidable() || (target->definition() == ld::Atom::definitionProxy) )
 				throwf("no supported runtime hi16 relocation in %s from %s to %s", atom->name(), atom->file()->path(), target->name());
 			break;
+#endif
 
 		default:
 			break;
@@ -4232,11 +4568,17 @@ void OutputFile::addClassicRelocs(ld::Internal& state, ld::Internal::FinalSectio
 
 bool OutputFile::useExternalSectionReloc(const ld::Atom* atom, const ld::Atom* target, ld::Fixup* fixupWithTarget)
 {
-	if ( (_options.architecture() == CPU_TYPE_X86_64) || (_options.architecture() == CPU_TYPE_ARM64) ) {
+	if ( 0
+		|| (_options.architecture() == CPU_TYPE_X86_64)
+#if SUPPORT_ARCH_arm64
+		|| (_options.architecture() == CPU_TYPE_ARM64)
+#endif
+		) {
 		// x86_64 and ARM64 use external relocations for everthing that has a symbol
 		return ( target->symbolTableInclusion() != ld::Atom::symbolTableNotIn );
 	}
 	
+#if SUPPORT_ARCH_arm_any
 	// <rdar://problem/9513487> support arm branch interworking in -r mode 
 	if ( (_options.architecture() == CPU_TYPE_ARM) && (_options.outputKind() == Options::kObjectFile) ) {
 		if ( atom->isThumb() != target->isThumb() ) {
@@ -4251,7 +4593,8 @@ bool OutputFile::useExternalSectionReloc(const ld::Atom* atom, const ld::Atom* t
 			}
 		}
 	}
-	
+#endif
+
 	if ( (_options.architecture() == CPU_TYPE_I386) && (_options.outputKind() == Options::kObjectFile) ) {
 		if ( target->contentType() == ld::Atom::typeTLV ) 
 			return true;
@@ -4318,7 +4661,12 @@ void OutputFile::addSectionRelocs(ld::Internal& state, ld::Internal::FinalSectio
 	bool minusTargetUsesExternalReloc = (minusTarget != NULL) && this->useExternalSectionReloc(atom, minusTarget, fixupWithMinusTarget);
 	
 	// in x86_64 and arm64 .o files an external reloc means the content contains just the addend
-	if ( (_options.architecture() == CPU_TYPE_X86_64) ||(_options.architecture() == CPU_TYPE_ARM64)  ) {
+	if ( 0
+		|| (_options.architecture() == CPU_TYPE_X86_64)
+#if SUPPORT_ARCH_arm64
+		|| (_options.architecture() == CPU_TYPE_ARM64)
+#endif
+		) {
 		if ( targetUsesExternalReloc ) {
 			fixupWithTarget->contentAddendOnly = true;
 			fixupWithStore->contentAddendOnly = true;
@@ -4377,16 +4725,20 @@ void OutputFile::makeSplitSegInfo(ld::Internal& state)
 			const ld::Atom* target = NULL;
 			const ld::Atom* fromTarget = NULL;
             uint64_t accumulator = 0;
+#if SUPPORT_ARCH_arm_any
             bool thumbTarget;
+#endif
 			bool hadSubtract = false;
 			for (ld::Fixup::iterator fit = atom->fixupsBegin(), end=atom->fixupsEnd(); fit != end; ++fit) {
 				if ( fit->firstInCluster() ) 
 					target = NULL;
 				if ( this->setsTarget(fit->kind) ) {
 					accumulator = addressOf(state, fit, &target);			
+#if SUPPORT_ARCH_arm_any
 					thumbTarget = targetIsThumb(state, fit);
 					if ( thumbTarget ) 
 						accumulator |= 1;
+#endif
 				}
 				switch ( fit->kind ) {
 					case ld::Fixup::kindSubtractTargetAddress:
@@ -4418,13 +4770,18 @@ void OutputFile::makeSplitSegInfo(ld::Internal& state)
 					case ld::Fixup::kindStoreX86PCRel32GOT:
 					case ld::Fixup::kindStoreX86PCRel32TLVLoad:
 					case ld::Fixup::kindStoreX86PCRel32TLVLoadNowLEA:
+#if SUPPORT_ARCH_ppc
+					case ld::Fixup::kindStorePPCPicHigh16AddLow:
+#endif
 					case ld::Fixup::kindStoreTargetAddressX86PCRel32:
 					case ld::Fixup::kindStoreTargetAddressX86PCRel32GOTLoad:
 					case ld::Fixup::kindStoreTargetAddressX86PCRel32GOTLoadNowLEA:
 					case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoad:
 					case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoadNowLEA:
+#if SUPPORT_ARCH_arm_any
                     case ld::Fixup::kindStoreARMLow16:
                     case ld::Fixup::kindStoreThumbLow16: 
+#endif
 #if SUPPORT_ARCH_arm64
 					case ld::Fixup::kindStoreARM64Page21:
 					case ld::Fixup::kindStoreARM64GOTLoadPage21:
@@ -4440,6 +4797,7 @@ void OutputFile::makeSplitSegInfo(ld::Internal& state)
 							_splitSegInfos.push_back(SplitSegInfoEntry(atom->finalAddress()+fit->offsetInAtom,fit->kind));
 						}
 						break;
+#if SUPPORT_ARCH_arm_any
                     case ld::Fixup::kindStoreARMHigh16: 
                     case ld::Fixup::kindStoreThumbHigh16: 
 						assert(target != NULL);
@@ -4449,6 +4807,7 @@ void OutputFile::makeSplitSegInfo(ld::Internal& state)
  							_splitSegInfos.push_back(SplitSegInfoEntry(atom->finalAddress()+fit->offsetInAtom,fit->kind, extra));
 						}
 						break;
+#endif
 					case ld::Fixup::kindSetTargetImageOffset:
 						accumulator = addressOf(state, fit, &target);			
 						assert(target != NULL);
diff --git a/src/ld/OutputFile.h b/src/ld/OutputFile.h
index 6bb793b..eb05610 100644
--- a/src/ld/OutputFile.h
+++ b/src/ld/OutputFile.h
@@ -178,7 +178,9 @@ private:
 	void						updateLINKEDITAddresses(ld::Internal& state);
 	void						applyFixUps(ld::Internal& state, uint64_t mhAddress, const ld::Atom*  atom, uint8_t* buffer);
 	uint64_t					addressOf(const ld::Internal& state, const ld::Fixup* fixup, const ld::Atom** target);
+#if SUPPORT_ARCH_arm_any
 	bool						targetIsThumb(ld::Internal& state, const ld::Fixup* fixup);
+#endif
 	uint32_t					lazyBindingInfoOffsetForLazyPointerAddress(uint64_t lpAddress);
 	void						copyNoOps(uint8_t* from, uint8_t* to, bool thumb);
 	bool						isPointerToTarget(ld::Fixup::Kind kind);
@@ -212,18 +214,28 @@ private:
 																							const ld::Fixup* fixup);
 	void						rangeCheckRIP32(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
+#if SUPPORT_ARCH_arm_any
 	void						rangeCheckARM12(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
 	void						rangeCheckARMBranch24(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
 	void						rangeCheckThumbBranch22(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
+#endif
+#if SUPPORT_ARCH_arm64
 	void						rangeCheckARM64Branch26(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
 	void						rangeCheckARM64Page21(int64_t delta, ld::Internal& state, const ld::Atom* atom, 
 																							const ld::Fixup* fixup);
 																							
 																							
+#endif
+#if SUPPORT_ARCH_ppc
+	void	rangeCheckPPCBranch24(int64_t delta, ld::Internal& state, const ld::Atom* atom,
+		const ld::Fixup* fixup);
+	void	rangeCheckPPCBranch14(int64_t delta, ld::Internal& state, const ld::Atom* atom,
+		const ld::Fixup* fixup);
+#endif
 	uint64_t					sectionOffsetOf(const ld::Internal& state, const ld::Fixup* fixup);
 	uint64_t					tlvTemplateOffsetOf(const ld::Internal& state, const ld::Fixup* fixup);
 	void						dumpAtomsBySection(ld::Internal& state, bool);
diff --git a/src/ld/Resolver.cpp b/src/ld/Resolver.cpp
index 573cad8..e60779a 100644
--- a/src/ld/Resolver.cpp
+++ b/src/ld/Resolver.cpp
@@ -105,7 +105,12 @@ public:
 											ld::Atom(target.section(), target.definition(), ld::Atom::combineNever,
 													ld::Atom::scopeGlobal, target.contentType(), 
 													target.symbolTableInclusion(), target.dontDeadStrip(), 
-													target.isThumb(), true, target.alignment()),
+#if SUPPORT_ARCH_arm_any
+													target.isThumb(),
+#else
+													false,
+#endif
+													true, target.alignment()),
 											_name(nm), 
 											_aliasOf(target),
 											_fixup(0, ld::Fixup::k1of1, ld::Fixup::kindNoneFollowOn, &target) { }
@@ -303,6 +308,28 @@ void Resolver::buildAtomList()
 	//_symbolTable.printStatistics();
 }
 
+#if SUPPORT_ARCH_ppc
+unsigned int Resolver::ppcSubTypeIndex(uint32_t subtype)
+{
+	switch ( subtype ) {
+		case CPU_SUBTYPE_POWERPC_ALL:
+			return 0;
+		case CPU_SUBTYPE_POWERPC_750:
+			// G3
+			return 1;
+		case CPU_SUBTYPE_POWERPC_7400:
+		case CPU_SUBTYPE_POWERPC_7450:
+			// G4
+			return 2;
+		case CPU_SUBTYPE_POWERPC_970:
+			// G5 can run everything
+			return 3;
+		default:
+			throw "Unhandled PPC cpu subtype!";
+			break;
+	}
+}
+#endif
 
 void Resolver::doLinkerOption(const std::vector<const char*>& linkerOption, const char* fileName)
 {
@@ -394,6 +421,32 @@ void Resolver::doFile(const ld::File& file)
 		// update cpu-sub-type
 		cpu_subtype_t nextObjectSubType = file.cpuSubType();
 		switch ( _options.architecture() ) {
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+				// no checking when -force_cpusubtype_ALL is used
+				if ( _options.forceCpuSubtypeAll() )
+					return;
+				if ( _options.preferSubArchitecture() ) {
+					// warn if some .o file is not compatible with desired output sub-type
+					if ( _options.subArchitecture() != nextObjectSubType ) {
+						if ( ppcSubTypeIndex(nextObjectSubType) > ppcSubTypeIndex(_options.subArchitecture()) ) {
+							if ( !_inputFiles.inferredArch() )
+								warning("cpu-sub-type of %s is not compatible with command line cpu-sub-type", file.path());
+							_internal.cpuSubType = nextObjectSubType;
+						}
+					}
+				}
+				else {
+					// command line to linker just had -arch ppc
+					// figure out final sub-type based on sub-type of all .o files
+					if ( ppcSubTypeIndex(nextObjectSubType) > ppcSubTypeIndex(_internal.cpuSubType) ) {
+						_internal.cpuSubType = nextObjectSubType;
+					}
+				}
+				break;
+#endif
+
+#if SUPPORT_ARCH_arm_any
 			case CPU_TYPE_ARM:
 				if ( _options.subArchitecture() != nextObjectSubType ) {
 					if ( (_options.subArchitecture() == CPU_SUBTYPE_ARM_ALL) && _options.forceCpuSubtypeAll() ) {
@@ -412,7 +465,13 @@ void Resolver::doFile(const ld::File& file)
 					}
 				}
 				break;
+#endif
 			
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+				break;
+#endif
+
 			case CPU_TYPE_I386:
 				_internal.cpuSubType = CPU_SUBTYPE_I386_ALL;
 				break;
@@ -591,12 +650,22 @@ bool Resolver::isDtraceProbe(ld::Fixup::Kind kind)
 	switch (kind) {
 		case ld::Fixup::kindStoreX86DtraceCallSiteNop:
 		case ld::Fixup::kindStoreX86DtraceIsEnableSiteClear:
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMDtraceCallSiteNop:
 		case ld::Fixup::kindStoreARMDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreARM64DtraceCallSiteNop:
 		case ld::Fixup::kindStoreARM64DtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreThumbDtraceCallSiteNop:
 		case ld::Fixup::kindStoreThumbDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+		case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+#endif
 		case ld::Fixup::kindDtraceExtra:
 			return true;
 		default: 
@@ -819,14 +888,19 @@ void Resolver::markLive(const ld::Atom& atom, WhyLiveBackChain* previous)
 			case ld::Fixup::kindStoreTargetAddressX86PCRel32TLVLoadNowLEA:
 			case ld::Fixup::kindStoreTargetAddressX86Abs32TLVLoad:
 			case ld::Fixup::kindStoreTargetAddressX86Abs32TLVLoadNowLEA:
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreTargetAddressARMBranch24:
 			case ld::Fixup::kindStoreTargetAddressThumbBranch22:
+#endif
 #if SUPPORT_ARCH_arm64
 			case ld::Fixup::kindStoreTargetAddressARM64Branch26:
 			case ld::Fixup::kindStoreTargetAddressARM64Page21:
 			case ld::Fixup::kindStoreTargetAddressARM64GOTLoadPage21:
 			case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPage21:
 #endif
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+#endif
 				if ( fit->binding == ld::Fixup::bindingByContentBound ) {
 					// normally this was done in convertReferencesToIndirect()
 					// but a archive loaded .o file may have a forward reference
diff --git a/src/ld/Resolver.h b/src/ld/Resolver.h
index 4a3cd73..7b90e8a 100644
--- a/src/ld/Resolver.h
+++ b/src/ld/Resolver.h
@@ -98,6 +98,7 @@ private:
 	bool					isDtraceProbe(ld::Fixup::Kind kind);
 	void					liveUndefines(std::vector<const char*>&);
 	void					remainingUndefines(std::vector<const char*>&);
+	static unsigned int			ppcSubTypeIndex(uint32_t subtype);
 	bool					printReferencedBy(const char* name, SymbolTable::IndirectBindingSlot slot);
 	void					tweakWeakness();
 	void					doLinkerOption(const std::vector<const char*>& linkerOption, const char* fileName);
diff --git a/src/ld/ld.hpp b/src/ld/ld.hpp
index 95973aa..0d9d5e4 100644
--- a/src/ld/ld.hpp
+++ b/src/ld/ld.hpp
@@ -398,11 +398,13 @@ struct Fixup
 					kindStoreX86PCRel32GOTLoad, kindStoreX86PCRel32GOTLoadNowLEA, kindStoreX86PCRel32GOT, 
 					kindStoreX86PCRel32TLVLoad, kindStoreX86PCRel32TLVLoadNowLEA,
 					kindStoreX86Abs32TLVLoad, kindStoreX86Abs32TLVLoadNowLEA,
+#if SUPPORT_ARCH_arm_any
 					// ARM specific store kinds
 					kindStoreARMBranch24, kindStoreThumbBranch22, 
 					kindStoreARMLoad12,
 					kindStoreARMLow16, kindStoreARMHigh16, 
 					kindStoreThumbLow16, kindStoreThumbHigh16, 
+#endif
 #if SUPPORT_ARCH_arm64
 					// ARM64 specific store kinds
 					kindStoreARM64Branch26,  
@@ -413,12 +415,27 @@ struct Fixup
 					kindStoreARM64TLVPLoadNowLeaPage21, kindStoreARM64TLVPLoadNowLeaPageOff12,
 					kindStoreARM64PointerToGOT, kindStoreARM64PCRelToGOT,
 #endif
+#if SUPPORT_ARCH_ppc
+					// PowerPC specific store kinds
+					kindStorePPCBranch24, kindStorePPCBranch14,
+					kindStorePPCPicLow14, kindStorePPCPicLow16, kindStorePPCPicHigh16AddLow,
+					kindStorePPCAbsLow14, kindStorePPCAbsLow16, kindStorePPCAbsHigh16AddLow, kindStorePPCAbsHigh16,
+#endif
 					// dtrace probes
 					kindDtraceExtra,
 					kindStoreX86DtraceCallSiteNop, kindStoreX86DtraceIsEnableSiteClear,
+#if SUPPORT_ARCH_arm_any
 					kindStoreARMDtraceCallSiteNop, kindStoreARMDtraceIsEnableSiteClear,
+#endif
+#if SUPPORT_ARCH_arm64
 					kindStoreARM64DtraceCallSiteNop, kindStoreARM64DtraceIsEnableSiteClear,
+#endif
+#if SUPPORT_ARCH_arm_any
 					kindStoreThumbDtraceCallSiteNop, kindStoreThumbDtraceIsEnableSiteClear,
+#endif
+#if SUPPORT_ARCH_ppc
+					kindStorePPCDtraceCallSiteNop, kindStorePPCDtraceIsEnableSiteClear,
+#endif
 					// lazy binding
 					kindLazyTarget, kindSetLazyOffset,
 					// islands
@@ -444,10 +461,12 @@ struct Fixup
 					kindStoreTargetAddressX86PCRel32TLVLoadNowLEA, // kindSetTargetAddress + kindStoreX86PCRel32TLVLoadNowLEA
 					kindStoreTargetAddressX86Abs32TLVLoad,		// kindSetTargetAddress + kindStoreX86Abs32TLVLoad
 					kindStoreTargetAddressX86Abs32TLVLoadNowLEA,	// kindSetTargetAddress + kindStoreX86Abs32TLVLoadNowLEA
+#if SUPPORT_ARCH_arm_any
 					// ARM value calculation and store combinations
 					kindStoreTargetAddressARMBranch24,		// kindSetTargetAddress + kindStoreARMBranch24
 					kindStoreTargetAddressThumbBranch22,	// kindSetTargetAddress + kindStoreThumbBranch22
 					kindStoreTargetAddressARMLoad12,		// kindSetTargetAddress + kindStoreARMLoad12
+#endif
 #if SUPPORT_ARCH_arm64
 					// ARM64 value calculation and store combinations
 					kindStoreTargetAddressARM64Branch26,		// kindSetTargetAddress + kindStoreARM64Branch26
@@ -462,6 +481,10 @@ struct Fixup
 					kindStoreTargetAddressARM64TLVPLoadNowLeaPage21,	// kindSetTargetAddress + kindStoreARM64TLVPLoadNowLeaPage21
 					kindStoreTargetAddressARM64TLVPLoadNowLeaPageOff12,	// kindSetTargetAddress + kindStoreARM64TLVPLoadNowLeaPageOff12
 #endif
+#if SUPPORT_ARCH_ppc
+					// PowerPC value calculation and store combinations
+					kindStoreTargetAddressPPCBranch24,		// kindSetTargetAddress + kindStorePPCBranch24
+#endif
 			};
 
 	union {
@@ -702,7 +725,9 @@ public:
 	ContentType								contentType() const			{ return _contentType; }
 	SymbolTableInclusion					symbolTableInclusion() const{ return _symbolTableInclusion; }
 	bool									dontDeadStrip() const		{ return _dontDeadStrip; }
+#if SUPPORT_ARCH_arm_any
 	bool									isThumb() const				{ return _thumb; }
+#endif
 	bool									isAlias() const				{ return _alias; }
 	Alignment								alignment() const			{ return Alignment(_alignmentPowerOf2, _alignmentModulus); }
 	bool									overridesDylibsWeakDef() const	{ return _overridesADylibsWeakDef; }
diff --git a/src/ld/lto_file.hpp b/src/ld/lto_file.hpp
index 24d3f58..01d8df3 100644
--- a/src/ld/lto_file.hpp
+++ b/src/ld/lto_file.hpp
@@ -206,16 +206,22 @@ std::vector<File*> Parser::_s_files;
 const char* Parser::tripletPrefixForArch(cpu_type_t arch)
 {
 	switch (arch) {
+#if SUPPORT_ARCH_ppc
 		case CPU_TYPE_POWERPC:
 			return "powerpc-";
+#endif
+#if SUPPORT_ARCH_ppc64
 		case CPU_TYPE_POWERPC64:
 			return "powerpc64-";
+#endif
 		case CPU_TYPE_I386:
 			return "i386-";
 		case CPU_TYPE_X86_64:
 			return "x86_64-";
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			return "arm";
+#endif
 	}
 	return "";
 }
@@ -230,14 +236,18 @@ const char* Parser::fileKind(const uint8_t* p)
 	if ( (p[0] == 0xDE) && (p[1] == 0xC0) && (p[2] == 0x17) && (p[3] == 0x0B) ) {
 		uint32_t arch = LittleEndian::get32(*((uint32_t*)(&p[16])));
 		switch (arch) {
+#if SUPPORT_ARCH_ppc
 			case CPU_TYPE_POWERPC:
 				return "ppc";
+#endif
 			case CPU_TYPE_I386:
 				return "i386";
 			case CPU_TYPE_X86_64:
 				return "x86_64";
+#if SUPPORT_ARCH_arm_any
 			case CPU_TYPE_ARM:
 				return "arm";
+#endif
 		}
 		return "unknown bitcode architecture";
 	}
@@ -256,14 +266,18 @@ File* Parser::parse(const uint8_t* fileContent, uint64_t fileLength, const char*
 ld::relocatable::File* Parser::parseMachOFile(const uint8_t* p, size_t len, uint32_t nextInputOrdinal, cpu_type_t arch) 
 {
 	switch ( arch ) {
+#if SUPPORT_ARCH_ppc
 		case CPU_TYPE_POWERPC:
 			if ( mach_o::relocatable::Parser<ppc>::validFile(p) )
 				return mach_o::relocatable::Parser<ppc>::parse(p, len, "/tmp/lto.o", 0, nextInputOrdinal);
 			break;
+#endif
+#if SUPPORT_ARCH_ppc64
 		case CPU_TYPE_POWERPC64:
 			if ( mach_o::relocatable::Parser<ppc64>::validFile(p) )
 				return mach_o::relocatable::Parser<ppc64>::parse(p, len, "/tmp/lto.o", 0, nextInputOrdinal);
 			break;
+#endif
 		case CPU_TYPE_I386:
 			if ( mach_o::relocatable::Parser<x86>::validFile(p) )
 				return mach_o::relocatable::Parser<x86>::parse(p, len, "/tmp/lto.o", 0, nextInputOrdinal);
@@ -272,10 +286,12 @@ ld::relocatable::File* Parser::parseMachOFile(const uint8_t* p, size_t len, uint
 			if ( mach_o::relocatable::Parser<x86_64>::validFile(p) )
 				return mach_o::relocatable::Parser<x86_64>::parse(p, len, "/tmp/lto.o", 0, nextInputOrdinal);
 			break;
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			if ( mach_o::relocatable::Parser<arm>::validFile(p) )
 				return mach_o::relocatable::Parser<arm>::parse(p, len, "/tmp/lto.o", 0, nextInputOrdinal);
 			break;
+#endif
 	}
 	throw "LLVM LTO, file is not of required architecture";
 }
diff --git a/src/ld/parsers/archive_file.cpp b/src/ld/parsers/archive_file.cpp
index 9004530..676b298 100644
--- a/src/ld/parsers/archive_file.cpp
+++ b/src/ld/parsers/archive_file.cpp
@@ -220,10 +220,20 @@ const class File<A>::Entry* File<A>::Entry::next() const
 }
 
 
+#if SUPPORT_ARCH_ppc
+template <> cpu_type_t File<ppc>::architecture()    { return CPU_TYPE_POWERPC; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <> cpu_type_t File<ppc64>::architecture()  { return CPU_TYPE_POWERPC64; }
+#endif
 template <> cpu_type_t File<x86>::architecture()    { return CPU_TYPE_I386; }
 template <> cpu_type_t File<x86_64>::architecture() { return CPU_TYPE_X86_64; }
+#if SUPPORT_ARCH_arm_any
 template <> cpu_type_t File<arm>::architecture()    { return CPU_TYPE_ARM; }
+#endif
+#if SUPPORT_ARCH_arm64
 template <> cpu_type_t File<arm64>::architecture()  { return CPU_TYPE_ARM64; }
+#endif
 
 
 template <typename A>
@@ -311,6 +321,14 @@ bool File<x86>::memberHasObjCCategories(const Entry* member) const
 	}
 }
 
+#if SUPPORT_ARCH_ppc
+template <>
+bool File<ppc>::memberHasObjCCategories(const Entry* member) const
+{
+	// ppc uses ObjC1 ABI which has .objc_category* global symbols
+	return false;
+}
+#endif
 
 
 template <typename A>
@@ -606,6 +624,18 @@ ld::archive::File* parse(const uint8_t* fileContent, uint64_t fileLength,
 				return archive::Parser<arm64>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
 			break;
 #endif
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			if ( archive::Parser<ppc>::validFile(fileContent, fileLength, opts.objOpts) )
+				return archive::Parser<ppc>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			if ( archive::Parser<ppc64>::validFile(fileContent, fileLength, opts.objOpts) )
+				return archive::Parser<ppc64>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
+			break;
+#endif
 	}
 	return NULL;
 }
diff --git a/src/ld/parsers/libunwind/DwarfInstructions.hpp b/src/ld/parsers/libunwind/DwarfInstructions.hpp
index a37c8a0..722bd0f 100644
--- a/src/ld/parsers/libunwind/DwarfInstructions.hpp
+++ b/src/ld/parsers/libunwind/DwarfInstructions.hpp
@@ -146,6 +146,7 @@ private:
 												const Registers_x86_64&, const typename CFI_Parser<A>::PrologInfo& prolog,
 												char warningBuffer[1024]);
 	
+#if SUPPORT_ARCH_ppc
 	// ppc specific variants
 	static int    lastRestoreReg(const Registers_ppc&);
 	static bool   isReturnAddressRegister(int regNum, const Registers_ppc&);
@@ -154,7 +155,9 @@ private:
 	static compact_unwind_encoding_t createCompactEncodingFromProlog(A& addressSpace, pint_t funcAddr,
 												const Registers_ppc&, const typename CFI_Parser<A>::PrologInfo& prolog,
 												char warningBuffer[1024]);
+#endif
 												
+#if SUPPORT_ARCH_arm64
 	// arm64 specific variants
 	static bool   isReturnAddressRegister(int regNum, const Registers_arm64&);
 	static int    lastRestoreReg(const Registers_arm64&);
@@ -165,6 +168,7 @@ private:
 	static compact_unwind_encoding_t createCompactEncodingFromProlog(A& addressSpace, pint_t funcAddr,
 												const Registers_arm64&, const typename CFI_Parser<A>::PrologInfo& prolog,
 												char warningBuffer[1024]);
+#endif
 	
 };
 
@@ -1723,6 +1727,7 @@ compact_unwind_encoding_t DwarfInstructions<A,R>::createCompactEncodingFromProlo
 
 
 
+#if SUPPORT_ARCH_ppc
 //
 //	ppc specific functions
 //
@@ -1767,9 +1772,11 @@ compact_unwind_encoding_t DwarfInstructions<A,R>::createCompactEncodingFromProlo
 	warningBuffer[0] = '\0';
 	return UNWIND_X86_MODE_DWARF;
 }
+#endif
 
 
 
+#if SUPPORT_ARCH_arm64
 //
 // arm64 specific functions
 //
@@ -1959,6 +1966,7 @@ compact_unwind_encoding_t DwarfInstructions<A,R>::createCompactEncodingFromProlo
 
   return encoding;
 }
+#endif
 
 } // namespace libunwind
 
diff --git a/src/ld/parsers/libunwind/Registers.hpp b/src/ld/parsers/libunwind/Registers.hpp
index 0247066..367ad83 100644
--- a/src/ld/parsers/libunwind/Registers.hpp
+++ b/src/ld/parsers/libunwind/Registers.hpp
@@ -459,6 +459,7 @@ inline void Registers_x86_64::setVectorRegister(int num, v128 value)
 }
 
 
+#if SUPPORT_ARCH_ppc
 ///
 /// Registers_ppc holds the register state of a thread in a 32-bit PowerPC process.  
 ///
@@ -1036,11 +1037,13 @@ inline const char* Registers_ppc::getRegisterName(int regNum)
 	}
 
 }
+#endif
 
 
 
 
 
+#if SUPPORT_ARCH_arm64
 struct arm_thread_state64_t
 {
 	__uint64_t    __x[29];	/* General purpose registers x0-x28 */
@@ -1315,6 +1318,7 @@ inline void Registers_arm64::setVectorRegister(int regNum, v128 value)
 {
 	ABORT("no arm64 vector register support yet");
 }
+#endif
 
 
 
diff --git a/src/ld/parsers/macho_dylib_file.cpp b/src/ld/parsers/macho_dylib_file.cpp
index d37098b..47abb2f 100644
--- a/src/ld/parsers/macho_dylib_file.cpp
+++ b/src/ld/parsers/macho_dylib_file.cpp
@@ -241,11 +241,15 @@ template <typename A>
 bool File<A>::_s_logHashtable = false;
 
 template <> const char* File<x86_64>::objCInfoSegmentName() { return "__DATA"; }
+#if SUPPORT_ARCH_arm_any
 template <> const char* File<arm>::objCInfoSegmentName() { return "__DATA"; }
+#endif
 template <typename A> const char* File<A>::objCInfoSegmentName() { return "__OBJC"; }
 
 template <> const char* File<x86_64>::objCInfoSectionName() { return "__objc_imageinfo"; }
+#if SUPPORT_ARCH_arm_any
 template <> const char* File<arm>::objCInfoSectionName() { return "__objc_imageinfo"; }
+#endif
 template <typename A> const char* File<A>::objCInfoSectionName() { return "__image_info"; }
 
 template <typename A>
@@ -939,6 +943,64 @@ public:
 
 
 
+#if SUPPORT_ARCH_ppc
+template <>
+bool Parser<ppc>::validFile(const uint8_t* fileContent, bool executableOrDyliborBundle)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return false;
+	if ( header->cputype() != CPU_TYPE_POWERPC )
+		return false;
+	switch ( header->filetype() ) {
+		case MH_DYLIB:
+		case MH_DYLIB_STUB:
+			return true;
+		case MH_BUNDLE:
+			if ( executableOrDyliborBundle )
+				return true;
+			else
+				throw "can't link with bundle (MH_BUNDLE) only dylibs (MH_DYLIB)";
+		case MH_EXECUTE:
+			if ( executableOrDyliborBundle )
+				return true;
+			else
+				throw "can't link with a main executable";
+		default:
+			return false;
+	}
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+bool Parser<ppc64>::validFile(const uint8_t* fileContent, bool executableOrDyliborBundle)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC_64 )
+		return false;
+	if ( header->cputype() != CPU_TYPE_POWERPC64 )
+		return false;
+	switch ( header->filetype() ) {
+		case MH_DYLIB:
+		case MH_DYLIB_STUB:
+			return true;
+		case MH_BUNDLE:
+			if ( executableOrDyliborBundle )
+				return true;
+			else
+				throw "can't link with bundle (MH_BUNDLE) only dylibs (MH_DYLIB)";
+		case MH_EXECUTE:
+			if ( executableOrDyliborBundle )
+				return true;
+			else
+				throw "can't link with a main executable";
+		default:
+			return false;
+	}
+}
+#endif
+
 template <>
 bool Parser<x86>::validFile(const uint8_t* fileContent, bool executableOrDyliborBundle)
 {
@@ -993,6 +1055,7 @@ bool Parser<x86_64>::validFile(const uint8_t* fileContent, bool executableOrDyli
 	}
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 bool Parser<arm>::validFile(const uint8_t* fileContent, bool executableOrDyliborBundle)
 {
@@ -1019,9 +1082,11 @@ bool Parser<arm>::validFile(const uint8_t* fileContent, bool executableOrDylibor
 			return false;
 	}
 }
+#endif
 
 
 
+#if SUPPORT_ARCH_arm64
 template <>
 bool Parser<arm64>::validFile(const uint8_t* fileContent, bool executableOrDyliborBundle)
 {
@@ -1048,6 +1113,7 @@ bool Parser<arm64>::validFile(const uint8_t* fileContent, bool executableOrDylib
 			return false;
 	}
 }
+#endif
 
 
 bool isDylibFile(const uint8_t* fileContent, cpu_type_t* result, cpu_subtype_t* subResult)
@@ -1063,28 +1129,36 @@ bool isDylibFile(const uint8_t* fileContent, cpu_type_t* result, cpu_subtype_t*
 		*subResult = CPU_SUBTYPE_X86_ALL;
 		return true;
 	}
+#if SUPPORT_ARCH_arm_any
 	if ( Parser<arm>::validFile(fileContent, false) ) {
 		*result = CPU_TYPE_ARM;
 		const macho_header<Pointer32<LittleEndian> >* header = (const macho_header<Pointer32<LittleEndian> >*)fileContent;
 		*subResult = header->cpusubtype();
 		return true;
 	}
+#endif
+#if SUPPORT_ARCH_arm64
 	if ( Parser<arm64>::validFile(fileContent, false) ) {
 		*result = CPU_TYPE_ARM64;
 		*subResult = CPU_SUBTYPE_ARM64_ALL;
 		return true;
 	}
+#endif
+#if SUPPORT_ARCH_ppc
 	if ( Parser<ppc>::validFile(fileContent, false) ) {
 		*result = CPU_TYPE_POWERPC;
 		const macho_header<Pointer32<BigEndian> >* header = (const macho_header<Pointer32<BigEndian> >*)fileContent;
 		*subResult = header->cpusubtype();
 		return true;
 	}
+#endif
+#if SUPPORT_ARCH_ppc64
 	if ( Parser<ppc64>::validFile(fileContent, false) ) {
 		*result = CPU_TYPE_POWERPC64;
 		*subResult = CPU_SUBTYPE_POWERPC_ALL;
 		return true;
 	}
+#endif
 	return false;
 }
 
@@ -1110,6 +1184,7 @@ const char* Parser<x86_64>::fileKind(const uint8_t* fileContent)
 	return "x86_64";
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 const char* Parser<arm>::fileKind(const uint8_t* fileContent)
 {
@@ -1125,6 +1200,7 @@ const char* Parser<arm>::fileKind(const uint8_t* fileContent)
 	}
 	return "arm???";
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -1139,6 +1215,44 @@ const char* Parser<arm64>::fileKind(const uint8_t* fileContent)
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
+template <>
+const char* Parser<ppc>::fileKind(const uint8_t* fileContent)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return NULL;
+	if ( header->cputype() != CPU_TYPE_POWERPC )
+		return NULL;
+	switch ( header->cpusubtype() ) {
+		case CPU_SUBTYPE_POWERPC_750:
+			return "ppc750";
+		case CPU_SUBTYPE_POWERPC_7400:
+			return "ppc7400";
+		case CPU_SUBTYPE_POWERPC_7450:
+			return "ppc7450";
+		case CPU_SUBTYPE_POWERPC_970:
+			return "ppc970";
+		case CPU_SUBTYPE_POWERPC_ALL:
+			return "ppc";
+	}
+	return "ppc???";
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+const char* Parser<ppc64>::fileKind(const uint8_t* fileContent)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return NULL;
+	if ( header->cputype() != CPU_TYPE_POWERPC64 )
+		return NULL;
+	return "ppc64";
+}
+#endif
+
 //
 // used by linker is error messages to describe mismatched files
 //
@@ -1150,14 +1264,26 @@ const char* archName(const uint8_t* fileContent)
 	if ( Parser<x86>::validFile(fileContent, true) ) {
 		return Parser<x86>::fileKind(fileContent);
 	}
+#if SUPPORT_ARCH_arm_any
 	if ( Parser<arm>::validFile(fileContent, true) ) {
 		return Parser<arm>::fileKind(fileContent);
 	}
+#endif
 #if SUPPORT_ARCH_arm64
 	if ( Parser<arm64>::validFile(fileContent, false) ) {
 		return Parser<arm64>::fileKind(fileContent);
 	}
 #endif
+#if SUPPORT_ARCH_ppc
+	if ( Parser<ppc>::validFile(fileContent, true) ) {
+		return Parser<ppc>::fileKind(fileContent);
+	}
+#endif
+#if SUPPORT_ARCH_ppc64
+	if ( Parser<ppc64>::validFile(fileContent, false) ) {
+		return Parser<ppc64>::fileKind(fileContent);
+	}
+#endif
 	return NULL;
 }
 
@@ -1194,6 +1320,18 @@ ld::dylib::File* parse(const uint8_t* fileContent, uint64_t fileLength,
 				return Parser<arm64>::parse(fileContent, fileLength, path, modTime, ordinal, opts, indirectDylib);
 			break;
 #endif
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			if ( Parser<ppc>::validFile(fileContent, bundleLoader) )
+				return Parser<ppc>::parse(fileContent, fileLength, path, modTime, ordinal, opts, indirectDylib);
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			if ( Parser<ppc64>::validFile(fileContent, bundleLoader) )
+				return Parser<ppc64>::parse(fileContent, fileLength, path, modTime, ordinal, opts, indirectDylib);
+			break;
+#endif
 	}
 	return NULL;
 }
diff --git a/src/ld/parsers/macho_relocatable_file.cpp b/src/ld/parsers/macho_relocatable_file.cpp
index ad5720e..5a87f62 100644
--- a/src/ld/parsers/macho_relocatable_file.cpp
+++ b/src/ld/parsers/macho_relocatable_file.cpp
@@ -168,6 +168,9 @@ protected:
 								_beginAtoms(NULL), _endAtoms(NULL), _hasAliases(false) { }
 
 
+#if SUPPORT_ARCH_ppc || SUPPORT_ARCH_ppc64
+	bool	addRelocFixup_powerpc(class Parser<A>& parser,const macho_relocation_info<typename A::P>* reloc);
+#endif
 	Atom<A>*						findContentAtomByAddress(pint_t addr, class Atom<A>* start, class Atom<A>* end);
 	uint32_t						x86_64PcRelOffset(uint8_t r_type);
 	void							addLOH(class Parser<A>& parser, int kind, int count, const uint64_t addrs[]);
@@ -861,6 +864,7 @@ void Atom<A>::copyRawContent(uint8_t buffer[]) const
 	}
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 void Atom<arm>::verifyAlignment(const macho_section<P>&) const
 {
@@ -869,6 +873,7 @@ void Atom<arm>::verifyAlignment(const macho_section<P>&) const
 			warning("ARM function not 4-byte aligned: %s from %s", this->name(), this->file()->path());
 	}
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -1191,6 +1196,35 @@ Parser<A>::Parser(const uint8_t* fileContent, uint64_t fileLength, const char* p
 {
 }
 
+#if SUPPORT_ARCH_ppc
+template <>
+bool Parser<ppc>::validFile(const uint8_t* fileContent, bool, cpu_subtype_t)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return false;
+	if ( header->cputype() != CPU_TYPE_POWERPC )
+		return false;
+	if ( header->filetype() != MH_OBJECT )
+		return false;
+	return true;
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+bool Parser<ppc64>::validFile(const uint8_t* fileContent, bool, cpu_subtype_t)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC_64 )
+		return false;
+	if ( header->cputype() != CPU_TYPE_POWERPC64 )
+		return false;
+	if ( header->filetype() != MH_OBJECT )
+		return false;
+	return true;
+}
+#endif
 
 template <>
 bool Parser<x86>::validFile(const uint8_t* fileContent, bool, cpu_subtype_t)
@@ -1218,6 +1252,7 @@ bool Parser<x86_64>::validFile(const uint8_t* fileContent, bool, cpu_subtype_t)
 	return true;
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 bool Parser<arm>::validFile(const uint8_t* fileContent, bool subtypeMustMatch, cpu_subtype_t subtype)
 {
@@ -1238,8 +1273,10 @@ bool Parser<arm>::validFile(const uint8_t* fileContent, bool subtypeMustMatch, c
 	}
 	return true;
 }
+#endif
 
 
+#if SUPPORT_ARCH_arm64
 template <>
 bool Parser<arm64>::validFile(const uint8_t* fileContent, bool subtypeMustMatch, cpu_subtype_t subtype)
 {
@@ -1252,7 +1289,45 @@ bool Parser<arm64>::validFile(const uint8_t* fileContent, bool subtypeMustMatch,
 		return false;
 	return true;
 }
+#endif
 
+#if SUPPORT_ARCH_ppc
+template <>
+const char* Parser<ppc>::fileKind(const uint8_t* fileContent)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return NULL;
+	if ( header->cputype() != CPU_TYPE_POWERPC )
+		return NULL;
+	switch ( header->cpusubtype() ) {
+		case CPU_SUBTYPE_POWERPC_750:
+			return "ppc750";
+		case CPU_SUBTYPE_POWERPC_7400:
+			return "ppc7400";
+		case CPU_SUBTYPE_POWERPC_7450:
+			return "ppc7450";
+		case CPU_SUBTYPE_POWERPC_970:
+			return "ppc970";
+		case CPU_SUBTYPE_POWERPC_ALL:
+			return "ppc";
+	}
+	return "ppc???";
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+const char* Parser<ppc64>::fileKind(const uint8_t* fileContent)
+{
+	const macho_header<P>* header = (const macho_header<P>*)fileContent;
+	if ( header->magic() != MH_MAGIC )
+		return NULL;
+	if ( header->cputype() != CPU_TYPE_POWERPC64 )
+		return NULL;
+	return "ppc64";
+}
+#endif
 
 template <>
 const char* Parser<x86>::fileKind(const uint8_t* fileContent)
@@ -1276,6 +1351,7 @@ const char* Parser<x86_64>::fileKind(const uint8_t* fileContent)
 	return "x86_64";
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 const char* Parser<arm>::fileKind(const uint8_t* fileContent)
 {
@@ -1291,6 +1367,7 @@ const char* Parser<arm>::fileKind(const uint8_t* fileContent)
 	}
 	return "arm???";
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -1800,10 +1877,20 @@ ld::relocatable::File* Parser<A>::parse(const ParserOptions& opts)
 
 
 
+#if SUPPORT_ARCH_ppc
+template <> uint8_t Parser<ppc>::loadCommandSizeMask()		{ return 0x03; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <> uint8_t Parser<ppc64>::loadCommandSizeMask()	{ return 0x07; }
+#endif
 template <> uint8_t Parser<x86>::loadCommandSizeMask()		{ return 0x03; }
 template <> uint8_t Parser<x86_64>::loadCommandSizeMask()	{ return 0x07; }
+#if SUPPORT_ARCH_arm_any
 template <> uint8_t Parser<arm>::loadCommandSizeMask()		{ return 0x03; }
+#endif
+#if SUPPORT_ARCH_arm64
 template <> uint8_t Parser<arm64>::loadCommandSizeMask()	{ return 0x07; }
+#endif
 
 template <typename A>
 bool Parser<A>::parseLoadCommands()
@@ -2681,12 +2768,14 @@ void Parser<A>::addFixups(const SourceLocation& src, ld::Fixup::Kind setKind, co
 			case ld::Fixup::kindStoreX86Abs32TLVLoad:
 				firstKind = ld::Fixup::kindStoreTargetAddressX86Abs32TLVLoad;
 				break;
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreARMBranch24:
 				firstKind = ld::Fixup::kindStoreTargetAddressARMBranch24;
 				break;
 			case ld::Fixup::kindStoreThumbBranch22:
 				firstKind = ld::Fixup::kindStoreTargetAddressThumbBranch22;
 				break;
+#endif
 #if SUPPORT_ARCH_arm64
 			case ld::Fixup::kindStoreARM64Branch26:
 				firstKind = ld::Fixup::kindStoreTargetAddressARM64Branch26;
@@ -2710,6 +2799,11 @@ void Parser<A>::addFixups(const SourceLocation& src, ld::Fixup::Kind setKind, co
 				firstKind = ld::Fixup::kindStoreTargetAddressARM64TLVPLoadPageOff12;
 				break;
 #endif
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStorePPCBranch24:
+				firstKind = ld::Fixup::kindStoreTargetAddressPPCBranch24;
+				break;
+#endif
 			default:
 				combined = false;
 				cl = ld::Fixup::k1of2;
@@ -2996,7 +3090,11 @@ bool Parser<A>::dontDeadStripFromSymbol(const macho_nlist<P>& sym)
 template <typename A>
 bool Parser<A>::isThumbFromSymbol(const macho_nlist<P>& sym)
 {
+#if SUPPORT_ARCH_arm_any
 	return ( sym.n_desc() & N_ARM_THUMB_DEF );
+#else
+	return false;
+#endif
 }
 
 template <typename A>
@@ -3921,8 +4019,14 @@ uint32_t Section<A>::sectionNum(class Parser<A>& parser) const
 		return 1 + (this->_machOSection - parser.firstMachOSection());
 }
 
+#if SUPPORT_ARCH_ppc64
+// libunwind does not support ppc64
+template <> uint32_t CFISection<ppc64>::cfiCount() { return 0; }
+#endif
+#if SUPPORT_ARCH_arm_any
 // arm does not have zero cost exceptions
 template <> uint32_t CFISection<arm>::cfiCount() { return 0; }
+#endif
 
 template <typename A>
 uint32_t CFISection<A>::cfiCount()
@@ -3955,11 +4059,13 @@ bool CFISection<x86_64>::needsRelocating()
 	return true;
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 bool CFISection<arm64>::needsRelocating()
 {
 	return true;
 }
+#endif
 
 template <typename A>
 bool CFISection<A>::needsRelocating()
@@ -4048,8 +4154,39 @@ void CFISection<x86>::cfiParse(class Parser<x86>& parser, uint8_t* buffer,
 }
 
 
+#if SUPPORT_ARCH_ppc
+// need to change libunwind parseCFIs() to work for ppc
+template <>
+void CFISection<ppc>::cfiParse(class Parser<ppc>& parser, uint8_t* buffer,
+	libunwind::CFI_Atom_Info<CFISection<ppc>::OAS>::CFI_Atom_Info cfiArray[],
+	uint32_t& count, const pint_t cuStarts[], uint32_t cuCount)
+{
+	// create ObjectAddressSpace object for use by libunwind
+	OAS oas(*this, (uint8_t*)this->file().fileContent()+this->_machOSection->offset());
 
+	// use libuwind to parse __eh_frame data into array of CFI_Atom_Info
+	const char* msg;
+	msg = libunwind::DwarfInstructions<OAS, libunwind::Registers_ppc>::parseCFIs(
+		oas, this->_machOSection->addr(), this->_machOSection->size(),
+		cuStarts, cuCount, parser.keepDwarfUnwind(), parser.forceDwarfConversion(), parser.neverConvertDwarf(),
+		cfiArray, count, (void*)&parser, warnFunc);
+	if ( msg != NULL )
+		throwf("malformed __eh_frame section: %s", msg);
+}
+#endif
 
+#if SUPPORT_ARCH_ppc64
+template <>
+void CFISection<ppc64>::cfiParse(class Parser<ppc64>& parser, uint8_t* buffer,
+	libunwind::CFI_Atom_Info<CFISection<ppc64>::OAS>::CFI_Atom_Info cfiArray[],
+	uint32_t& count, const pint_t cuStarts[], uint32_t cuCount)
+{
+	// libunwind does not support ppc64
+	assert(count == 0);
+}
+#endif
+
+#if SUPPORT_ARCH_arm_any
 template <>
 void CFISection<arm>::cfiParse(class Parser<arm>& parser, uint8_t* buffer, 
 									libunwind::CFI_Atom_Info<CFISection<arm>::OAS>::CFI_Atom_Info cfiArray[], 
@@ -4058,7 +4195,9 @@ void CFISection<arm>::cfiParse(class Parser<arm>& parser, uint8_t* buffer,
 	// arm does not use zero cost exceptions
 	assert(count == 0);
 }
+#endif
 
+#if SUPPORT_ARCH_arm64
 template <>
 void CFISection<arm64>::cfiParse(class Parser<arm64>& parser, uint8_t* buffer, 
 									libunwind::CFI_Atom_Info<CFISection<arm64>::OAS>::CFI_Atom_Info cfiArray[], 
@@ -4123,6 +4262,7 @@ void CFISection<arm64>::cfiParse(class Parser<arm64>& parser, uint8_t* buffer,
 	if ( msg != NULL ) 
 		throwf("malformed __eh_frame section: %s", msg);
 }
+#endif
 
 
 template <typename A>
@@ -4159,8 +4299,18 @@ uint32_t CFISection<A>::appendAtoms(class Parser<A>& parser, uint8_t* p,
 
 template <> bool CFISection<x86_64>::bigEndian() { return false; }
 template <> bool CFISection<x86>::bigEndian() { return false; }
+#if SUPPORT_ARCH_arm_any
 template <> bool CFISection<arm>::bigEndian() { return false; }
+#endif
+#if SUPPORT_ARCH_arm64
 template <> bool CFISection<arm64>::bigEndian() { return false; }
+#endif
+#if SUPPORT_ARCH_ppc
+template <> bool CFISection<ppc>::bigEndian() { return true; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <> bool CFISection<ppc64>::bigEndian() { return true; }
+#endif
 
 
 template <>
@@ -4236,6 +4386,31 @@ void CFISection<arm64>::addCiePersonalityFixups(class Parser<arm64>& parser, con
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
+template <>
+void CFISection<ppc>::addCiePersonalityFixups(class Parser<ppc>& parser, const CFI_Atom_Info* cieInfo)
+{
+	uint8_t personalityEncoding = cieInfo->u.cieInfo.personality.encodingOfTargetAddress;
+	if ( (personalityEncoding == 0x9B) || (personalityEncoding == 0x90) ) {
+		uint32_t offsetInCFI = cieInfo->u.cieInfo.personality.offsetInCFI;
+		uint32_t nlpAddr = cieInfo->u.cieInfo.personality.targetAddress;
+		Atom<ppc>* cieAtom = this->findAtomByAddress(cieInfo->address);
+		Atom<ppc>* nlpAtom = parser.findAtomByAddress(nlpAddr);
+		assert(nlpAtom->contentType() == ld::Atom::typeNonLazyPointer);
+		Parser<ppc>::SourceLocation src(cieAtom, cieInfo->u.cieInfo.personality.offsetInCFI);
+
+		parser.addFixup(src, ld::Fixup::k1of4, ld::Fixup::kindSetTargetAddress, ld::Fixup::bindingByContentBound, nlpAtom);
+		parser.addFixup(src, ld::Fixup::k2of4, ld::Fixup::kindSubtractTargetAddress, cieAtom);
+		parser.addFixup(src, ld::Fixup::k3of4, ld::Fixup::kindSubtractAddend, offsetInCFI);
+		parser.addFixup(src, ld::Fixup::k4of4, ld::Fixup::kindStoreBigEndian32);
+	}
+	else if ( personalityEncoding != 0 ) {
+		throwf("unsupported address encoding (%02X) of personality function in CIE",
+			personalityEncoding);
+	}
+}
+#endif
+
 template <typename A>
 void CFISection<A>::addCiePersonalityFixups(class Parser<A>& parser, const CFI_Atom_Info* cieInfo)
 {
@@ -4571,6 +4746,24 @@ bool CUSection<arm64>::encodingMeansUseDwarf(compact_unwind_encoding_t enc)
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
+/* No unwind headers saying anything about PPC to be found anywhere. So the
+ * encoding shouldn't be able to ask for DWARF. */
+template <>
+bool CUSection<ppc>::encodingMeansUseDwarf(compact_unwind_encoding_t enc)
+{
+	return false;
+}
+#endif
+
+#if SUPPORT_ARCH_ppc64
+template <>
+bool CUSection<ppc64>::encodingMeansUseDwarf(compact_unwind_encoding_t enc)
+{
+	return false;
+}
+#endif
+
 template <typename A>
 int CUSection<A>::infoSorter(const void* l, const void* r)
 {
@@ -4799,11 +4992,13 @@ uint32_t SymboledSection<A>::appendAtoms(class Parser<A>& parser, uint8_t* p,
 }
 
 
+#if SUPPORT_ARCH_arm64
 template <>
 ld::Atom::SymbolTableInclusion ImplicitSizeSection<arm64>::symbolTableInclusion()
 {
 	return ld::Atom::symbolTableInWithRandomAutoStripLabel;
 }
+#endif
 
 template <typename A>
 ld::Atom::SymbolTableInclusion ImplicitSizeSection<A>::symbolTableInclusion()
@@ -5077,18 +5272,37 @@ ld::Fixup::Kind NonLazyPointerSection<x86>::fixupKind()
 	return ld::Fixup::kindStoreLittleEndian32;
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 ld::Fixup::Kind NonLazyPointerSection<arm>::fixupKind()
 {
 	return ld::Fixup::kindStoreLittleEndian32;
 }
+#endif
 
+#if SUPPORT_ARCH_arm64
 template <>
 ld::Fixup::Kind NonLazyPointerSection<arm64>::fixupKind()
 {
 	return ld::Fixup::kindStoreLittleEndian64;
 }
+#endif
+
+#if SUPPORT_ARCH_ppc
+template <>
+ld::Fixup::Kind NonLazyPointerSection<ppc>::fixupKind()
+{
+	return ld::Fixup::kindStoreBigEndian32;
+}
+#endif
 
+#if SUPPORT_ARCH_ppc64
+template <>
+ld::Fixup::Kind NonLazyPointerSection<ppc64>::fixupKind()
+{
+	return ld::Fixup::kindStoreBigEndian64;
+}
+#endif
 
 template <>
 void NonLazyPointerSection<x86_64>::makeFixups(class Parser<x86_64>& parser, const struct Parser<x86_64>::CFI_CU_InfoArrays&)
@@ -5119,9 +5333,11 @@ void NonLazyPointerSection<A>::makeFixups(class Parser<A>& parser, const struct
 			target.atom = parser.findAtomByAddress(targetAddr);
 			target.weakImport = false;
 			target.addend = (targetAddr - target.atom->objectAddress());
+#if SUPPORT_ARCH_arm_any
 			// <rdar://problem/8385011> if pointer to thumb function, mask of thumb bit (not an addend of +1)
 			if ( target.atom->isThumb() )
 				target.addend &= (-2); 
+#endif
 			assert(src.atom->combine() == ld::Atom::combineNever);
 		}
 		else {
@@ -6033,6 +6249,412 @@ bool Section<x86>::addRelocFixup(class Parser<x86>& parser, const macho_relocati
 
 
 	
+#if SUPPORT_ARCH_ppc || SUPPORT_ARCH_ppc64
+//
+// ppc and ppc64 both use the same relocations, so process them in one common routine
+//
+template <typename A>
+bool Section<A>::addRelocFixup_powerpc(class Parser<A>& parser,
+	const macho_relocation_info<typename A::P>* reloc)
+{
+	const macho_section<P>* sect = this->machoSection();
+	bool result = false;
+	uint32_t srcAddr;
+	uint32_t dstAddr;
+	uint32_t* fixUpPtr;
+	int32_t displacement = 0;
+	uint32_t instruction = 0;
+	int16_t lowBits;
+	pint_t contentValue = 0;
+	typename Parser<A>::SourceLocation	src;
+	typename Parser<A>::TargetDesc		target;
+
+	if ( (reloc->r_address() & R_SCATTERED) == 0 ) {
+		srcAddr = sect->addr() + reloc->r_address();
+		src.atom = this->findAtomByAddress(srcAddr);
+		src.offsetInAtom = srcAddr - src.atom->_objAddress;
+		const macho_relocation_info<P>* nextReloc = &reloc[1];
+		fixUpPtr = (uint32_t*)(file().fileContent() + sect->offset() + reloc->r_address());
+		if ( reloc->r_type() != PPC_RELOC_PAIR )
+			instruction = BigEndian::get32(*fixUpPtr);
+		if ( reloc->r_extern() ) {
+			target.atom = NULL;
+			const macho_nlist<P>& targetSymbol = parser.symbolFromIndex(reloc->r_symbolnum());
+			target.name = parser.nameFromSymbol(targetSymbol);
+			target.weakImport = parser.weakImportFromSymbol(targetSymbol);
+		}
+		switch ( reloc->r_type() ) {
+			case PPC_RELOC_BR24:
+				assert((instruction & 0x4C000000) == 0x48000000);
+				displacement = (instruction & 0x03FFFFFC);
+				if ( (displacement & 0x02000000) != 0 )
+					displacement |= 0xFC000000;
+				if ( reloc->r_extern() ) {
+					target.addend = srcAddr + displacement;
+				}
+				else {
+					dstAddr = srcAddr + displacement;
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				// special case "calls" for dtrace
+				if ( (target.name != NULL) && (strncmp(target.name, "___dtrace_probe$", 16) == 0) ) {
+					parser.addFixup(src, ld::Fixup::k1of1,
+						ld::Fixup::kindStorePPCDtraceCallSiteNop, false, target.name);
+					parser.addDtraceExtraInfos(src, &target.name[16]);
+				}
+				else if ( (target.name != NULL) && (strncmp(target.name, "___dtrace_isenabled$", 20) == 0) ) {
+					parser.addFixup(src, ld::Fixup::k1of1,
+						ld::Fixup::kindStorePPCDtraceIsEnableSiteClear, false, target.name);
+					parser.addDtraceExtraInfos(src, &target.name[20]);
+				}
+				else {
+					parser.addFixups(src, ld::Fixup::kindStorePPCBranch24, target);
+				}
+				break;
+			case PPC_RELOC_BR14:
+				displacement = (instruction & 0x0000FFFC);
+				if ( (displacement & 0x00008000) != 0 )
+					displacement |= 0xFFFF0000;
+				if ( reloc->r_extern() ) {
+					target.addend = srcAddr + displacement;
+				}
+				else {
+					dstAddr = srcAddr + displacement;
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				parser.addFixups(src, ld::Fixup::kindStorePPCBranch14, target);
+				break;
+			case PPC_RELOC_PAIR:
+				// skip, processed by a previous look ahead
+				break;
+			case PPC_RELOC_LO16:
+				if ( nextReloc->r_type() != PPC_RELOC_PAIR )
+					throw "PPC_RELOC_LO16 missing following pair";
+				result = true;
+				lowBits = (instruction & 0x0000FFFF);
+				dstAddr = (nextReloc->r_address() << 16) + ((uint32_t)lowBits & 0x0000FFFF);
+				if ( reloc->r_extern() ) {
+					target.addend = dstAddr;
+				}
+				else {
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsLow16, target);
+				break;
+			case PPC_RELOC_LO14:
+				if ( nextReloc->r_type() != PPC_RELOC_PAIR )
+					throw "PPC_RELOC_LO14 missing following pair";
+				result = true;
+				lowBits = (instruction & 0xFFFC);
+				dstAddr = (nextReloc->r_address() << 16) + ((uint32_t)lowBits & 0x0000FFFF);
+				if ( reloc->r_extern() ) {
+					target.addend = dstAddr;
+				}
+				else {
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsLow14, target);
+				break;
+			case PPC_RELOC_HI16:
+				if ( nextReloc->r_type() != PPC_RELOC_PAIR )
+					throw "PPC_RELOC_HI16 missing following pair";
+				result = true;
+				lowBits = (nextReloc->r_address() & 0xFFFF);
+				dstAddr = ((instruction & 0xFFFF) << 16) | (lowBits & 0x0000FFFF);
+				if ( reloc->r_extern() ) {
+					target.addend = dstAddr;
+				}
+				else {
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsHigh16, target);
+				break;
+			case PPC_RELOC_HA16:
+				if ( nextReloc->r_type() != PPC_RELOC_PAIR )
+					throw "PPC_RELOC_HA16 missing following pair";
+				result = true;
+				lowBits = (nextReloc->r_address() & 0x0000FFFF);
+				dstAddr = ((instruction & 0xFFFF) << 16) + (int32_t)lowBits;
+				if ( reloc->r_extern() ) {
+					target.addend = dstAddr;
+				}
+				else {
+					parser.findTargetFromAddressAndSectionNum(dstAddr, reloc->r_symbolnum(), target);
+				}
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsHigh16AddLow, target);
+				break;
+			case PPC_RELOC_VANILLA:
+				contentValue = P::getP(*((pint_t*)fixUpPtr));
+				if ( reloc->r_extern() ) {
+					target.addend = contentValue;
+				}
+				else {
+					parser.findTargetFromAddressAndSectionNum(contentValue, reloc->r_symbolnum(), target);
+				}
+				switch ( reloc->r_length() ) {
+					case 0:
+					case 1:
+						throw "bad r_length in PPC_RELOC_VANILLA";
+					case 2:
+						parser.addFixups(src, ld::Fixup::kindStoreBigEndian32, target);
+						break;
+					case 3:
+						parser.addFixups(src, ld::Fixup::kindStoreBigEndian64, target);
+						break;
+				}
+				break;
+			case PPC_RELOC_JBSR:
+				// this is from -mlong-branch codegen.  We ignore the jump island and make reference to the real target
+				if ( nextReloc->r_type() != PPC_RELOC_PAIR )
+					throw "PPC_RELOC_JBSR missing following pair";
+				if ( !parser._hasLongBranchStubs )
+					warning("object file compiled with -mlong-branch which is no longer needed. "
+							"To remove this warning, recompile without -mlong-branch: %s", parser._path);
+				parser._hasLongBranchStubs = true;
+				result = true;
+				if ( reloc->r_extern() ) {
+					throw "PPC_RELOC_JBSR should not be using an external relocation";
+				}
+				parser.findTargetFromAddressAndSectionNum(nextReloc->r_address(), reloc->r_symbolnum(), target);
+				parser.addFixups(src, ld::Fixup::kindStorePPCBranch24, target);
+				break;
+			default:
+				warning("unknown relocation type %d", reloc->r_type());
+		}
+	}
+	else {
+		const macho_scattered_relocation_info<P>* sreloc = (macho_scattered_relocation_info<P>*)reloc;
+		// file format allows pair to be scattered or not
+		const macho_scattered_relocation_info<P>* nextSReloc = &sreloc[1];
+		const macho_relocation_info<P>* nextReloc = &reloc[1];
+		srcAddr = sect->addr() + sreloc->r_address();
+		dstAddr = sreloc->r_value();
+		fixUpPtr = (uint32_t*)(file().fileContent() + sect->offset() + sreloc->r_address());
+		instruction = BigEndian::get32(*fixUpPtr);
+		src.atom = this->findAtomByAddress(srcAddr);
+		src.offsetInAtom = srcAddr - src.atom->_objAddress;
+		typename Parser<A>::TargetDesc		picBase;
+		bool nextRelocIsPair = false;
+		uint32_t nextRelocAddress = 0;
+		uint32_t nextRelocValue = 0;
+		if ( (nextReloc->r_address() & R_SCATTERED) == 0 ) {
+			if ( nextReloc->r_type() == PPC_RELOC_PAIR ) {
+				nextRelocIsPair = true;
+				nextRelocAddress = nextReloc->r_address();
+				result = true;
+			}
+		}
+		else {
+			if ( nextSReloc->r_type() == PPC_RELOC_PAIR ) {
+				nextRelocIsPair = true;
+				nextRelocAddress = nextSReloc->r_address();
+				nextRelocValue = nextSReloc->r_value();
+				result = true;
+			}
+		}
+		switch ( sreloc->r_type() ) {
+			case PPC_RELOC_VANILLA:
+				// with a scattered relocation we get both the target (sreloc->r_value()) and the target+offset (*fixUpPtr)
+				target.atom = parser.findAtomByAddress(sreloc->r_value());
+				switch ( sreloc->r_length() ) {
+					case 0:
+					case 1:
+						throw "unsuppored r_length < 2 for scattered PPC_RELOC_VANILLA";
+					case 2:
+						contentValue = BigEndian::get32(*(uint32_t*)fixUpPtr);
+						target.addend = contentValue - target.atom->_objAddress;
+						parser.addFixups(src, ld::Fixup::kindStoreBigEndian32, target);
+						break;
+					case 3:
+						contentValue = BigEndian::get64(*(uint64_t*)fixUpPtr);
+						target.addend = contentValue - target.atom->_objAddress;
+						parser.addFixups(src, ld::Fixup::kindStoreBigEndian64, target);
+						break;
+				}
+				break;
+			case PPC_RELOC_BR14:
+				displacement = (instruction & 0x0000FFFC);
+				if ( (displacement & 0x00008000) != 0 )
+					displacement |= 0xFFFF0000;
+				target.atom = parser.findAtomByAddress(sreloc->r_value());
+				target.addend = (srcAddr + displacement) - target.atom->_objAddress;
+				parser.addFixups(src, ld::Fixup::kindStorePPCBranch14, target);
+				break;
+			case PPC_RELOC_BR24:
+				assert((instruction & 0x4C000000) == 0x48000000);
+				displacement = (instruction & 0x03FFFFFC);
+				if ( (displacement & 0x02000000) != 0 )
+					displacement |= 0xFC000000;
+				target.atom = parser.findAtomByAddress(sreloc->r_value());
+				target.addend = (srcAddr + displacement) - target.atom->_objAddress;
+				parser.addFixups(src, ld::Fixup::kindStorePPCBranch24, target);
+				break;
+			case PPC_RELOC_LO16_SECTDIFF:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_LO16_SECTDIFF missing following pair";
+				lowBits = (instruction & 0xFFFF);
+				dstAddr = nextRelocValue + ((nextRelocAddress << 16) | ((uint32_t)lowBits & 0x0000FFFF));
+				parser.findTargetFromAddress(sreloc->r_value(), target);
+				if ( target.atom != NULL )
+					target.addend = dstAddr - target.atom->_objAddress;
+				picBase.atom = parser.findAtomByAddress(nextRelocValue);
+				picBase.addend = nextRelocValue - picBase.atom->_objAddress;
+				picBase.weakImport = false;
+				picBase.name = NULL;
+				parser.addFixups(src, ld::Fixup::kindStorePPCPicLow16, target, picBase);
+				break;
+			case PPC_RELOC_LO14_SECTDIFF:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_LO14_SECTDIFF missing following pair";
+				lowBits = (instruction & 0xFFFC);
+				dstAddr = nextRelocValue + ((nextRelocAddress << 16) | ((uint32_t)lowBits & 0x0000FFFF));
+				parser.findTargetFromAddress(sreloc->r_value(), target);
+				if ( target.atom != NULL )
+					target.addend = dstAddr - target.atom->_objAddress;
+				picBase.atom = parser.findAtomByAddress(nextRelocValue);
+				picBase.addend = nextRelocValue - picBase.atom->_objAddress;
+				picBase.weakImport = false;
+				picBase.name = NULL;
+				parser.addFixups(src, ld::Fixup::kindStorePPCPicLow14, target, picBase);
+				break;
+			case PPC_RELOC_HA16_SECTDIFF:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_HA16_SECTDIFF missing following pair";
+				lowBits = (nextRelocAddress & 0x0000FFFF);
+				dstAddr = nextRelocValue + (((instruction & 0x0000FFFF) << 16) + (int32_t)lowBits);
+				parser.findTargetFromAddress(sreloc->r_value(), target);
+				if ( target.atom != NULL )
+					target.addend = dstAddr - target.atom->_objAddress;
+				picBase.atom = parser.findAtomByAddress(nextRelocValue);
+				picBase.addend = nextRelocValue - picBase.atom->_objAddress;
+				picBase.weakImport = false;
+				picBase.name = NULL;
+				parser.addFixups(src, ld::Fixup::kindStorePPCPicHigh16AddLow, target, picBase);
+				break;
+			case PPC_RELOC_LO14:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_LO14 missing following pair";
+				lowBits = (instruction & 0xFFFC);
+				dstAddr = ((nextRelocAddress << 16) + ((uint32_t)lowBits & 0x0000FFFF));
+				parser.findTargetFromAddress(sreloc->r_value(), dstAddr, target);
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsLow14, target);
+				break;
+			case PPC_RELOC_LO16:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_LO16 missing following pair";
+				lowBits = (instruction & 0xFFFF);
+				dstAddr = ((nextRelocAddress << 16) + ((uint32_t)lowBits & 0x0000FFFF));
+				parser.findTargetFromAddress(sreloc->r_value(), dstAddr, target);
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsLow16, target);
+				break;
+			case PPC_RELOC_HA16:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_HA16 missing following pair";
+				lowBits = (nextRelocAddress & 0xFFFF);
+				dstAddr = (((instruction & 0xFFFF) << 16) + (int32_t)lowBits);
+				parser.findTargetFromAddress(sreloc->r_value(), dstAddr, target);
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsHigh16AddLow, target);
+				break;
+			case PPC_RELOC_HI16:
+				if ( ! nextRelocIsPair )
+					throw "PPC_RELOC_HI16 missing following pair";
+				lowBits = (nextRelocAddress & 0xFFFF);
+				dstAddr = ((instruction & 0xFFFF) << 16) | (lowBits & 0x0000FFFF);
+				parser.findTargetFromAddress(sreloc->r_value(), dstAddr, target);
+				parser.addFixups(src, ld::Fixup::kindStorePPCAbsHigh16, target);
+				break;
+			case PPC_RELOC_SECTDIFF:
+			case PPC_RELOC_LOCAL_SECTDIFF:
+				{
+					if ( ! nextRelocIsPair )
+						throw "PPC_RELOC_SECTDIFF missing following pair";
+					ld::Fixup::Kind kind = ld::Fixup::kindNone;
+					switch ( sreloc->r_length() ) {
+						case 0:
+							throw "bad length for PPC_RELOC_SECTDIFF";
+						case 1:
+							contentValue = (int32_t)(int16_t)BigEndian::get16(*((uint16_t*)fixUpPtr));
+							kind = ld::Fixup::kindStoreBigEndian16;
+							break;
+						case 2:
+							contentValue = BigEndian::get32(*((uint32_t*)fixUpPtr));
+							kind = ld::Fixup::kindStoreBigEndian32;
+							break;
+						case 3:
+							contentValue = BigEndian::get64(*((uint64_t*)fixUpPtr));
+							kind = ld::Fixup::kindStoreBigEndian64;
+							break;
+						break;
+					}
+					Atom<A>* fromAtom  = parser.findAtomByAddress(nextRelocValue);
+					Atom<A>* targetAtom = parser.findAtomByAddress(sreloc->r_value());
+					uint32_t offsetInFrom = nextRelocValue - fromAtom->_objAddress;
+					uint32_t offsetInTarget = sreloc->r_value() - targetAtom->_objAddress;
+					// check for addend encoded in the section content
+					int32_t addend = contentValue - (sreloc->r_value() - nextRelocValue);
+					if ( addend < 0 ) {
+						if ( targetAtom->scope() == ld::Atom::scopeTranslationUnit ) {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, targetAtom);
+						}
+						else if ( (targetAtom->combine() == ld::Atom::combineByNameAndContent) || (targetAtom->combine() == ld::Atom::combineByNameAndReferences) ) {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, ld::Fixup::bindingByContentBound, targetAtom);
+						}
+						else {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, false, targetAtom->name());
+						}
+						parser.addFixup(src, ld::Fixup::k2of5, ld::Fixup::kindAddAddend, offsetInTarget);
+						parser.addFixup(src, ld::Fixup::k3of5, ld::Fixup::kindSubtractTargetAddress, fromAtom);
+						parser.addFixup(src, ld::Fixup::k4of5, ld::Fixup::kindSubtractAddend, offsetInFrom-addend);
+						parser.addFixup(src, ld::Fixup::k5of5, kind);
+					}
+					else {
+						if ( targetAtom->scope() == ld::Atom::scopeTranslationUnit ) {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, targetAtom);
+						}
+						else if ( (targetAtom->combine() == ld::Atom::combineByNameAndContent) || (targetAtom->combine() == ld::Atom::combineByNameAndReferences) ) {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, ld::Fixup::bindingByContentBound, targetAtom);
+						}
+						else {
+							parser.addFixup(src, ld::Fixup::k1of5, ld::Fixup::kindSetTargetAddress, false, targetAtom->name());
+						}
+						parser.addFixup(src, ld::Fixup::k2of5, ld::Fixup::kindAddAddend, offsetInTarget+addend);
+						parser.addFixup(src, ld::Fixup::k3of5, ld::Fixup::kindSubtractTargetAddress, fromAtom);
+						parser.addFixup(src, ld::Fixup::k4of5, ld::Fixup::kindSubtractAddend, offsetInFrom);
+						parser.addFixup(src, ld::Fixup::k5of5, kind);
+					}
+				}
+				break;
+			case PPC_RELOC_PAIR:
+				break;
+			case PPC_RELOC_HI16_SECTDIFF:
+				warning("unexpected scattered relocation type PPC_RELOC_HI16_SECTDIFF");
+				break;
+			default:
+				warning("unknown scattered relocation type %d", sreloc->r_type());
+		}
+	}
+	return result;
+}
+#endif
+
+
+#if SUPPORT_ARCH_ppc
+template <>
+bool Section<ppc>::addRelocFixup(class Parser<ppc>& parser, const macho_relocation_info<P>* reloc)
+{
+	return addRelocFixup_powerpc(parser, reloc);
+}
+#endif
+
+
+#if SUPPORT_ARCH_ppc64
+template <>
+bool Section<ppc64>::addRelocFixup(class Parser<ppc64>& parser, const macho_relocation_info<P>* reloc)
+{
+	return addRelocFixup_powerpc(parser, reloc);
+}
+#endif
+
 
 
 #if SUPPORT_ARCH_arm_any
@@ -6845,6 +7467,43 @@ bool ObjC1ClassSection<x86>::addRelocFixup(class Parser<x86>& parser, const mach
 	return FixedSizeSection<x86>::addRelocFixup(parser, reloc);
 }
 
+#if SUPPORT_ARCH_ppc
+template <>
+bool ObjC1ClassSection<ppc>::addRelocFixup(class Parser<ppc>& parser, const macho_relocation_info<ppc::P>* reloc)
+{
+	// if this is the reloc for the super class name string, add implicit reference to super class
+	if ( ((reloc->r_address() & R_SCATTERED) == 0) && (reloc->r_type() == PPC_RELOC_VANILLA) ) {
+		assert( reloc->r_length() == 2 );
+		assert( ! reloc->r_pcrel() );
+
+		const macho_section<P>* sect = this->machoSection();
+		Parser<ppc>::SourceLocation	src;
+		uint32_t srcAddr = sect->addr() + reloc->r_address();
+		src.atom = this->findAtomByAddress(srcAddr);
+		src.offsetInAtom = srcAddr - src.atom->objectAddress();
+		if ( src.offsetInAtom == 4 ) {
+			Parser<ppc>::TargetDesc		stringTarget;
+			const uint8_t* fixUpPtr = file().fileContent() + sect->offset() + reloc->r_address();
+			uint32_t contentValue = BigEndian::get32(*((uint32_t*)fixUpPtr));
+			parser.findTargetFromAddressAndSectionNum(contentValue, reloc->r_symbolnum(), stringTarget);
+
+			assert(stringTarget.atom != NULL);
+			assert(stringTarget.atom->contentType() == ld::Atom::typeCString);
+			const char* superClassBaseName = (char*)stringTarget.atom->rawContentPointer();
+			char* superClassName = new char[strlen(superClassBaseName) + 20];
+			strcpy(superClassName, ".objc_class_name_");
+			strcat(superClassName, superClassBaseName);
+
+			parser.addFixup(src, ld::Fixup::k1of1, ld::Fixup::kindSetTargetAddress, false, superClassName);
+		}
+	}
+
+	// inherited
+	return FixedSizeSection<ppc>::addRelocFixup(parser, reloc);
+}
+#endif
+
+
 
 
 template <typename A>
@@ -6858,6 +7517,40 @@ bool Objc1ClassReferences<A>::addRelocFixup(class Parser<A>& parser, const macho
 }
 
 
+#if SUPPORT_ARCH_ppc
+template <>
+bool Objc1ClassReferences<ppc>::addRelocFixup(class Parser<ppc>& parser, const macho_relocation_info<ppc::P>* reloc)
+{
+	// add implict class refs, fixups not usable yet, so look at relocations
+	assert( (reloc->r_address() & R_SCATTERED) == 0 );
+	assert( reloc->r_type() == PPC_RELOC_VANILLA );
+	assert( reloc->r_length() == 2 );
+	assert( ! reloc->r_pcrel() );
+
+	const macho_section<P>* sect = this->machoSection();
+	Parser<ppc>::SourceLocation	src;
+	uint32_t srcAddr = sect->addr() + reloc->r_address();
+	src.atom = this->findAtomByAddress(srcAddr);
+	src.offsetInAtom = srcAddr - src.atom->objectAddress();
+	Parser<ppc>::TargetDesc		stringTarget;
+	const uint8_t* fixUpPtr = file().fileContent() + sect->offset() + reloc->r_address();
+	uint32_t contentValue = BigEndian::get32(*((uint32_t*)fixUpPtr));
+	parser.findTargetFromAddressAndSectionNum(contentValue, reloc->r_symbolnum(), stringTarget);
+
+	assert(stringTarget.atom != NULL);
+	assert(stringTarget.atom->contentType() == ld::Atom::typeCString);
+	const char* baseClassName = (char*)stringTarget.atom->rawContentPointer();
+	char* objcClassName = new char[strlen(baseClassName) + 20];
+	strcpy(objcClassName, ".objc_class_name_");
+	strcat(objcClassName, baseClassName);
+
+	parser.addFixup(src, ld::Fixup::k1of1, ld::Fixup::kindSetTargetAddress, false, objcClassName);
+
+	// inherited
+	return PointerToCStringSection<ppc>::addRelocFixup(parser, reloc);
+}
+#endif
+
 
 template <>
 bool Objc1ClassReferences<x86>::addRelocFixup(class Parser<x86>& parser, const macho_relocation_info<x86::P>* reloc)
@@ -7156,6 +7849,18 @@ ld::relocatable::File* parse(const uint8_t* fileContent, uint64_t fileLength,
 				return mach_o::relocatable::Parser<arm64>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
 			break;
 #endif
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			if ( mach_o::relocatable::Parser<ppc>::validFile(fileContent) )
+				return mach_o::relocatable::Parser<ppc>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			if ( mach_o::relocatable::Parser<ppc64>::validFile(fileContent) )
+				return mach_o::relocatable::Parser<ppc64>::parse(fileContent, fileLength, path, modTime, ordinal, opts);
+			break;
+#endif
 	}
 	return NULL;
 }
@@ -7170,10 +7875,22 @@ bool isObjectFile(const uint8_t* fileContent, uint64_t fileLength, const ParserO
 			return ( mach_o::relocatable::Parser<x86_64>::validFile(fileContent) );
 		case CPU_TYPE_I386:
 			return ( mach_o::relocatable::Parser<x86>::validFile(fileContent) );
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			return ( mach_o::relocatable::Parser<arm>::validFile(fileContent, opts.objSubtypeMustMatch, opts.subType) );
+#endif
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:
 			return ( mach_o::relocatable::Parser<arm64>::validFile(fileContent, opts.objSubtypeMustMatch, opts.subType) );
+#endif
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			return ( mach_o::relocatable::Parser<ppc>::validFile(fileContent) );
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			return ( mach_o::relocatable::Parser<ppc64>::validFile(fileContent) );
+#endif
 	}
 	return false;
 }
@@ -7194,17 +7911,36 @@ bool isObjectFile(const uint8_t* fileContent, cpu_type_t* result, cpu_subtype_t*
 		*subResult = CPU_SUBTYPE_X86_ALL;
 		return true;
 	}
+#if SUPPORT_ARCH_arm_any
 	if ( mach_o::relocatable::Parser<arm>::validFile(fileContent, false, 0) ) {
 		*result = CPU_TYPE_ARM;
 		const macho_header<Pointer32<LittleEndian> >* header = (const macho_header<Pointer32<LittleEndian> >*)fileContent;
 		*subResult = header->cpusubtype();
 		return true;
 	}
+#endif
+#if SUPPORT_ARCH_arm64
 	if ( mach_o::relocatable::Parser<arm64>::validFile(fileContent, false, 0) ) {
 		*result = CPU_TYPE_ARM64;
 		*subResult = CPU_SUBTYPE_ARM64_ALL;
 		return true;
 	}
+#endif
+#if SUPPORT_ARCH_ppc
+	if ( mach_o::relocatable::Parser<ppc>::validFile(fileContent) ) {
+		*result = CPU_TYPE_POWERPC;
+		const macho_header<Pointer32<BigEndian> >* header = (const macho_header<Pointer32<BigEndian> >*)fileContent;
+		*subResult = header->cpusubtype();
+		return true;
+	}
+#endif
+#if SUPPORT_ARCH_ppc64
+	if ( mach_o::relocatable::Parser<ppc64>::validFile(fileContent) ) {
+		*result = CPU_TYPE_POWERPC64;
+		*subResult = CPU_SUBTYPE_POWERPC_ALL;
+		return true;
+	}
+#endif
 	return false;
 }					
 
@@ -7219,9 +7955,21 @@ const char* archName(const uint8_t* fileContent)
 	if ( mach_o::relocatable::Parser<x86>::validFile(fileContent) ) {
 		return mach_o::relocatable::Parser<x86>::fileKind(fileContent);
 	}
+#if SUPPORT_ARCH_arm_any
 	if ( mach_o::relocatable::Parser<arm>::validFile(fileContent, false, 0) ) {
 		return mach_o::relocatable::Parser<arm>::fileKind(fileContent);
 	}
+#endif
+#if SUPPORT_ARCH_ppc
+	if ( mach_o::relocatable::Parser<ppc>::validFile(fileContent) ) {
+		return mach_o::relocatable::Parser<ppc>::fileKind(fileContent);
+	}
+#endif
+#if SUPPORT_ARCH_ppc64
+	if ( mach_o::relocatable::Parser<ppc64>::validFile(fileContent) ) {
+		return mach_o::relocatable::Parser<ppc64>::fileKind(fileContent);
+	}
+#endif
 	return NULL;
 }
 
@@ -7233,9 +7981,11 @@ bool hasObjC2Categories(const uint8_t* fileContent)
 	if ( mach_o::relocatable::Parser<x86_64>::validFile(fileContent) ) {
 		return mach_o::relocatable::Parser<x86_64>::hasObjC2Categories(fileContent);
 	}
+#if SUPPORT_ARCH_arm_any
 	else if ( mach_o::relocatable::Parser<arm>::validFile(fileContent, false, 0) ) {
 		return mach_o::relocatable::Parser<arm>::hasObjC2Categories(fileContent);
 	}
+#endif
 	else if ( mach_o::relocatable::Parser<x86>::validFile(fileContent, false, 0) ) {
 		return mach_o::relocatable::Parser<x86>::hasObjC2Categories(fileContent);
 	}
diff --git a/src/ld/passes/branch_island.cpp b/src/ld/passes/branch_island.cpp
index 5f5612c..075f4ec 100644
--- a/src/ld/passes/branch_island.cpp
+++ b/src/ld/passes/branch_island.cpp
@@ -60,8 +60,47 @@ public:
 static bool _s_log = false;
 static ld::Section _s_text_section("__TEXT", "__text", ld::Section::typeCode);
 
+#if SUPPORT_ARCH_ppc
+class PPCBranchIslandAtom : public ld::Atom {
+public:
+	PPCBranchIslandAtom(const char* nm, const ld::Atom* target, TargetAndOffset finalTarget)
+		: ld::Atom(_s_text_section, ld::Atom::definitionRegular, ld::Atom::combineNever,
+			ld::Atom::scopeLinkageUnit, ld::Atom::typeBranchIsland,
+			ld::Atom::symbolTableIn, false, false, false, ld::Atom::Alignment(2)),
+	_name(nm),
+				_target(target),
+				_finalTarget(finalTarget) { }
 
+	virtual const ld::File*	file() const	{ return NULL; }
+	virtual bool		translationUnitSource(const char** dir, const char**) const
+		{ return false; }
+	virtual const char*	name() const		{ return _name; }
+	virtual uint64_t	size() const		{ return 4; }
+	virtual uint64_t	objectAddress() const	{ return 0; }
+	virtual void		copyRawContent(uint8_t buffer[]) const {
+		int64_t displacement = _target->finalAddress() - this->finalAddress();
+		const int64_t bl_sixteenMegLimit = 0x00FFFFFF;
+		if ( _target->contentType() == ld::Atom::typeBranchIsland ) {
+			// try optimizing away intermediate islands
+			int64_t skipToFinalDisplacement = _finalTarget.atom->finalAddress() + _finalTarget.offset - this->finalAddress();
+			if ( (skipToFinalDisplacement > bl_sixteenMegLimit) && (skipToFinalDisplacement < (-bl_sixteenMegLimit)) ) {
+				displacement = skipToFinalDisplacement;
+			}
+		}
+		int32_t branchInstruction = 0x48000000 | ((uint32_t)displacement & 0x03FFFFFC);
+		OSWriteBigInt32(buffer, 0, branchInstruction);
+	}
+	virtual void		setScope(Scope)		{ }
+
+private:
+	const char*		_name;
+	const ld::Atom*		_target;
+	TargetAndOffset		_finalTarget;
+};
+#endif
 
+
+#if SUPPORT_ARCH_arm_any
 class ARMtoARMBranchIslandAtom : public ld::Atom {
 public:
 											ARMtoARMBranchIslandAtom(const char* nm, const ld::Atom* target, TargetAndOffset finalTarget)
@@ -234,6 +273,7 @@ private:
 	const ld::Atom*							_target;
 	TargetAndOffset							_finalTarget;
 };
+#endif
 
 
 static ld::Atom* makeBranchIsland(const Options& opts, ld::Fixup::Kind kind, int islandRegion, const ld::Atom* nextTarget, 
@@ -251,6 +291,13 @@ static ld::Atom* makeBranchIsland(const Options& opts, ld::Fixup::Kind kind, int
 	}
 
 	switch ( kind ) {
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCBranch24:
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+			return new PPCBranchIslandAtom(name, nextTarget, finalTarget);
+			break;
+#endif
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMBranch24:
 		case ld::Fixup::kindStoreThumbBranch22:
 		case ld::Fixup::kindStoreTargetAddressARMBranch24:
@@ -273,6 +320,7 @@ static ld::Atom* makeBranchIsland(const Options& opts, ld::Fixup::Kind kind, int
 				return new ARMtoARMBranchIslandAtom(name, nextTarget, finalTarget);
 			}
 			break;
+#endif
 		default:
 			assert(0 && "unexpected branch kind");
 			break;
@@ -284,6 +332,17 @@ static ld::Atom* makeBranchIsland(const Options& opts, ld::Fixup::Kind kind, int
 static uint64_t textSizeWhenMightNeedBranchIslands(const Options& opts, bool seenThumbBranch)
 {
 	switch ( opts.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			return 16000000;
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			return 16000000;
+			break;
+#endif
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			if ( ! seenThumbBranch )
 				return 32000000;  // ARM can branch +/- 32MB
@@ -292,6 +351,7 @@ static uint64_t textSizeWhenMightNeedBranchIslands(const Options& opts, bool see
 			else
 				return  4000000;  // thumb1 can branch +/- 4MB
 			break;
+#endif
 	}
 	assert(0 && "unexpected architecture");
 	return 0x100000000LL;
@@ -301,6 +361,17 @@ static uint64_t textSizeWhenMightNeedBranchIslands(const Options& opts, bool see
 static uint64_t maxDistanceBetweenIslands(const Options& opts, bool seenThumbBranch)
 {
 	switch ( opts.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+				return 14*1024*1024;
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+				return 14*1024*1024;
+			break;
+#endif
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			if ( ! seenThumbBranch )
 				return 30*1024*1024;	// 2MB of branch islands per 32MB
@@ -309,6 +380,7 @@ static uint64_t maxDistanceBetweenIslands(const Options& opts, bool seenThumbBra
 			else
 				return 3500000;			// 0.5MB of branch islands per 4MB
 			break;
+#endif
 	}
 	assert(0 && "unexpected architecture");
 	return 0x100000000LL;
@@ -368,6 +440,7 @@ static void makeIslandsForSection(const Options& opts, ld::Internal& state, ld::
 			}
 			bool haveBranch = false;
 			switch (fit->kind) {
+#if SUPPORT_ARCH_arm_any
 				case ld::Fixup::kindStoreThumbBranch22:
 				case ld::Fixup::kindStoreTargetAddressThumbBranch22:
 					hasThumbBranches = true;
@@ -376,6 +449,7 @@ static void makeIslandsForSection(const Options& opts, ld::Internal& state, ld::
 				case ld::Fixup::kindStoreTargetAddressARMBranch24:
 					haveBranch = true;
 					break;
+#endif
                 default:
                     break;   
 			}
@@ -478,10 +552,16 @@ static void makeIslandsForSection(const Options& opts, ld::Internal& state, ld::
 				case ld::Fixup::kindAddAddend:
 					addend = fit->u.addend;
 					break;
+#if SUPPORT_ARCH_ppc
+				case ld::Fixup::kindStorePPCBranch24:
+				case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+#endif
+#if SUPPORT_ARCH_arm_any
 				case ld::Fixup::kindStoreARMBranch24:
 				case ld::Fixup::kindStoreThumbBranch22:
 				case ld::Fixup::kindStoreTargetAddressARMBranch24:
 				case ld::Fixup::kindStoreTargetAddressThumbBranch22:
+#endif
 					haveBranch = true;
 					break;
                 default:
@@ -651,10 +731,20 @@ void doPass(const Options& opts, ld::Internal& state)
 	if ( !opts.allowBranchIslands() )
 		return;
 	
-	// only ARM needs branch islands
+	// only PowerPC and ARM need branch islands
 	switch ( opts.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			break;
+#endif
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			break;
+#endif
 		default:
 			return;
 	}
diff --git a/src/ld/passes/branch_shim.cpp b/src/ld/passes/branch_shim.cpp
index 840a391..b91d7ad 100644
--- a/src/ld/passes/branch_shim.cpp
+++ b/src/ld/passes/branch_shim.cpp
@@ -44,6 +44,7 @@ namespace branch_shim {
 static bool _s_log = false;
 
 
+#if SUPPORT_ARCH_arm_any
 class Thumb2ToArmShimAtom : public ld::Atom {
 public:
 											Thumb2ToArmShimAtom(const ld::Atom* target, const ld::Section& inSect)
@@ -262,6 +263,7 @@ static void extractTarget(ld::Fixup::iterator fixup, ld::Internal& state, const
 			break;
 	}
 }
+#endif
 
 
 
@@ -276,6 +278,7 @@ static void extractTarget(ld::Fixup::iterator fixup, ld::Internal& state, const
 //
 void doPass(const Options& opts, ld::Internal& state)
 {	
+#if SUPPORT_ARCH_arm_any
 	// only make branch shims in final linked images
 	if ( opts.outputKind() == Options::kObjectFile )
 		return;
@@ -386,6 +389,9 @@ void doPass(const Options& opts, ld::Internal& state)
 		// append all new shims to end of __text
 		sect->atoms.insert(sect->atoms.end(), shims.begin(), shims.end());
 	}
+#else
+	return;
+#endif
 }
 
 
diff --git a/src/ld/passes/compact_unwind.cpp b/src/ld/passes/compact_unwind.cpp
index ad8a504..1d671f6 100644
--- a/src/ld/passes/compact_unwind.cpp
+++ b/src/ld/passes/compact_unwind.cpp
@@ -297,11 +297,13 @@ bool UnwindInfoAtom<x86_64>::encodingMeansUseDwarf(compact_unwind_encoding_t enc
 	return ((enc & UNWIND_X86_64_MODE_MASK) == UNWIND_X86_64_MODE_DWARF);
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 bool UnwindInfoAtom<arm64>::encodingMeansUseDwarf(compact_unwind_encoding_t enc)
 {
 	return ((enc & UNWIND_ARM64_MODE_MASK) == UNWIND_ARM64_MODE_DWARF);
 }
+#endif
 
 template <typename A>
 void UnwindInfoAtom<A>::compressDuplicates(const std::vector<UnwindEntry>& entries, std::vector<UnwindEntry>& uniqueEntries)
@@ -409,6 +411,7 @@ void UnwindInfoAtom<x86_64>::addCompressedAddressOffsetFixup(uint32_t offset, co
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k3of3, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addCompressedAddressOffsetFixup(uint32_t offset, const ld::Atom* func, const ld::Atom* fromFunc)
 {
@@ -416,6 +419,7 @@ void UnwindInfoAtom<arm64>::addCompressedAddressOffsetFixup(uint32_t offset, con
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of3, ld::Fixup::kindSubtractTargetAddress, fromFunc));
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k3of3, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
+#endif
 
 template <>
 void UnwindInfoAtom<x86>::addCompressedEncodingFixup(uint32_t offset, const ld::Atom* fde)
@@ -431,12 +435,14 @@ void UnwindInfoAtom<x86_64>::addCompressedEncodingFixup(uint32_t offset, const l
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addCompressedEncodingFixup(uint32_t offset, const ld::Atom* fde)
 {
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of2, ld::Fixup::kindSetTargetSectionOffset, fde));
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
+#endif
 
 template <>
 void UnwindInfoAtom<x86>::addRegularAddressFixup(uint32_t offset, const ld::Atom* func)
@@ -452,12 +458,14 @@ void UnwindInfoAtom<x86_64>::addRegularAddressFixup(uint32_t offset, const ld::A
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndian32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addRegularAddressFixup(uint32_t offset, const ld::Atom* func)
 {
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of2, ld::Fixup::kindSetTargetImageOffset, func));
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndian32));
 }
+#endif
 
 template <>
 void UnwindInfoAtom<x86>::addRegularFDEOffsetFixup(uint32_t offset, const ld::Atom* fde)
@@ -473,12 +481,14 @@ void UnwindInfoAtom<x86_64>::addRegularFDEOffsetFixup(uint32_t offset, const ld:
 	_fixups.push_back(ld::Fixup(offset+4, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addRegularFDEOffsetFixup(uint32_t offset, const ld::Atom* fde)
 {
 	_fixups.push_back(ld::Fixup(offset+4, ld::Fixup::k1of2, ld::Fixup::kindSetTargetSectionOffset, fde));
 	_fixups.push_back(ld::Fixup(offset+4, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndianLow24of32));
 }
+#endif
 
 template <>
 void UnwindInfoAtom<x86>::addImageOffsetFixup(uint32_t offset, const ld::Atom* targ)
@@ -494,12 +504,14 @@ void UnwindInfoAtom<x86_64>::addImageOffsetFixup(uint32_t offset, const ld::Atom
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndian32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addImageOffsetFixup(uint32_t offset, const ld::Atom* targ)
 {
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of2, ld::Fixup::kindSetTargetImageOffset, targ));
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of2, ld::Fixup::kindStoreLittleEndian32));
 }
+#endif
 
 template <>
 void UnwindInfoAtom<x86>::addImageOffsetFixupPlusAddend(uint32_t offset, const ld::Atom* targ, uint32_t addend)
@@ -517,6 +529,7 @@ void UnwindInfoAtom<x86_64>::addImageOffsetFixupPlusAddend(uint32_t offset, cons
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k3of3, ld::Fixup::kindStoreLittleEndian32));
 }
 
+#if SUPPORT_ARCH_arm64
 template <>
 void UnwindInfoAtom<arm64>::addImageOffsetFixupPlusAddend(uint32_t offset, const ld::Atom* targ, uint32_t addend)
 {
@@ -524,6 +537,7 @@ void UnwindInfoAtom<arm64>::addImageOffsetFixupPlusAddend(uint32_t offset, const
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k2of3, ld::Fixup::kindAddAddend, addend));
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k3of3, ld::Fixup::kindStoreLittleEndian32));
 }
+#endif
 
 
 
diff --git a/src/ld/passes/dtrace_dof.cpp b/src/ld/passes/dtrace_dof.cpp
index 6f8a544..6a9b29b 100644
--- a/src/ld/passes/dtrace_dof.cpp
+++ b/src/ld/passes/dtrace_dof.cpp
@@ -141,15 +141,29 @@ void doPass(const Options& opts, ld::Internal& internal)
 			for (ld::Fixup::iterator fit = atom->fixupsBegin(), end=atom->fixupsEnd(); fit != end; ++fit) {
 				switch ( fit->kind ) {
 					case ld::Fixup::kindStoreX86DtraceCallSiteNop:
+#if SUPPORT_ARCH_ppc
+					case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+#endif
+#if SUPPORT_ARCH_arm_any
 					case ld::Fixup::kindStoreARMDtraceCallSiteNop:
 					case ld::Fixup::kindStoreThumbDtraceCallSiteNop:
+#endif
+#if SUPPORT_ARCH_arm64
 					case ld::Fixup::kindStoreARM64DtraceCallSiteNop:
+#endif
 						probeSites.push_back(DTraceProbeInfo(atom, fit->offsetInAtom, fit->u.name));
 						break;
 					case ld::Fixup::kindStoreX86DtraceIsEnableSiteClear:
+#if SUPPORT_ARCH_ppc
+					case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm_any
 					case ld::Fixup::kindStoreARMDtraceIsEnableSiteClear:
 					case ld::Fixup::kindStoreThumbDtraceIsEnableSiteClear:
+#endif
+#if SUPPORT_ARCH_arm64
 					case ld::Fixup::kindStoreARM64DtraceIsEnableSiteClear:
+#endif
 						isEnabledSites.push_back(DTraceProbeInfo(atom, fit->offsetInAtom, fit->u.name));
 						break;
 					case ld::Fixup::kindDtraceExtra:
@@ -168,12 +182,28 @@ void doPass(const Options& opts, ld::Internal& internal)
 	
 	ld::Fixup::Kind storeKind = ld::Fixup::kindNone;
 	switch ( opts.architecture() ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			storeKind = ld::Fixup::kindStoreBigEndian32;
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			storeKind = ld::Fixup::kindStoreBigEndian32;
+			break;
+#endif
 		case CPU_TYPE_I386:
 		case CPU_TYPE_X86_64:
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
+#endif
+#if SUPPORT_ARCH_arm64
 		case CPU_TYPE_ARM64:
+#endif
+#if SUPPORT_ARCH_arm_any || SUPPORT_ARCH_arm64
 			storeKind = ld::Fixup::kindStoreLittleEndian32;
 			break;
+#endif
 		default:
 			throw "unsupported arch for DOF";
 	}
diff --git a/src/ld/passes/objc.cpp b/src/ld/passes/objc.cpp
index d921a64..4b2513c 100644
--- a/src/ld/passes/objc.cpp
+++ b/src/ld/passes/objc.cpp
@@ -465,7 +465,9 @@ private:
 };
 
 template <> unsigned int Class<x86_64>::class_ro_header_size() { return 16; }
+#if SUPPORT_ARCH_arm_any
 template <> unsigned int Class<arm>::class_ro_header_size() { return 12;}
+#endif
 template <> unsigned int Class<x86>::class_ro_header_size() { return 12; }
 
 
@@ -602,6 +604,7 @@ void ClassROOverlayAtom<x86_64>::addMethodListFixup()
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian64, targetAtom));
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 void ClassROOverlayAtom<arm>::addMethodListFixup()
 {
@@ -609,6 +612,7 @@ void ClassROOverlayAtom<arm>::addMethodListFixup()
 	uint32_t offset = Class<arm>::class_ro_header_size() + 2*4; // class_ro_t.baseMethods
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian32, targetAtom));
 }
+#endif
 
 template <>
 void ClassROOverlayAtom<x86>::addMethodListFixup()
@@ -628,6 +632,7 @@ void ClassROOverlayAtom<x86_64>::addProtocolListFixup()
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian64, targetAtom));
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 void ClassROOverlayAtom<arm>::addProtocolListFixup()
 {
@@ -635,6 +640,7 @@ void ClassROOverlayAtom<arm>::addProtocolListFixup()
 	uint32_t offset = Class<arm>::class_ro_header_size() + 3*4; // class_ro_t.baseProtocols
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian32, targetAtom));
 }
+#endif
 
 template <>
 void ClassROOverlayAtom<x86>::addProtocolListFixup()
@@ -653,6 +659,7 @@ void ClassROOverlayAtom<x86_64>::addPropertyListFixup()
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian64, targetAtom));
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 void ClassROOverlayAtom<arm>::addPropertyListFixup()
 {
@@ -660,6 +667,7 @@ void ClassROOverlayAtom<arm>::addPropertyListFixup()
 	uint32_t offset = Class<arm>::class_ro_header_size() + 6*4; // class_ro_t.baseProperties
 	_fixups.push_back(ld::Fixup(offset, ld::Fixup::k1of1, ld::Fixup::kindStoreTargetAddressLittleEndian32, targetAtom));
 }
+#endif
 
 template <>
 void ClassROOverlayAtom<x86>::addPropertyListFixup()
@@ -1192,6 +1200,18 @@ void doPass(const Options& opts, ld::Internal& state)
 							true));
 				break;
 #endif
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+				state.addAtom(*new ObjCImageInfoAtom<ppc>(state.objcObjectConstraint, compaction,
+							false));
+				break;
+#endif
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+				state.addAtom(*new ObjCImageInfoAtom<ppc64>(state.objcObjectConstraint, compaction,
+							true));
+				break;
+#endif
 			default:
 				assert(0 && "unknown objc arch");
 		}	
@@ -1221,6 +1241,14 @@ void doPass(const Options& opts, ld::Internal& state)
 				// disabled until tested
 				break;
 #endif
+#if SUPPORT_ARCH_ppc64
+			case CPU_TYPE_POWERPC64:
+				break;
+#endif
+#if SUPPORT_ARCH_ppc
+			case CPU_TYPE_POWERPC:
+				break;
+#endif
 			default:
 				assert(0 && "unknown objc arch");
 		}	
diff --git a/src/ld/passes/stubs/stub_arm.hpp b/src/ld/passes/stubs/stub_arm.hpp
index 5c8fc42..8a2d324 100644
--- a/src/ld/passes/stubs/stub_arm.hpp
+++ b/src/ld/passes/stubs/stub_arm.hpp
@@ -22,6 +22,7 @@
  * @APPLE_LICENSE_HEADER_END@
  */
 
+#if SUPPORT_ARCH_arm_any
 // already in ld::passes::stubs namespace
 namespace arm {
 
@@ -480,4 +481,4 @@ ld::Section StubCloseAtom::_s_section("__TEXT", "__symbolstub1", ld::Section::ty
 
 
 } // namespace arm 
-
+#endif
diff --git a/src/ld/passes/stubs/stub_arm64.hpp b/src/ld/passes/stubs/stub_arm64.hpp
index 63382e5..81dc009 100644
--- a/src/ld/passes/stubs/stub_arm64.hpp
+++ b/src/ld/passes/stubs/stub_arm64.hpp
@@ -23,6 +23,7 @@
  */
 
 
+#if SUPPORT_ARCH_arm64
 // already in ld::passes::stubs namespace
 namespace arm64 {
 
@@ -393,4 +394,4 @@ ld::Section KextStubAtom::_s_section("__TEXT", "__stubs", ld::Section::typeCode)
 
 
 } // namespace x86_64 
-
+#endif
diff --git a/src/ld/passes/stubs/stub_arm_classic.hpp b/src/ld/passes/stubs/stub_arm_classic.hpp
index c7967d7..175527f 100644
--- a/src/ld/passes/stubs/stub_arm_classic.hpp
+++ b/src/ld/passes/stubs/stub_arm_classic.hpp
@@ -22,6 +22,7 @@
  * @APPLE_LICENSE_HEADER_END@
  */
 
+#if SUPPORT_ARCH_arm_any
 // already in ld::passes::stubs namespace
 namespace arm {
 namespace classic {
@@ -146,4 +147,4 @@ ld::Section StubNoPICAtom::_s_section("__TEXT", "__symbol_stub4", ld::Section::t
 
 } // namespace classic 
 } // namespace arm 
-
+#endif
diff --git a/src/ld/passes/stubs/stub_ppc_classic.hpp b/src/ld/passes/stubs/stub_ppc_classic.hpp
new file mode 100644
index 0000000..51c1717
--- /dev/null
+++ b/src/ld/passes/stubs/stub_ppc_classic.hpp
@@ -0,0 +1,191 @@
+/* -*- mode: C++; c-basic-offset: 4; tab-width: 4 -*-
+ *
+ * Copyright (c) 2009 Apple Inc. All rights reserved.
+ *
+ * @APPLE_LICENSE_HEADER_START@
+ *
+ * This file contains Original Code and/or Modifications of Original Code
+ * as defined in and that are subject to the Apple Public Source License
+ * Version 2.0 (the 'License'). You may not use this file except in
+ * compliance with the License. Please obtain a copy of the License at
+ * http://www.opensource.apple.com/apsl/ and read it before using this
+ * file.
+ *
+ * The Original Code and all software distributed under the License are
+ * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
+ * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
+ * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
+ * Please see the License for the specific language governing rights and
+ * limitations under the License.
+ *
+ * @APPLE_LICENSE_HEADER_END@
+ */
+
+
+#if SUPPORT_ARCH_ppc
+// already in ld::passes::stubs namespace
+namespace ppc {
+namespace classic {
+
+
+
+class LazyPointerAtom : public ld::Atom {
+public:
+	LazyPointerAtom(ld::passes::stubs::Pass& pass, const ld::Atom& stubTo,
+		bool forLazyDylib, bool for64, bool weakImport)
+		: ld::Atom( forLazyDylib ? _s_sectionLazy : _s_section,
+				ld::Atom::definitionRegular, ld::Atom::combineNever,
+				ld::Atom::scopeTranslationUnit,
+				forLazyDylib ? ld::Atom::typeLazyDylibPointer : ld::Atom::typeLazyPointer,
+				symbolTableNotIn, false, false, false, for64 ? ld::Atom::Alignment(3) : ld::Atom::Alignment(2)),
+			_stubTo(stubTo),
+			_fixup1(0, ld::Fixup::k1of1,
+			for64 ? ld::Fixup::kindStoreTargetAddressBigEndian64 : ld::Fixup::kindStoreTargetAddressBigEndian32,
+			forLazyDylib ? pass.internal()->lazyBindingHelper : pass.internal()->classicBindingHelper),
+			_fixup2(0, ld::Fixup::k1of1, ld::Fixup::kindLazyTarget, &stubTo),
+			_for64(for64)
+		{  _fixup2.weakImport = weakImport; pass.addAtom(*this);  }
+
+	virtual const ld::File*	file() const	{ return _stubTo.file(); }
+	virtual bool		translationUnitSource(const char** dir, const char** ) const
+		{ return false; }
+	virtual const char*	name() const		{ return _stubTo.name(); }
+	virtual uint64_t	size() const		{ return _for64 ? 8 : 4; }
+	virtual uint64_t	objectAddress() const	{ return 0; }
+	virtual void		copyRawContent(uint8_t buffer[]) const { }
+	virtual void		setScope(Scope)		{ }
+	virtual ld::Fixup::iterator	fixupsBegin() const	{ return &_fixup1; }
+	virtual ld::Fixup::iterator	fixupsEnd() const	{ return &((ld::Fixup*)&_fixup2)[1]; }
+
+private:
+	const ld::Atom&		_stubTo;
+	mutable ld::Fixup	_fixup1;
+	mutable ld::Fixup	_fixup2;
+	const bool		_for64;
+
+	static ld::Section	_s_section;
+	static ld::Section	_s_sectionLazy;
+};
+
+ld::Section LazyPointerAtom::_s_section("__DATA", "__la_symbol_ptr", ld::Section::typeLazyPointer);
+ld::Section LazyPointerAtom::_s_sectionLazy("__DATA", "__ld_symbol_ptr", ld::Section::typeLazyDylibPointer);
+
+
+
+class StubPICAtom : public ld::Atom {
+public:
+	StubPICAtom(ld::passes::stubs::Pass& pass, const ld::Atom& stubTo,
+		bool forLazyDylib, bool for64, bool weakImport)
+		: ld::Atom(_s_section, ld::Atom::definitionRegular, ld::Atom::combineNever,
+				ld::Atom::scopeLinkageUnit, ld::Atom::typeStub,
+				symbolTableNotIn, false, false, false, ld::Atom::Alignment(2)),
+			_stubTo(stubTo),
+			_lazyPointer(pass, stubTo, forLazyDylib, for64, weakImport),
+			_fixup1(12, ld::Fixup::k1of4, ld::Fixup::kindSetTargetAddress, &_lazyPointer),
+			_fixup2(12, ld::Fixup::k2of4, ld::Fixup::kindSubtractTargetAddress, this),
+			_fixup3(12, ld::Fixup::k3of4, ld::Fixup::kindSubtractAddend, 8),
+			_fixup4(12, ld::Fixup::k4of4, ld::Fixup::kindStorePPCPicHigh16AddLow),
+			_fixup5(20, ld::Fixup::k1of4, ld::Fixup::kindSetTargetAddress, &_lazyPointer),
+			_fixup6(20, ld::Fixup::k2of4, ld::Fixup::kindSubtractTargetAddress, this),
+			_fixup7(20, ld::Fixup::k3of4, ld::Fixup::kindSubtractAddend, 8),
+			_fixup8(20, ld::Fixup::k4of4, for64 ? ld::Fixup::kindStorePPCPicLow14 : ld::Fixup::kindStorePPCPicLow16),
+			_for64(for64)
+		{ pass.addAtom(*this); }
+
+	virtual const ld::File*	file() const	{ return _stubTo.file(); }
+	virtual bool		translationUnitSource(const char** dir, const char** ) const
+																			{ return false; }
+	virtual const char*	name() const		{ return _stubTo.name(); }
+	virtual uint64_t	size() const		{ return 32; }
+	virtual uint64_t	objectAddress() const	{ return 0; }
+	virtual void		copyRawContent(uint8_t buffer[]) const {
+		OSWriteBigInt32(&buffer[ 0], 0, 0x7c0802a6);	// mflr r0
+		OSWriteBigInt32(&buffer[ 4], 0, 0x429f0005);	// bcl 20,31,Lpicbase
+		OSWriteBigInt32(&buffer[ 8], 0, 0x7d6802a6);	// Lpicbase: mflr r11
+		OSWriteBigInt32(&buffer[12], 0, 0x3d6b0000);	// addis r11,r11,ha16(L_fwrite$lazy_ptr-Lpicbase)
+		OSWriteBigInt32(&buffer[16], 0, 0x7c0803a6);	// mtlr r0
+		if ( _for64 )
+			OSWriteBigInt32(&buffer[20], 0, 0xe98b0001);// ldu r12,lo16(L_fwrite$lazy_ptr-Lpicbase)(r11)
+		else
+			OSWriteBigInt32(&buffer[20], 0, 0x858b0000);// lwzu r12,lo16(L_fwrite$lazy_ptr-Lpicbase)(r11)
+		OSWriteBigInt32(&buffer[24], 0, 0x7d8903a6);	//  mtctr r12
+		OSWriteBigInt32(&buffer[28], 0, 0x4e800420);	//  bctr
+	}
+	virtual void			setScope(Scope)		{ }
+	virtual ld::Fixup::iterator	fixupsBegin() const	{ return &_fixup1; }
+	virtual ld::Fixup::iterator	fixupsEnd() const	{ return &((ld::Fixup*)&_fixup8)[1]; }
+
+private:
+	const ld::Atom&		_stubTo;
+	LazyPointerAtom		_lazyPointer;
+	mutable ld::Fixup	_fixup1;
+	mutable ld::Fixup	_fixup2;
+	mutable ld::Fixup	_fixup3;
+	mutable ld::Fixup	_fixup4;
+	mutable ld::Fixup	_fixup5;
+	mutable ld::Fixup	_fixup6;
+	mutable ld::Fixup	_fixup7;
+	mutable ld::Fixup	_fixup8;
+	const bool		_for64;
+
+	static ld::Section	_s_section;
+};
+
+ld::Section StubPICAtom::_s_section("__TEXT", "__picsymbolstub1", ld::Section::typeStub);
+
+
+
+class StubNoPICAtom : public ld::Atom {
+public:
+	StubNoPICAtom(ld::passes::stubs::Pass& pass, const ld::Atom& stubTo,
+		bool forLazyDylib, bool for64, bool weakImport)
+			: ld::Atom(_s_section, ld::Atom::definitionRegular, ld::Atom::combineNever,
+				ld::Atom::scopeLinkageUnit, ld::Atom::typeStub,
+				symbolTableNotIn, false, false, false, ld::Atom::Alignment(2)),
+			_stubTo(stubTo),
+			_lazyPointer(pass, stubTo, forLazyDylib, for64, weakImport),
+			_fixup1(0, ld::Fixup::k1of2, ld::Fixup::kindSetTargetAddress, &_lazyPointer),
+			_fixup2(0, ld::Fixup::k2of2, ld::Fixup::kindStorePPCAbsHigh16AddLow),
+			_fixup3(4, ld::Fixup::k1of2, ld::Fixup::kindSetTargetAddress, &_lazyPointer),
+			_fixup4(4, ld::Fixup::k2of2, for64 ? ld::Fixup::kindStorePPCAbsLow14 : ld::Fixup::kindStorePPCAbsLow16),
+			_for64(for64)
+		{ pass.addAtom(*this); }
+
+	virtual const ld::File*	file() const	{ return _stubTo.file(); }
+	virtual bool		translationUnitSource(const char** dir, const char** ) const
+		{ return false; }
+	virtual const char*	name() const		{ return _stubTo.name(); }
+	virtual uint64_t	size() const		{ return 16; }
+	virtual uint64_t	objectAddress() const	{ return 0; }
+	virtual void		copyRawContent(uint8_t buffer[]) const {
+		OSWriteBigInt32(&buffer[ 0], 0, 0x3d600000);	// lis r11,ha16(L_foo$lazy_ptr)
+		if ( _for64 )
+			OSWriteBigInt32(&buffer[ 4], 0, 0xe98b0001);// ldu r12,lo16(L_foo$lazy_ptr)(r11)
+		else
+			OSWriteBigInt32(&buffer[ 4], 0, 0x858b0000);// lwzu r12,lo16(L_foo$lazy_ptr)(r11)
+		OSWriteBigInt32(&buffer[ 8], 0, 0x7d8903a6);	// mtctr r12
+		OSWriteBigInt32(&buffer[12], 0, 0x4e800420);	// bctr
+	}
+	virtual void			setScope(Scope)		{ }
+	virtual ld::Fixup::iterator	fixupsBegin() const	{ return &_fixup1; }
+	virtual ld::Fixup::iterator	fixupsEnd() const	{ return &((ld::Fixup*)&_fixup4)[1]; }
+
+private:
+	const ld::Atom&		_stubTo;
+	LazyPointerAtom		_lazyPointer;
+	mutable ld::Fixup	_fixup1;
+	mutable ld::Fixup	_fixup2;
+	mutable ld::Fixup	_fixup3;
+	mutable ld::Fixup	_fixup4;
+	const bool		_for64;
+
+	static ld::Section	_s_section;
+};
+
+ld::Section StubNoPICAtom::_s_section("__TEXT", "__symbol_stub1", ld::Section::typeStub);
+
+
+} // namespace classic
+} // namespace ppc
+#endif
diff --git a/src/ld/passes/stubs/stubs.cpp b/src/ld/passes/stubs/stubs.cpp
index c01f3f9..e9d8449 100644
--- a/src/ld/passes/stubs/stubs.cpp
+++ b/src/ld/passes/stubs/stubs.cpp
@@ -93,6 +93,7 @@ private:
 #if SUPPORT_ARCH_arm64
 #include "stub_arm64.hpp"
 #endif
+#include "stub_ppc_classic.hpp"
 
 Pass::Pass(const Options& opts) 
 	:	compressedHelperHelper(NULL), 
@@ -117,9 +118,14 @@ const ld::Atom* Pass::stubableFixup(const ld::Fixup* fixup, ld::Internal& state)
 	if ( fixup->binding == ld::Fixup::bindingsIndirectlyBound ) {
 		const ld::Atom* target = state.indirectBindingTable[fixup->u.bindingIndex];
 		switch ( fixup->kind ) {
+#if SUPPORT_ARCH_ppc
+			case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+#endif
 			case ld::Fixup::kindStoreTargetAddressX86BranchPCRel32:
+#if SUPPORT_ARCH_arm_any
 			case ld::Fixup::kindStoreTargetAddressARMBranch24:
 			case ld::Fixup::kindStoreTargetAddressThumbBranch22:
+#endif
 #if SUPPORT_ARCH_arm64
 			case ld::Fixup::kindStoreTargetAddressARM64Branch26:
 #endif
@@ -181,6 +187,19 @@ ld::Atom* Pass::makeStub(const ld::Atom& target, bool weakImport)
 	}
 
 	switch ( _architecture ) {
+#if SUPPORT_ARCH_ppc
+		case CPU_TYPE_POWERPC:
+			if ( _pic )
+				return new ld::passes::stubs::ppc::classic::StubPICAtom(*this, target, forLazyDylib, false, weakImport);
+			else
+				return new ld::passes::stubs::ppc::classic::StubNoPICAtom(*this, target, forLazyDylib, false, weakImport);
+			break;
+#endif
+#if SUPPORT_ARCH_ppc64
+		case CPU_TYPE_POWERPC64:
+			return new ld::passes::stubs::ppc::classic::StubPICAtom(*this, target, forLazyDylib, true, weakImport);
+			break;
+#endif
 #if SUPPORT_ARCH_i386
 		case CPU_TYPE_I386:
 			if ( usingCompressedLINKEDIT() && !forLazyDylib )
@@ -324,8 +343,15 @@ void Pass::process(ld::Internal& state)
 				if ( _options.outputKind() != Options::kDynamicLibrary ) 
 					throwf("resolver functions (%s) can only be used in dylibs", atom->name());
 				if ( !_options.makeCompressedDyldInfo() ) {
-					if ( _options.architecture() == CPU_TYPE_ARM )
+					if ( 0 ) { }
+#if SUPPORT_ARCH_arm_any
+					else if ( _options.architecture() == CPU_TYPE_ARM )
 						throwf("resolver functions (%s) can only be used when targeting iOS 4.2 or later", atom->name());
+#endif
+#if SUPPORT_ARCH_ppc
+					else if ( _options.architecture() == CPU_TYPE_POWERPC )
+						throwf("resolver functions (%s) not supported for PowerPC", atom->name());
+#endif
 					else
 						throwf("resolver functions (%s) can only be used when targeting Mac OS X 10.6 or later", atom->name());
 				}
@@ -353,6 +379,7 @@ void Pass::process(ld::Internal& state)
 	if ( !_options.makeCompressedDyldInfo() && (state.classicBindingHelper == NULL) && (_options.outputKind() != Options::kKextBundle) ) 
 		throw "symbol dyld_stub_binding_helper not found, normally in crt1.o/dylib1.o/bundle1.o";
 
+#if SUPPORT_ARCH_arm_any
 	// disable arm close stubs in some cases
 	if ( _architecture == CPU_TYPE_ARM ) {
         if ( codeSize > 4*1024*1024 )
@@ -377,6 +404,7 @@ void Pass::process(ld::Internal& state)
             }
         }
     }
+#endif
 	
 	// make stub atoms 
 	for (std::map<const ld::Atom*,ld::Atom*>::iterator it = stubFor.begin(); it != stubFor.end(); ++it) {
diff --git a/src/other/ObjectDump.cpp b/src/other/ObjectDump.cpp
index c9eb46c..349c102 100644
--- a/src/other/ObjectDump.cpp
+++ b/src/other/ObjectDump.cpp
@@ -276,8 +276,10 @@ static void dumpAtom(ld::Atom* atom)
 		printf("attrs:   ");
 		if ( atom->dontDeadStrip() )
 			printf("dont-dead-strip ");
+#if SUPPORT_ARCH_arm_any
 		if ( atom->isThumb() )
 			printf("thumb ");
+#endif
 		printf("\n");
 	}
 	
@@ -548,8 +550,10 @@ const char*	dumper::attributeString(const ld::Atom& atom)
 	if ( atom.dontDeadStrip() )
 		strcat(buffer, "dont-dead-strip ");
 
+#if SUPPORT_ARCH_arm_any
 	if ( atom.isThumb() )
 		strcat(buffer, "thumb ");
+#endif
 		
 	if ( atom.isAlias() )
 		strcat(buffer, "alias ");
@@ -738,6 +742,35 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreBigEndian64:
 			printf(", then store 64-bit big endian");
 			break;
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCBranch24:
+			printf(", then store as PPC branch24");
+			break;
+		case ld::Fixup::kindStorePPCBranch14:
+			printf(", then store as PPC branch14");
+			break;
+		case ld::Fixup::kindStorePPCPicLow14:
+			printf(", then store as PPC low14 pic");
+			break;
+		case ld::Fixup::kindStorePPCPicLow16:
+			printf(", then store as PPC low14 pic");
+			break;
+		case ld::Fixup::kindStorePPCPicHigh16AddLow:
+			printf(", then store as PPC high16 pic");
+			break;
+		case ld::Fixup::kindStorePPCAbsLow14:
+			printf(", then store as PPC low14 abs");
+			break;
+		case ld::Fixup::kindStorePPCAbsLow16:
+			printf(", then store as PPC low14 abs");
+			break;
+		case ld::Fixup::kindStorePPCAbsHigh16AddLow:
+			printf(", then store as PPC high16 abs");
+			break;
+		case ld::Fixup::kindStorePPCAbsHigh16:
+			printf(", then store as PPC high16 abs, no carry");
+			break;
+#endif
 		case ld::Fixup::kindStoreX86BranchPCRel8:
 			printf(", then store as x86 8-bit pcrel branch");
 			break;
@@ -783,6 +816,7 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreX86Abs32TLVLoadNowLEA:
 			printf(", then store as x86 32-bit absolute TLV load -> LEA");
 			break;
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMBranch24:
 			printf(", then store as ARM 24-bit pcrel branch");
 			break;
@@ -804,6 +838,8 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreThumbHigh16:
 			printf(", then store high-16 in Thumb movt");
 			break;
+#endif
+#if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreARM64Branch26:
 			printf(", then store as ARM64 26-bit pcrel branch");
 			break;
@@ -837,6 +873,7 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreARM64PCRelToGOT:
 			printf(", then store as 32-bit delta to GOT entry");
 			break;
+#endif
 		case ld::Fixup::kindDtraceExtra:
 			printf("dtrace static probe extra info");
 			break;
@@ -846,6 +883,15 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreX86DtraceIsEnableSiteClear:
 			printf("x86 dtrace static is-enabled site");
 			break;
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStorePPCDtraceCallSiteNop:
+			printf("ppc dtrace static probe site");
+			break;
+		case ld::Fixup::kindStorePPCDtraceIsEnableSiteClear:
+			printf("ppc dtrace static is-enabled site");
+			break;
+#endif
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreARMDtraceCallSiteNop:
 			printf("ARM dtrace static probe site");
 			break;
@@ -858,12 +904,15 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreThumbDtraceIsEnableSiteClear:
 			printf("Thumb dtrace static is-enabled site");
 			break;
+#endif
+#if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreARM64DtraceCallSiteNop:
 			printf("ARM64 dtrace static probe site");
 			break;
 		case ld::Fixup::kindStoreARM64DtraceIsEnableSiteClear:
 			printf("ARM64 dtrace static is-enabled site");
 			break;
+#endif
 		case ld::Fixup::kindLazyTarget:
 			printf("lazy reference to external symbol %s", referenceTargetAtomName(ref));
 			break;
@@ -967,6 +1016,7 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreTargetAddressX86Abs32TLVLoadNowLEA:
 			printf("x86 store 32-bit absolute TLV lea of %s", referenceTargetAtomName(ref));
 			break;
+#if SUPPORT_ARCH_arm_any
 		case ld::Fixup::kindStoreTargetAddressARMBranch24:
 			printf("ARM store 24-bit pc-rel branch to %s", referenceTargetAtomName(ref));
 			break;
@@ -976,11 +1026,18 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreTargetAddressARMLoad12:
 			printf("ARM store 12-bit pc-rel branch to %s", referenceTargetAtomName(ref));
 			break;
+#endif
+#if SUPPORT_ARCH_ppc
+		case ld::Fixup::kindStoreTargetAddressPPCBranch24:
+			printf("PowerPC store 24-bit pc-rel load of %s", referenceTargetAtomName(ref));
+			break;
+#endif
 		case ld::Fixup::kindSetTargetTLVTemplateOffset:
 		case ld::Fixup::kindSetTargetTLVTemplateOffsetLittleEndian32:
 		case ld::Fixup::kindSetTargetTLVTemplateOffsetLittleEndian64:
 			printf("tlv template offset of %s", referenceTargetAtomName(ref));
 			break;
+#if SUPPORT_ARCH_arm64
 		case ld::Fixup::kindStoreTargetAddressARM64Branch26:
 			printf("ARM64 store 26-bit pcrel branch to %s", referenceTargetAtomName(ref));
 			break;
@@ -1008,6 +1065,7 @@ void dumper::dumpFixup(const ld::Fixup* ref)
 		case ld::Fixup::kindStoreTargetAddressARM64GOTLeaPageOff12:
 			printf("ARM64 store 12-bit page offset of lea of %s", referenceTargetAtomName(ref));
 			break;
+#endif
 		//default:
 		//	printf("unknown fixup");
 		//	break;
diff --git a/src/other/dyldinfo.cpp b/src/other/dyldinfo.cpp
index 6ac3311..421ec24 100644
--- a/src/other/dyldinfo.cpp
+++ b/src/other/dyldinfo.cpp
@@ -155,6 +155,7 @@ private:
 
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 bool DyldInfoPrinter<ppc>::validFile(const uint8_t* fileContent)
 {	
@@ -173,7 +174,9 @@ bool DyldInfoPrinter<ppc>::validFile(const uint8_t* fileContent)
 	}
 	return false;
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 bool DyldInfoPrinter<ppc64>::validFile(const uint8_t* fileContent)
 {	
@@ -192,6 +195,7 @@ bool DyldInfoPrinter<ppc64>::validFile(const uint8_t* fileContent)
 	}
 	return false;
 }
+#endif
 
 template <>
 bool DyldInfoPrinter<x86>::validFile(const uint8_t* fileContent)
@@ -1755,6 +1759,7 @@ void DyldInfoPrinter<A>::printDataInCode()
 
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 ppc::P::uint_t DyldInfoPrinter<ppc>::relocBase()
 {
@@ -1763,7 +1768,9 @@ ppc::P::uint_t DyldInfoPrinter<ppc>::relocBase()
 	else
 		return fFirstSegment->vmaddr();
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 ppc64::P::uint_t DyldInfoPrinter<ppc64>::relocBase()
 {
@@ -1772,6 +1779,7 @@ ppc64::P::uint_t DyldInfoPrinter<ppc64>::relocBase()
 	else
 		return fFirstSegment->vmaddr();
 }
+#endif
 
 template <>
 x86::P::uint_t DyldInfoPrinter<x86>::relocBase()
@@ -1807,15 +1815,20 @@ arm64::P::uint_t DyldInfoPrinter<arm64>::relocBase()
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
 template <>
 const char*	DyldInfoPrinter<ppc>::relocTypeName(uint8_t r_type)
 {
 	if ( r_type == GENERIC_RELOC_VANILLA )
 		return "pointer";
+	else if ( r_type == PPC_RELOC_PB_LA_PTR )
+		return "pb pointer";
 	else
 		return "??";
 }
+#endif
 	
+#if SUPPORT_ARCH_ppc64
 template <>
 const char*	DyldInfoPrinter<ppc64>::relocTypeName(uint8_t r_type)
 {
@@ -1824,6 +1837,7 @@ const char*	DyldInfoPrinter<ppc64>::relocTypeName(uint8_t r_type)
 	else
 		return "??";
 }
+#endif
 	
 template <>
 const char*	DyldInfoPrinter<x86>::relocTypeName(uint8_t r_type)
@@ -1943,8 +1957,10 @@ void DyldInfoPrinter<A>::printSymbolTableExportInfo()
 			if ( sym->n_desc() & N_WEAK_DEF )
 				flags = "[weak_def] ";
 			pint_t thumb = 0;
+#if SUPPORT_ARCH_arm_any
 			if ( sym->n_desc() & N_ARM_THUMB_DEF )
 				thumb = 1;
+#endif
 			printf("0x%08llX %s%s\n", sym->n_value()+thumb, flags, &fStrings[sym->n_strx()]);
 		}
 	}
@@ -2133,24 +2149,28 @@ static void dump(const char* path)
 					&& ((sPreferredSubArch==0) || (sPreferredSubArch==cpusubtype)))
 					|| (sPreferredArch == 0) ) {	
 					switch(cputype) {
+#if SUPPORT_ARCH_ppc
 					case CPU_TYPE_POWERPC:
 						if ( DyldInfoPrinter<ppc>::validFile(p + offset) )
 							DyldInfoPrinter<ppc>::make(p + offset, size, path, (sPreferredArch == 0));
 						else
 							throw "in universal file, ppc slice does not contain ppc mach-o";
 						break;
+#endif
 					case CPU_TYPE_I386:
 						if ( DyldInfoPrinter<x86>::validFile(p + offset) )
 							DyldInfoPrinter<x86>::make(p + offset, size, path, (sPreferredArch == 0));
 						else
 							throw "in universal file, i386 slice does not contain i386 mach-o";
 						break;
+#if SUPPORT_ARCH_ppc64
 					case CPU_TYPE_POWERPC64:
 						if ( DyldInfoPrinter<ppc64>::validFile(p + offset) )
 							DyldInfoPrinter<ppc64>::make(p + offset, size, path, (sPreferredArch == 0));
 						else
 							throw "in universal file, ppc64 slice does not contain ppc64 mach-o";
 						break;
+#endif
 					case CPU_TYPE_X86_64:
 						if ( DyldInfoPrinter<x86_64>::validFile(p + offset) )
 							DyldInfoPrinter<x86_64>::make(p + offset, size, path, (sPreferredArch == 0));
@@ -2182,12 +2202,16 @@ static void dump(const char* path)
 		else if ( DyldInfoPrinter<x86>::validFile(p) ) {
 			DyldInfoPrinter<x86>::make(p, length, path, false);
 		}
+#if SUPPORT_ARCH_ppc
 		else if ( DyldInfoPrinter<ppc>::validFile(p) ) {
 			DyldInfoPrinter<ppc>::make(p, length, path, false);
 		}
+#endif
+#if SUPPORT_ARCH_ppc64
 		else if ( DyldInfoPrinter<ppc64>::validFile(p) ) {
 			DyldInfoPrinter<ppc64>::make(p, length, path, false);
 		}
+#endif
 		else if ( DyldInfoPrinter<x86_64>::validFile(p) ) {
 			DyldInfoPrinter<x86_64>::make(p, length, path, false);
 		}
@@ -2242,10 +2266,15 @@ int main(int argc, const char* argv[])
 			if ( arg[0] == '-' ) {
 				if ( strcmp(arg, "-arch") == 0 ) {
 					const char* arch = ++i<argc? argv[i]: "";
-					if ( strcmp(arch, "ppc64") == 0 )
+					if (0) { }
+#if SUPPORT_ARCH_ppc64
+					else if ( strcmp(arch, "ppc64") == 0 )
 						sPreferredArch = CPU_TYPE_POWERPC64;
+#endif
+#if SUPPORT_ARCH_ppc
 					else if ( strcmp(arch, "ppc") == 0 )
 						sPreferredArch = CPU_TYPE_POWERPC;
+#endif
 					else if ( strcmp(arch, "i386") == 0 )
 						sPreferredArch = CPU_TYPE_I386;
 					else if ( strcmp(arch, "x86_64") == 0 )
@@ -2257,6 +2286,7 @@ int main(int argc, const char* argv[])
 					else {
 						if ( arch == NULL )
 							throw "-arch missing architecture name";
+#if SUPPORT_ARCH_arm_any
 						bool found = false;
 						for (const ArchInfo* t=archInfoArray; t->archName != NULL; ++t) {
 							if ( strcmp(t->archName,arch) == 0 ) {
@@ -2268,6 +2298,7 @@ int main(int argc, const char* argv[])
 							}
 						}
 						if ( !found )
+#endif
 							throwf("unknown architecture %s", arch);
 					}
 				}
diff --git a/src/other/machochecker.cpp b/src/other/machochecker.cpp
index aec6ebe..beca980 100644
--- a/src/other/machochecker.cpp
+++ b/src/other/machochecker.cpp
@@ -174,6 +174,7 @@ private:
 
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 bool MachOChecker<ppc>::validFile(const uint8_t* fileContent)
 {	
@@ -191,7 +192,9 @@ bool MachOChecker<ppc>::validFile(const uint8_t* fileContent)
 	}
 	return false;
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 bool MachOChecker<ppc64>::validFile(const uint8_t* fileContent)
 {	
@@ -209,6 +212,7 @@ bool MachOChecker<ppc64>::validFile(const uint8_t* fileContent)
 	}
 	return false;
 }
+#endif
 
 template <>
 bool MachOChecker<x86>::validFile(const uint8_t* fileContent)
@@ -246,6 +250,7 @@ bool MachOChecker<x86_64>::validFile(const uint8_t* fileContent)
 	return false;
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 bool MachOChecker<arm>::validFile(const uint8_t* fileContent)
 {	
@@ -263,6 +268,7 @@ bool MachOChecker<arm>::validFile(const uint8_t* fileContent)
 	}
 	return false;
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -284,27 +290,37 @@ bool MachOChecker<arm64>::validFile(const uint8_t* fileContent)
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
 template <> uint8_t MachOChecker<ppc>::loadCommandSizeMask()	{ return 0x03; }
+#endif
+#if SUPPORT_ARCH_ppc64
 template <> uint8_t MachOChecker<ppc64>::loadCommandSizeMask()	{ return 0x07; }
+#endif
 template <> uint8_t MachOChecker<x86>::loadCommandSizeMask()	{ return 0x03; }
 template <> uint8_t MachOChecker<x86_64>::loadCommandSizeMask() { return 0x07; }
+#if SUPPORT_ARCH_arm_any
 template <> uint8_t MachOChecker<arm>::loadCommandSizeMask()	{ return 0x03; }
+#endif
 #if SUPPORT_ARCH_arm64
 template <> uint8_t MachOChecker<arm64>::loadCommandSizeMask()	{ return 0x07; }
 #endif
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 ppc::P::uint_t MachOChecker<ppc>::getInitialStackPointer(const macho_thread_command<ppc::P>* threadInfo)
 {
 	return threadInfo->thread_register(3);
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 ppc64::P::uint_t MachOChecker<ppc64>::getInitialStackPointer(const macho_thread_command<ppc64::P>* threadInfo)
 {
 	return threadInfo->thread_register(3);
 }
+#endif
 
 template <>
 x86::P::uint_t MachOChecker<x86>::getInitialStackPointer(const macho_thread_command<x86::P>* threadInfo)
@@ -318,11 +334,13 @@ x86_64::P::uint_t MachOChecker<x86_64>::getInitialStackPointer(const macho_threa
 	return threadInfo->thread_register(7);
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 arm::P::uint_t MachOChecker<arm>::getInitialStackPointer(const macho_thread_command<arm::P>* threadInfo)
 {
 	return threadInfo->thread_register(13);
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -332,17 +350,21 @@ arm64::P::uint_t MachOChecker<arm64>::getInitialStackPointer(const macho_thread_
 }
 #endif
 
+#if SUPPORT_ARCH_ppc
 template <>
 ppc::P::uint_t MachOChecker<ppc>::getEntryPoint(const macho_thread_command<ppc::P>* threadInfo)
 {
 	return threadInfo->thread_register(0);
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 ppc64::P::uint_t MachOChecker<ppc64>::getEntryPoint(const macho_thread_command<ppc64::P>* threadInfo)
 {
 	return threadInfo->thread_register(0);
 }
+#endif
 
 template <>
 x86::P::uint_t MachOChecker<x86>::getEntryPoint(const macho_thread_command<x86::P>* threadInfo)
@@ -356,11 +378,13 @@ x86_64::P::uint_t MachOChecker<x86_64>::getEntryPoint(const macho_thread_command
 	return threadInfo->thread_register(16);
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 arm::P::uint_t MachOChecker<arm>::getEntryPoint(const macho_thread_command<arm::P>* threadInfo)
 {
 	return threadInfo->thread_register(15);
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -985,6 +1009,7 @@ void MachOChecker<A>::checkInitTerms()
 }
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 ppc::P::uint_t MachOChecker<ppc>::relocBase()
 {
@@ -993,7 +1018,9 @@ ppc::P::uint_t MachOChecker<ppc>::relocBase()
 	else
 		return fFirstSegment->vmaddr();
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 ppc64::P::uint_t MachOChecker<ppc64>::relocBase()
 {
@@ -1002,6 +1029,7 @@ ppc64::P::uint_t MachOChecker<ppc64>::relocBase()
 	else
 		return fFirstSegment->vmaddr();
 }
+#endif
 
 template <>
 x86::P::uint_t MachOChecker<x86>::relocBase()
@@ -1019,6 +1047,7 @@ x86_64::P::uint_t MachOChecker<x86_64>::relocBase()
 	return fFirstWritableSegment->vmaddr();
 }
 
+#if SUPPORT_ARCH_arm_any
 template <>
 arm::P::uint_t MachOChecker<arm>::relocBase()
 {
@@ -1027,6 +1056,7 @@ arm::P::uint_t MachOChecker<arm>::relocBase()
 	else
 		return fFirstSegment->vmaddr();
 }
+#endif
 
 #if SUPPORT_ARCH_arm64
 template <>
@@ -1068,6 +1098,7 @@ bool MachOChecker<A>::addressInWritableSegment(pint_t address)
 }
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 void MachOChecker<ppc>::checkExternalReloation(const macho_relocation_info<P>* reloc)
 {
@@ -1083,7 +1114,9 @@ void MachOChecker<ppc>::checkExternalReloation(const macho_relocation_info<P>* r
 		throw "external relocation address not in writable segment";
 	// FIX: check r_symbol
 }
+#endif
 
+#if SUPPORT_ARCH_ppc64
 template <>
 void MachOChecker<ppc64>::checkExternalReloation(const macho_relocation_info<P>* reloc)
 {
@@ -1099,6 +1132,7 @@ void MachOChecker<ppc64>::checkExternalReloation(const macho_relocation_info<P>*
 		throw "external relocation address not in writable segment";
 	// FIX: check r_symbol
 }
+#endif
 
 template <>
 void MachOChecker<x86>::checkExternalReloation(const macho_relocation_info<P>* reloc)
@@ -1160,6 +1194,7 @@ void MachOChecker<arm64>::checkExternalReloation(const macho_relocation_info<P>*
 #endif
 
 
+#if SUPPORT_ARCH_ppc
 template <>
 void MachOChecker<ppc>::checkLocalReloation(const macho_relocation_info<P>* reloc)
 {
@@ -1170,13 +1205,18 @@ void MachOChecker<ppc>::checkLocalReloation(const macho_relocation_info<P>* relo
 	
 	}
 	else {
+		// ignore pair relocs
+		if ( reloc->r_type() == PPC_RELOC_PAIR )
+			return;
 		// FIX
 		if ( ! this->addressInWritableSegment(reloc->r_address() + this->relocBase()) )
 			throwf("local relocation address 0x%08X not in writable segment", reloc->r_address());
 	}
 }
+#endif
 
 
+#if SUPPORT_ARCH_ppc64
 template <>
 void MachOChecker<ppc64>::checkLocalReloation(const macho_relocation_info<P>* reloc)
 {
@@ -1191,6 +1231,7 @@ void MachOChecker<ppc64>::checkLocalReloation(const macho_relocation_info<P>* re
 	if ( ! this->addressInWritableSegment(reloc->r_address() + this->relocBase()) )
 		throw "local relocation address not in writable segment";
 }
+#endif
 
 template <>
 void MachOChecker<x86>::checkLocalReloation(const macho_relocation_info<P>* reloc)
@@ -1610,24 +1651,28 @@ static void check(const char* path)
 				unsigned int cputype = OSSwapBigToHostInt32(archs[i].cputype);
 
 				switch(cputype) {
+#if SUPPORT_ARCH_ppc
 				case CPU_TYPE_POWERPC:
 					if ( MachOChecker<ppc>::validFile(p + offset) )
 						MachOChecker<ppc>::make(p + offset, size, path);
 					else
 						throw "in universal file, ppc slice does not contain ppc mach-o";
 					break;
+#endif
 				case CPU_TYPE_I386:
 					if ( MachOChecker<x86>::validFile(p + offset) )
 						MachOChecker<x86>::make(p + offset, size, path);
 					else
 						throw "in universal file, i386 slice does not contain i386 mach-o";
 					break;
+#if SUPPORT_ARCH_ppc64
 				case CPU_TYPE_POWERPC64:
 					if ( MachOChecker<ppc64>::validFile(p + offset) )
 						MachOChecker<ppc64>::make(p + offset, size, path);
 					else
 						throw "in universal file, ppc64 slice does not contain ppc64 mach-o";
 					break;
+#endif
 				case CPU_TYPE_X86_64:
 					if ( MachOChecker<x86_64>::validFile(p + offset) )
 						MachOChecker<x86_64>::make(p + offset, size, path);
@@ -1650,12 +1695,16 @@ static void check(const char* path)
 		else if ( MachOChecker<x86>::validFile(p) ) {
 			MachOChecker<x86>::make(p, length, path);
 		}
+#if SUPPORT_ARCH_ppc
 		else if ( MachOChecker<ppc>::validFile(p) ) {
 			MachOChecker<ppc>::make(p, length, path);
 		}
+#endif
+#if SUPPORT_ARCH_ppc64
 		else if ( MachOChecker<ppc64>::validFile(p) ) {
 			MachOChecker<ppc64>::make(p, length, path);
 		}
+#endif
 		else if ( MachOChecker<x86_64>::validFile(p) ) {
 			MachOChecker<x86_64>::make(p, length, path);
 		}
diff --git a/src/other/rebase.cpp b/src/other/rebase.cpp
index e2776cf..6e973bc 100644
--- a/src/other/rebase.cpp
+++ b/src/other/rebase.cpp
@@ -148,21 +148,27 @@ MultiArchRebaser::MultiArchRebaser(const char* path, bool writable)
 			uint32_t fileOffset = OSSwapBigToHostInt32(archs[i].offset);
 			try {
 				switch ( OSSwapBigToHostInt32(archs[i].cputype) ) {
+#if SUPPORT_ARCH_ppc
 					case CPU_TYPE_POWERPC:
 						fRebasers.push_back(new Rebaser<ppc>(&p[fileOffset]));
 						break;
+#endif
+#if SUPPORT_ARCH_ppc64
 					case CPU_TYPE_POWERPC64:
 						fRebasers.push_back(new Rebaser<ppc64>(&p[fileOffset]));
 						break;
+#endif
 					case CPU_TYPE_I386:
 						fRebasers.push_back(new Rebaser<x86>(&p[fileOffset]));
 						break;
 					case CPU_TYPE_X86_64:
 						fRebasers.push_back(new Rebaser<x86_64>(&p[fileOffset]));
 						break;
+#if SUPPORT_ARCH_arm_any
 					case CPU_TYPE_ARM:
 						fRebasers.push_back(new Rebaser<arm>(&p[fileOffset]));
 						break;
+#endif
 					default:
 						throw "unknown file format";
 				}
@@ -174,21 +180,28 @@ MultiArchRebaser::MultiArchRebaser(const char* path, bool writable)
 	}
 	else {
 		try {
-			if ( (OSSwapBigToHostInt32(mh->magic) == MH_MAGIC) && (OSSwapBigToHostInt32(mh->cputype) == CPU_TYPE_POWERPC)) {
+			if (0) { }
+#if SUPPORT_ARCH_ppc
+			else if ( (OSSwapBigToHostInt32(mh->magic) == MH_MAGIC) && (OSSwapBigToHostInt32(mh->cputype) == CPU_TYPE_POWERPC)) {
 				fRebasers.push_back(new Rebaser<ppc>(mh));
 			}
+#endif
+#if SUPPORT_ARCH_ppc64
 			else if ( (OSSwapBigToHostInt32(mh->magic) == MH_MAGIC_64) && (OSSwapBigToHostInt32(mh->cputype) == CPU_TYPE_POWERPC64)) {
 				fRebasers.push_back(new Rebaser<ppc64>(mh));
 			}
+#endif
 			else if ( (OSSwapLittleToHostInt32(mh->magic) == MH_MAGIC) && (OSSwapLittleToHostInt32(mh->cputype) == CPU_TYPE_I386)) {
 				fRebasers.push_back(new Rebaser<x86>(mh));
 			}
 			else if ( (OSSwapLittleToHostInt32(mh->magic) == MH_MAGIC_64) && (OSSwapLittleToHostInt32(mh->cputype) == CPU_TYPE_X86_64)) {
 				fRebasers.push_back(new Rebaser<x86_64>(mh));
 			}
+#if SUPPORT_ARCH_arm_any
 			else if ( (OSSwapLittleToHostInt32(mh->magic) == MH_MAGIC) && (OSSwapLittleToHostInt32(mh->cputype) == CPU_TYPE_ARM)) {
 				fRebasers.push_back(new Rebaser<arm>(mh));
 			}
+#endif
 			else {
 				throw "unknown file format";
 			}
@@ -232,11 +245,17 @@ Rebaser<A>::Rebaser(const void* machHeader)
 		
 }
 
+#if SUPPORT_ARCH_ppc
 template <> cpu_type_t Rebaser<ppc>::getArchitecture()    const { return CPU_TYPE_POWERPC; }
+#endif
+#if SUPPORT_ARCH_ppc64
 template <> cpu_type_t Rebaser<ppc64>::getArchitecture()  const { return CPU_TYPE_POWERPC64; }
+#endif
 template <> cpu_type_t Rebaser<x86>::getArchitecture()    const { return CPU_TYPE_I386; }
 template <> cpu_type_t Rebaser<x86_64>::getArchitecture() const { return CPU_TYPE_X86_64; }
+#if SUPPORT_ARCH_arm_any
 template <> cpu_type_t Rebaser<arm>::getArchitecture() const { return CPU_TYPE_ARM; }
+#endif
 
 template <typename A>
 uint64_t Rebaser<A>::getBaseAddress() const
@@ -641,6 +660,7 @@ void Rebaser<x86_64>::doLocalRelocation(const macho_relocation_info<x86_64::P>*
 	}
 }
 
+#if SUPPORT_ARCH_ppc
 template <>
 void Rebaser<ppc>::doLocalRelocation(const macho_relocation_info<P>* reloc)
 {
@@ -651,9 +671,15 @@ void Rebaser<ppc>::doLocalRelocation(const macho_relocation_info<P>* reloc)
 		}
 	}
 	else {
+		macho_scattered_relocation_info<P>* sreloc = (macho_scattered_relocation_info<P>*)reloc;
+		if ( sreloc->r_type() == PPC_RELOC_PB_LA_PTR ) {
+			sreloc->set_r_value( sreloc->r_value() + fSlide );
+		}
+		else
 		throw "cannot rebase final linked image with scattered relocations";
 	}
 }
+#endif
 
 template <>
 void Rebaser<x86>::doLocalRelocation(const macho_relocation_info<P>* reloc)
@@ -720,6 +746,7 @@ void Rebaser<A>::setRelocBase()
 	//fprintf(stderr, "fOrignalVMRelocBaseAddress=0x%08X\n", fOrignalVMRelocBaseAddress);
 }
 
+#if SUPPORT_ARCH_ppc64
 template <>
 void Rebaser<ppc64>::setRelocBase()
 {
@@ -745,6 +772,7 @@ void Rebaser<ppc64>::setRelocBase()
 	// just use base address
 	fOrignalVMRelocBaseAddress = this->getBaseAddress();
 }
+#endif
 
 template <>
 void Rebaser<x86_64>::setRelocBase()
@@ -867,16 +895,22 @@ static void setSizes(fileInfo& info, const std::set<cpu_type_t>& onlyArchs)
 static const char* nameForArch(cpu_type_t arch)
 {
 	switch( arch ) {
+#if SUPPORT_ARCH_ppc
 		case CPU_TYPE_POWERPC:
 			return "ppc";
+#endif
+#if SUPPORT_ARCH_ppc64
 		case CPU_TYPE_POWERPC64:
 			return "ppca64";
+#endif
 		case CPU_TYPE_I386:
 			return "i386";
 		case CPU_TYPE_X86_64:
 			return "x86_64";
+#if SUPPORT_ARCH_arm_any
 		case CPU_TYPE_ARM:
 			return "arm";
+#endif
 	}
 	return "unknown";
 }
@@ -955,7 +989,12 @@ static uint64_t startAddress(cpu_type_t arch, std::vector<fileInfo>& files, uint
 		return highAddress - totalSize;
 	}
 	else {
-		if ( (arch == CPU_TYPE_I386) || (arch == CPU_TYPE_POWERPC) ) {
+		if ( 0
+			|| (arch == CPU_TYPE_I386)
+#if SUPPORT_ARCH_ppc
+			|| (arch == CPU_TYPE_POWERPC)
+#endif
+			) {
 			// place dylibs below dyld
 			uint64_t topAddr = 0x8FE00000;
 			uint64_t totalSize = totalVMSize(arch, files);
@@ -963,12 +1002,15 @@ static uint64_t startAddress(cpu_type_t arch, std::vector<fileInfo>& files, uint
 				throwf("total size of images (0x%X) does not fit below 0x8FE00000", totalSize);
 			return topAddr - totalSize;
 		}
+#if SUPPORT_ARCH_ppc64
 		else if ( arch == CPU_TYPE_POWERPC64 ) {
 			return 0x200000000ULL;
 		}
+#endif
 		else if ( arch == CPU_TYPE_X86_64 ) {
 			return 0x200000000ULL;
 		}
+#if SUPPORT_ARCH_arm_any
 		else if ( arch == CPU_TYPE_ARM ) {
 			// place dylibs below dyld
 			uint64_t topAddr = 0x2FE00000;
@@ -977,6 +1019,7 @@ static uint64_t startAddress(cpu_type_t arch, std::vector<fileInfo>& files, uint
 				throwf("total size of images (0x%X) does not fit below 0x2FE00000", totalSize);
 			return topAddr - totalSize;
 		}
+#endif
 		else
 			throw "unknown architecture";
 	}
@@ -1039,11 +1082,17 @@ int main(int argc, const char* argv[])
 		
 		// use all architectures if no restrictions specified
 		if ( onlyArchs.size() == 0 ) {
+#if SUPPORT_ARCH_ppc
 			onlyArchs.insert(CPU_TYPE_POWERPC);
+#endif
+#if SUPPORT_ARCH_ppc64
 			onlyArchs.insert(CPU_TYPE_POWERPC64);
+#endif
 			onlyArchs.insert(CPU_TYPE_I386);
 			onlyArchs.insert(CPU_TYPE_X86_64);
+#if SUPPORT_ARCH_arm_any
 			onlyArchs.insert(CPU_TYPE_ARM);
+#endif
 		}
 		
 		// scan files and collect sizes
diff --git a/src/other/unwinddump.cpp b/src/other/unwinddump.cpp
index 3da01c5..f013109 100644
--- a/src/other/unwinddump.cpp
+++ b/src/other/unwinddump.cpp
@@ -96,9 +96,17 @@ private:
 };
 
 
+#if SUPPORT_ARCH_ppc
+template <>	 const char*	UnwindPrinter<ppc>::archName()		{ return "ppc"; }
+#endif
+#if SUPPORT_ARCH_ppc64
+template <>	 const char*	UnwindPrinter<ppc64>::archName()	{ return "ppc64"; }
+#endif
 template <>	 const char*	UnwindPrinter<x86>::archName()		{ return "i386"; }
 template <>	 const char*	UnwindPrinter<x86_64>::archName()	{ return "x86_64"; }
+#if SUPPORT_ARCH_arm_any
 template <>	 const char*	UnwindPrinter<arm>::archName()		{ return "arm"; }
+#endif
 #if SUPPORT_ARCH_arm64
 template <>	 const char*	UnwindPrinter<arm64>::archName()	{ return "arm64"; }
 #endif
